[{"title":"First Blog Post","type":0,"sectionRef":"#","url":"/blog/first-blog-post","content":"Lorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque elementum dignissim ultricies. Fusce rhoncus ipsum tempor eros aliquam consequat. Lorem ipsum dolor sit amet","keywords":""},{"title":"Long Blog Post","type":0,"sectionRef":"#","url":"/blog/long-blog-post","content":"This is the summary of a very long blog post, Use a &lt;!-- truncate --&gt; comment to limit blog post size in the list view. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque elementum dignissim ultricies. Fusce rhoncus ipsum tempor eros aliquam consequat. Lorem ipsum dolor sit amet Lorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque elementum dignissim ultricies. Fusce rhoncus ipsum tempor eros aliquam consequat. Lorem ipsum dolor sit amet Lorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque elementum dignissim ultricies. Fusce rhoncus ipsum tempor eros aliquam consequat. Lorem ipsum dolor sit amet Lorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque elementum dignissim ultricies. Fusce rhoncus ipsum tempor eros aliquam consequat. Lorem ipsum dolor sit amet Lorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque elementum dignissim ultricies. Fusce rhoncus ipsum tempor eros aliquam consequat. Lorem ipsum dolor sit amet Lorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque elementum dignissim ultricies. Fusce rhoncus ipsum tempor eros aliquam consequat. Lorem ipsum dolor sit amet Lorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque elementum dignissim ultricies. Fusce rhoncus ipsum tempor eros aliquam consequat. Lorem ipsum dolor sit amet Lorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque elementum dignissim ultricies. Fusce rhoncus ipsum tempor eros aliquam consequat. Lorem ipsum dolor sit amet Lorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque elementum dignissim ultricies. Fusce rhoncus ipsum tempor eros aliquam consequat. Lorem ipsum dolor sit amet Lorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque elementum dignissim ultricies. Fusce rhoncus ipsum tempor eros aliquam consequat. Lorem ipsum dolor sit amet Lorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque elementum dignissim ultricies. Fusce rhoncus ipsum tempor eros aliquam consequat. Lorem ipsum dolor sit amet Lorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque elementum dignissim ultricies. Fusce rhoncus ipsum tempor eros aliquam consequat. Lorem ipsum dolor sit amet Lorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque elementum dignissim ultricies. Fusce rhoncus ipsum tempor eros aliquam consequat. Lorem ipsum dolor sit amet Lorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque elementum dignissim ultricies. Fusce rhoncus ipsum tempor eros aliquam consequat. Lorem ipsum dolor sit amet Lorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque elementum dignissim ultricies. Fusce rhoncus ipsum tempor eros aliquam consequat. Lorem ipsum dolor sit amet Lorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque elementum dignissim ultricies. Fusce rhoncus ipsum tempor eros aliquam consequat. Lorem ipsum dolor sit amet","keywords":""},{"title":"MDX Blog Post","type":0,"sectionRef":"#","url":"/blog/mdx-blog-post","content":"Blog posts support Docusaurus Markdown features, such as MDX. tip Use the power of React to create interactive blog posts. &lt;button onClick={() =&gt; alert('button clicked!')}&gt;Click me!&lt;/button&gt; Click me!","keywords":""},{"title":"Welcome","type":0,"sectionRef":"#","url":"/blog/welcome","content":"Docusaurus blogging features are powered by the blog plugin. Simply add Markdown files (or folders) to the blog directory. Regular blog authors can be added to authors.yml. The blog post date can be extracted from filenames, such as: 2019-05-30-welcome.md2019-05-30-welcome/index.md A blog post folder can be convenient to co-locate blog post images: The blog supports tags as well! And if you don't want a blog: just delete this directory, and use blog: false in your Docusaurus config.","keywords":""},{"title":"Code Overview","type":0,"sectionRef":"#","url":"/docs/contribute/code-overview","content":"","keywords":""},{"title":"High level​","type":1,"pageTitle":"Code Overview","url":"/docs/contribute/code-overview#high-level","content":""},{"title":"bpf​","type":1,"pageTitle":"Code Overview","url":"/docs/contribute/code-overview#bpf","content":"The eBPF code and headers used by exporter. "},{"title":"cmd​","type":1,"pageTitle":"Code Overview","url":"/docs/contribute/code-overview#cmd","content":"CLI programs. "},{"title":"deploy​","type":1,"pageTitle":"Code Overview","url":"/docs/contribute/code-overview#deploy","content":"Helm charts and manifests for deploying KubeSkoop. "},{"title":"docs​","type":1,"pageTitle":"Code Overview","url":"/docs/contribute/code-overview#docs","content":"Documentation. "},{"title":"pkg​","type":1,"pageTitle":"Code Overview","url":"/docs/contribute/code-overview#pkg","content":"Common go packages. "},{"title":"rpc​","type":1,"pageTitle":"Code Overview","url":"/docs/contribute/code-overview#rpc","content":"gRPC definitions used by exporter. "},{"title":"test​","type":1,"pageTitle":"Code Overview","url":"/docs/contribute/code-overview#test","content":"E2E tests. "},{"title":"KubeSkoop diagnosis​","type":1,"pageTitle":"Code Overview","url":"/docs/contribute/code-overview#kubeskoop-diagnosis","content":""},{"title":"cmd/skoop​","type":1,"pageTitle":"Code Overview","url":"/docs/contribute/code-overview#cmdskoop","content":"skoop command. "},{"title":"cmd/collector​","type":1,"pageTitle":"Code Overview","url":"/docs/contribute/code-overview#cmdcollector","content":"collector command. "},{"title":"pkg/skoop/cmd​","type":1,"pageTitle":"Code Overview","url":"/docs/contribute/code-overview#pkgskoopcmd","content":"Main logic of skoop CLI command. "},{"title":"pkg/skoop/assertions​","type":1,"pageTitle":"Code Overview","url":"/docs/contribute/code-overview#pkgskoopassertions","content":"Assertion type definitions and common assertion utils, including kubernetes and netstack. "},{"title":"pkg/skoop/collector​","type":1,"pageTitle":"Code Overview","url":"/docs/contribute/code-overview#pkgskoopcollector","content":"Definitions and implementation of collector command and CollectorManager . "},{"title":"pkg/skoop/context​","type":1,"pageTitle":"Code Overview","url":"/docs/contribute/code-overview#pkgskoopcontext","content":"Runtime context of the program, providing cluster or task information for the diagnosis. It also provides command flags parsing, and allow other package to register their flags. "},{"title":"pkg/skoop/infra​","type":1,"pageTitle":"Code Overview","url":"/docs/contribute/code-overview#pkgskoopinfra","content":"Implementation of cloud providers. "},{"title":"pkg/skoop/k8s​","type":1,"pageTitle":"Code Overview","url":"/docs/contribute/code-overview#pkgskoopk8s","content":"Definitions and utilities for components of Kubernetes cluster. "},{"title":"pkg/skoop/model​","type":1,"pageTitle":"Code Overview","url":"/docs/contribute/code-overview#pkgskoopmodel","content":"Definitions of models used for diagnosis, including Packet, Link, Action, etc. "},{"title":"pkg/skoop/netstack​","type":1,"pageTitle":"Code Overview","url":"/docs/contribute/code-overview#pkgskoopnetstack","content":"Definitions and parser of Linux network stack, like route, IPVS, and iptables simulation. "},{"title":"pkg/skoop/network​","type":1,"pageTitle":"Code Overview","url":"/docs/contribute/code-overview#pkgskoopnetwork","content":"Implementations of Network . "},{"title":"pkg/skoop/nodemanager​","type":1,"pageTitle":"Code Overview","url":"/docs/contribute/code-overview#pkgskoopnodemanager","content":"Implementation of NetNodeManager "},{"title":"pkg/skoop/plugin​","type":1,"pageTitle":"Code Overview","url":"/docs/contribute/code-overview#pkgskoopplugin","content":"Implementations of Plugin, including flannel, calico, etc. "},{"title":"pkg/skoop/provider​","type":1,"pageTitle":"Code Overview","url":"/docs/contribute/code-overview#pkgskoopprovider","content":"Implementations of Provider, including generic, aliyun, etc. "},{"title":"pkg/skoop/service​","type":1,"pageTitle":"Code Overview","url":"/docs/contribute/code-overview#pkgskoopservice","content":"Implementations of ServiceProcessor, including kube-proxy. "},{"title":"pkg/skoop/skoop​","type":1,"pageTitle":"Code Overview","url":"/docs/contribute/code-overview#pkgskoopskoop","content":"Implementations of Diagnostor. "},{"title":"pkg/skoop/ui​","type":1,"pageTitle":"Code Overview","url":"/docs/contribute/code-overview#pkgskoopui","content":"Output formatter and Web UI. "},{"title":"pkg/skoop/utils​","type":1,"pageTitle":"Code Overview","url":"/docs/contribute/code-overview#pkgskooputils","content":"Utilities. "},{"title":"Architecture","type":0,"sectionRef":"#","url":"/docs/contribute/diagnose/architecture","content":"","keywords":""},{"title":"Key components​","type":1,"pageTitle":"Architecture","url":"/docs/contribute/diagnose/architecture#key-components","content":""},{"title":"Provider​","type":1,"pageTitle":"Architecture","url":"/docs/contribute/diagnose/architecture#provider","content":"Abstraction of cloud provider, responsible for detecting network type and creating Network. "},{"title":"Network​","type":1,"pageTitle":"Architecture","url":"/docs/contribute/diagnose/architecture#network","content":"Cloud-specific container network. A Network should configure all resources that the diagnosis progress needs, including Plugin, Diagnostor, InfraShim, etc. "},{"title":"Diagnostor​","type":1,"pageTitle":"Architecture","url":"/docs/contribute/diagnose/architecture#diagnostor","content":"Implementation of the diagnosis algorithm. It generates the initial links and nodes on source NetNode by executing Send action, and continuously generates new links and nodes by executing Receive action on later added NetNode, until the entire graph has been constructed. "},{"title":"Plugin​","type":1,"pageTitle":"Architecture","url":"/docs/contribute/diagnose/architecture#plugin","content":"Network plugin(flannel, calico, etc.). It creates the actual NetNode from the network config and return NetNodeAction. "},{"title":"NetNodeManager​","type":1,"pageTitle":"Architecture","url":"/docs/contribute/diagnose/architecture#netnodemanager","content":"Create and cache NetNodeAction. It collects Kubernetes pod/node netstack info from CollectorManager, and create NetNodeAction from Plugin. "},{"title":"CollectorManager​","type":1,"pageTitle":"Architecture","url":"/docs/contribute/diagnose/architecture#collectormanager","content":"Manage collect tasks, which collect netstack info of Kubernetes pod/nodes. "},{"title":"IPCache​","type":1,"pageTitle":"Architecture","url":"/docs/contribute/diagnose/architecture#ipcache","content":"Cache major Kubernetes objects used by diagnosis, to prevent redundant access to the API Server. "},{"title":"NetNodeAction​","type":1,"pageTitle":"Architecture","url":"/docs/contribute/diagnose/architecture#netnodeaction","content":"An interface represents the network action of a NetNode. It should be implemented by any NetNode type. "},{"title":"InfraShim​","type":1,"pageTitle":"Architecture","url":"/docs/contribute/diagnose/architecture#infrashim","content":"Assertions of infra resources. Should be implemented by cloud providers. "},{"title":"service.Processor​","type":1,"pageTitle":"Architecture","url":"/docs/contribute/diagnose/architecture#serviceprocessor","content":"The component stands for a service processor (like kube-proxy). It gets the backends of a service, and check its configuration in from netstack info. "},{"title":"(Package)assertions​","type":1,"pageTitle":"Architecture","url":"/docs/contribute/diagnose/architecture#packageassertions","content":"Assertion utilities for diagnosis. Including NetstackAssertion and KubernetesAssertion. "},{"title":"(Package)netstack​","type":1,"pageTitle":"Architecture","url":"/docs/contribute/diagnose/architecture#packagenetstack","content":"Components and utilities of the Linux netstack. Including Router, Netfilter, IPTables, etc. "},{"title":"Key structures​","type":1,"pageTitle":"Architecture","url":"/docs/contribute/diagnose/architecture#key-structures","content":""},{"title":"Context​","type":1,"pageTitle":"Architecture","url":"/docs/contribute/diagnose/architecture#context","content":"type Context struct { Ctx *sync.Map }  Context is used to store runtime configurations. It is responsible for binding flags for modules and providing interfaces for registration. "},{"title":"Endpoint​","type":1,"pageTitle":"Architecture","url":"/docs/contribute/diagnose/architecture#endpoint","content":"type Endpoint struct { IP string Type EndpointType Port uint16 }  Endpoint for the network layer, including IP, Port and Type. "},{"title":"Packet​","type":1,"pageTitle":"Architecture","url":"/docs/contribute/diagnose/architecture#packet","content":"type Packet struct { Src net.IP Sport uint16 Dst net.IP Dport uint16 Protocol Protocol Encap *Packet Mark uint32 }  A data packet. Encap: If the packet is an encapsuled packet (such as an IPIP packet), the real packet is in this field. Mark: Used in router and iptables simulation. "},{"title":"NetNode​","type":1,"pageTitle":"Architecture","url":"/docs/contribute/diagnose/architecture#netnode","content":"type NetNode struct { Type NetNodeType ID string Actions map[*Link]*Action Suspicions []Suspicion initiative *Action }  Node in the network graph. It can be Pod or Node in Kubernetes, or can also be a network resources on the cloud. NetNode implements NetNodeAction for handle network traffic, and Assertion for storing assertions. "},{"title":"Transmission​","type":1,"pageTitle":"Architecture","url":"/docs/contribute/diagnose/architecture#transmission","content":"type Transmission struct { NextHop Hop Link *Link }  A transmit operation created by Send() or Receive() action of a NetNode. It contains NextHop pointing to the next NetNode, and Link to describe the transmission info. "},{"title":"Hop​","type":1,"pageTitle":"Architecture","url":"/docs/contribute/diagnose/architecture#hop","content":"type Hop struct { Type NetNodeType ID string }  Information for a hop, used to find a NetNode. "},{"title":"Link​","type":1,"pageTitle":"Architecture","url":"/docs/contribute/diagnose/architecture#link","content":"type Link struct { Type LinkType Source NetNodeAction Destination NetNodeAction Packet *Packet SourceAttribute LinkAttribute DestinationAttribute LinkAttribute Level int // for print } type LinkAttribute interface { GetAttrs() map[string]string }  The link between two nodes. Type: Contains external, vpc, veth, ipvlan, local, and more. SourceAttribute&amp;DestinationAttribute: The key-value attributes of this link on source and destination nodes. "},{"title":"k8s.Pod​","type":1,"pageTitle":"Architecture","url":"/docs/contribute/diagnose/architecture#k8spod","content":"type PodMeta struct { Namespace string PodName string NodeName string HostNetwork bool } type Pod struct { model.NetNode netstack.NetNS PodMeta }  Information for a Pod of Kubernetes. Includes Pod's metadata and netstack info. "},{"title":"k8s.NodeInfo​","type":1,"pageTitle":"Architecture","url":"/docs/contribute/diagnose/architecture#k8snodeinfo","content":"type NodeInfo struct { netstack.NetNS SubNetNSInfo []netstack.NetNSInfo NodeMeta } type NodeNetworkStackDump struct { Pods []PodNetInfo `json:&quot;pods&quot;` Netns []netstack.NetNSInfo `json:&quot;netns&quot;` } type NodeMeta struct { NodeName string }  Information for a Node of Kubernetes. Includes Node's metadata and netstack info of node and pods on it. "},{"title":"Suspicion​","type":1,"pageTitle":"Architecture","url":"/docs/contribute/diagnose/architecture#suspicion","content":"type Suspicion struct { Level SuspicionLevel Message string }  The problem occurred on a NetNode. Level: Severity of the problem. Contains Info, Warning, Critical and Fatal. Message: Problem description. "},{"title":"Add a new cloud provider","type":0,"sectionRef":"#","url":"/docs/contribute/diagnose/new-cloud-provider","content":"","keywords":""},{"title":"Implement InfraShim​","type":1,"pageTitle":"Add a new cloud provider","url":"/docs/contribute/diagnose/new-cloud-provider#implement-infrashim","content":"InfraShim is used for checking configuration of the underlying infra network. type InfraShim interface { NodeToNode(src *v1.Node, oif string, dst *v1.Node, packet *model.Packet) ([]model.Suspicion, error) NodeToExternal(src *v1.Node, oif string, packet *model.Packet) ([]model.Suspicion, error) }  NodeToNode(): Transmission between two nodes. Accepts kubernetes *v1.Node for source and destination, output interface name, and *model.Packet. Returns []model.Suspicions as result. NodeToExternal() : Transmission from node to external network (eg. internet). Accepts kubernetes *v1.Node for source, output interface name and *model.Packet. Returns []model.Suspicions as result. InfraShim is responsible to check whether the packet can reach its destination in the underlying network, for example, an address in intranet but outside of the cluster should check routes and security groups rules, or an address in internet should check NAT entries. InfraShim should be implemented in pkg/skoop/network/&lt;provider name&gt;. "},{"title":"Implement Network​","type":1,"pageTitle":"Add a new cloud provider","url":"/docs/contribute/diagnose/new-cloud-provider#implement-network","content":"Network are also located in pkg/skoop/network/&lt;provider name&gt;.They are both cloud provider specified and plugin specified, so you should implement your own Network for supported plugins. type Network interface { Diagnose(ctx *ctx.Context, src model.Endpoint, dst model.Endpoint) ([]model.Suspicion, *model.PacketPath, error) }  Diagnose(): accepts *ctx.Context, source and destination as *model.Endpoint. Returns []model.Suspicion and *model.PacketPath. A Network should configure all resources that a diagnosis progress needs, including Plugin, Diagnostor, InfraShim, etc. "},{"title":"Add new Provider​","type":1,"pageTitle":"Add a new cloud provider","url":"/docs/contribute/diagnose/new-cloud-provider#add-new-provider","content":"Provider are located in pkg/skoop/provider. type Provider interface { CreateNetwork(ctx *ctx.Context) (network.Network, error) }  CreateNetwork(): accepts *ctx.Context and returns network.Network. The implementation of Provider is simple: check the plugin type, and create corresponding Network. type genericProvider struct { } func (g genericProvider) CreateNetwork(ctx *context.Context) (network.Network, error) { switch ctx.ClusterConfig().NetworkPlugin { case context.NetworkPluginFlannel: return generic.NewFlannelNetwork(ctx) case context.NetworkPluginCalico: return generic.NewCalicoNetwork(ctx) default: return nil, fmt.Errorf(&quot;not support cni type %q&quot;, ctx.ClusterConfig().NetworkPlugin) } }  You should implement your Provider in pkg/skoop/provider/&lt;provider name&gt;.go. Then, a new provider type constant need to be added in pkg/skoop/provider/provider.go. const ( providerNameGeneric = &quot;generic&quot; providerNameAliyun = &quot;aliyun&quot; // add new provider name here )  This constant value will be used in the command line arguments At last, add your implementation to providers. var providers = map[string]Provider{ providerNameGeneric: genericProvider{}, providerNameAliyun: aliyunProvider{}, // add new provider }  "},{"title":"Components used by cloud providers​","type":1,"pageTitle":"Add a new cloud provider","url":"/docs/contribute/diagnose/new-cloud-provider#components-used-by-cloud-providers","content":"Cloud provider related components are located in pkg/skoop/infra/&lt;provider name&gt;. Such as config, or cloud client. If you want to add any flags for your plugin, you should implement ConfigBinder, and register it. For example in pkg/skoop/infra/aliyun/config.go. type ProviderConfig struct { AccessKeyID string AccessKeySecret string SecurityToken string } var Config = &amp;ProviderConfig{} func init() { context.RegisterConfigBinder(&quot;Aliyun provider&quot;, Config) } func (pc *ProviderConfig) BindFlags(fs *pflag.FlagSet) { fs.StringVarP(&amp;pc.AccessKeyID, &quot;aliyun-access-key-id&quot;, &quot;&quot;, &quot;&quot;, &quot;Aliyun access key.&quot;) fs.StringVarP(&amp;pc.AccessKeySecret, &quot;aliyun-access-key-secret&quot;, &quot;&quot;, &quot;&quot;, &quot;Aliyun access secret.&quot;) fs.StringVarP(&amp;pc.SecurityToken, &quot;aliyun-security-token&quot;, &quot;&quot;, &quot;&quot;, &quot;Aliyun security token (optional).&quot;) } func (pc *ProviderConfig) Validate() error { return nil }  "},{"title":"Extend KubeSkoop","type":0,"sectionRef":"#","url":"/docs/contribute/extend-kubeskoop","content":"","keywords":""},{"title":"Extend KubeSkoop diagnosis​","type":1,"pageTitle":"Extend KubeSkoop","url":"/docs/contribute/extend-kubeskoop#extend-kubeskoop-diagnosis","content":"The key components and structures a described in Architecture. If you are going to add a new plugin or a new cloud provider support for the diagnosis, you can refer to Add a new plugin or Add a new cloud provider. "},{"title":"Extend KubeSkoop exporter​","type":1,"pageTitle":"Extend KubeSkoop","url":"/docs/contribute/extend-kubeskoop#extend-kubeskoop-exporter","content":""},{"title":"Specifying Cloud Provider","type":0,"sectionRef":"#","url":"/docs/guide/diagnose/cloud-providers","content":"Specifying Cloud Provider Cloud provider can be specified via --cloud-provider argument before execution of KubeSkoop diagnose. After setting cloud provider of the cluster, connectivity diagnosis will your configuration on the cloud, like VM security group, route tables, NAT, etc. Aliyun(Alibaba Cloud) Specify --cloud-provider aliyun to use Alibaba Cloud as the cloud provider. Except this, you should also use arguments below: Argument\tDescription--aliyun-access-key-id\taccess key for aliyun provider --aliyun-access-key-secret\taccess secret for aliyun provider --aliyun-security-token\tsecurity token for aliyun provider","keywords":""},{"title":"Command line arguments","type":0,"sectionRef":"#","url":"/docs/guide/diagnose/command-line-arguments","content":"Command line arguments The following command line arguments are provided by kubeskoop cli. Argument\tDescription-p, --dport uint16\tDestination port for the network problem. -d, --dst string\tDestination address for the network problem. --protocol string\tProtocol for the network problem. (default tcp) -s, --src string\tSource address for the network problem. --cloud-provider string\tCloud provider of cluster. (default generic) --cluster-cidr string\tCluster pod CIDR. If not set, will try to detect it automatically. --kube-config string\tCluster kubeconfig file. (default ~/.kube/config) --network-plugin string\tNetwork plugin used in cluster. If not set, will try to auto detect it. --proxy-mode string\tProxy mode for kube-proxy. If not set, will try to detect it automatically. --format string\tOutput format of diagnose result, support dot/svg/json. If not set, only print simple path info on console. --http\tEnable an http server to show diagnose result. --http-address string\tListen address for http server. (default 127.0.0.1:8080) --output string\tOutput file name, default is output.dot/svg/json in current work directory. --aliyun-access-key-id string\tAliyun access key. --aliyun-access-key-secret string\tAliyun access secret. --aliyun-security-token string\tAliyun security token (optional). --collector-image string\tImage used for collector. (default kubeskoop/kubeskoop:&lt;version&gt;) --collector-namespace string\tNamespace where collector pods in. (default skoop) --collector-pod-wait-interval duration\tCollector pod running check interval. (default 2s) --collector-pod-wait-timeout duration\tCollector pod running check timeout. (default 2m0s) --calico-host-interface string\tHost interface for calico plugin. (default eth0) --calico-ipip-pod-mtu int\tPod MTU for calico plugin. Pod interface MTU in IPIP mode. (default 1480) --calico-pod-mtu int\tPod MTU for calico plugin. Pod interface MTU in BGP mode. (default 1500) --flannel-backend-type string\tBackend type for flannel plugin, support host-gw,vxlan,alloc. If not set, it will auto detect from flannel config. --flannel-bridge string\tBridge name for flannel plugin. (default cni0) --flannel-host-interface string\tHost interface for flannel plugin. (default eth0) --flannel-ip-masq\tShould do IP masquerade for flannel plugin. (default true) --flannel-pod-mtu int\tPod MTU for flannel plugin. If not set, it will auto detect from flannel cni mode (1450 for vxlan, 1500 for others).","keywords":""},{"title":"Show/Save Diagnosis Result","type":0,"sectionRef":"#","url":"/docs/guide/diagnose/diagnosis-result","content":"","keywords":""},{"title":"Web UI​","type":1,"pageTitle":"Show/Save Diagnosis Result","url":"/docs/guide/diagnose/diagnosis-result#web-ui","content":"Web UI are provided to view diagnosis result interactivity, by adding --http argument to enable it. When diagnosis finished, it will start an HTTP server on the specified address, by using --http-address argument. Default value of --http-address is 127.0.0.1:8080. $ skoop -s 172.18.0.4 -d 10.96.0.10 -p 53 --http # Execute the diagnostic command, specify the src,dst, and use --http to provide the diagnostic result through the local web service I0118 11:43:23.383446 6280 web.go:97] HTTP server listening on http://127.0.0.1:8080 # After the diagnosis is completed, a link to the diagnosis result will be output  Open the diagnosis result http://127.0.0.1:8080 through browser：  "},{"title":"Output format​","type":1,"pageTitle":"Show/Save Diagnosis Result","url":"/docs/guide/diagnose/diagnosis-result#output-format","content":"dot, svg and json are supported as output format, by using --format to specify which one you want to use. You can also use --output to specify output filename. When set output filename to -, it will print the result to standard output. File will be saved into output.dot/svg/json by default. "},{"title":"dot​","type":1,"pageTitle":"Show/Save Diagnosis Result","url":"/docs/guide/diagnose/diagnosis-result#dot","content":"Use dot as the output format. For more information about dot syntax, please see documentation. This format only contains link graph, and will not contain diagnose result. "},{"title":"svg​","type":1,"pageTitle":"Show/Save Diagnosis Result","url":"/docs/guide/diagnose/diagnosis-result#svg","content":"Use svg as the output format. svg are generated by graphviz via dot file. This format only contains link graph, and will not contain diagnose result. "},{"title":"json​","type":1,"pageTitle":"Show/Save Diagnosis Result","url":"/docs/guide/diagnose/diagnosis-result#json","content":"Use json as the output format. It contains details about nodes and edges in link graph, and also contains diagnose result on them. "},{"title":"Intro","type":0,"sectionRef":"#","url":"/docs/guide/diagnose/intro","content":"","keywords":""},{"title":"Quick Start​","type":1,"pageTitle":"Intro","url":"/docs/guide/diagnose/intro#quick-start","content":""},{"title":"Install KubeSkoop command​","type":1,"pageTitle":"Intro","url":"/docs/guide/diagnose/intro#install-kubeskoop-command","content":"Through go install to install KubeSkoop CLI： go install github.com/alibaba/kubeskoop/cmd/skoop@latest  "},{"title":"One-Shot Diagnose​","type":1,"pageTitle":"Intro","url":"/docs/guide/diagnose/intro#one-shot-diagnose","content":"$ skoop -s 172.18.0.4 -d 10.96.0.10 -p 53 --http # Execute the diagnostic command, specify the src,dst, and use --http to provide the diagnostic result through the local web service I0118 11:43:23.383446 6280 web.go:97] HTTP server listening on http://127.0.0.1:8080 # After the diagnosis is completed, a link to the diagnosis result will be output  And then, you can open http://127.0.0.1:8080 to view the diagnosis result through browser. "},{"title":"How it works​","type":1,"pageTitle":"Intro","url":"/docs/guide/diagnose/intro#how-it-works","content":"When run KubeSkoop connectivity diagnosis, it generates traffic graph from source address to destination address by the network plugin and cloud provider of your cluster. Then, it collects network stack information (iptables rules, network device info, sysctls, etc.) on nodes. When build traffic links, it will evaluate links and edges in the graph to check whether it works as expected. If not, it will be considered as a misconfiguration. "},{"title":"Limitations​","type":1,"pageTitle":"Intro","url":"/docs/guide/diagnose/intro#limitations","content":"KubeSkoop connectivity diagnosis now only supports diagnosis for implemented network plugins. For more information, please see Network plugins "},{"title":"Add a new plugin","type":0,"sectionRef":"#","url":"/docs/contribute/diagnose/new-plugin","content":"","keywords":""},{"title":"Implement Plugin​","type":1,"pageTitle":"Add a new plugin","url":"/docs/contribute/diagnose/new-plugin#implement-plugin","content":"All plugins are located in pkg/skoop/plugin. A plugin should implement interface Plugin. type Plugin interface { CreatePod(pod *k8s.Pod) (model.NetNodeAction, error) CreateNode(node *k8s.NodeInfo) (model.NetNodeAction, error) }  CreatePod(): accepts *k8s.Pod and creates pod implementation as NetNodeAction. CreateNode(): accepts *k8s.NodeInfo and creates node implementation as NetNodeAction You should provide implementations for pod and node based on your plugin. The definition of NetNodeAction is as follows: type NetNodeAction interface { Send(dst Endpoint, protocol Protocol) ([]Transmission, error) Receive(upstream *Link) ([]Transmission, error) }  Send() represents the operation of sending a packet from the node. It accepts destination endpoint and protocol, and returns []Transmission as the result.Receive() represents the operation of receiving a packet on the node. It accepts upstream as *Link, and returns []Transmission as the result. It's quite common to use veth pair as the network interface of pod. In this case, you can use simpleVethPod as implementation of pod by newSimpleVethPod(). For example: func (f *flannelPlugin) CreatePod(pod *k8s.Pod) (model.NetNodeAction, error) { return newSimpleVEthPod(pod, f.ipCache, f.podMTU, &quot;eth0&quot;) }  For node implementations, you may have to determine the type of an Endpoint (Pod, Node, Service, or External). For general, you can use BasePluginNode as NetNodeAction, and implement SimplePluginNode for it. type SimplePluginNode interface { ToPod(upstream *model.Link, dst model.Endpoint, protocol model.Protocol, pod *v1.Pod) ([]model.Transmission, error) ToHost(upstream *model.Link, dst model.Endpoint, protocol model.Protocol, node *v1.Node) ([]model.Transmission, error) ToService(upstream *model.Link, dst model.Endpoint, protocol model.Protocol, service *v1.Service) ([]model.Transmission, error) ToExternal(upstream *model.Link, dst model.Endpoint, protocol model.Protocol) ([]model.Transmission, error) Serve(upstream *model.Link, dst model.Endpoint, protocol model.Protocol) ([]model.Transmission, error) }  SimplePluginNode has already classified actions according to endpoint types. Take Flannel plugin as an example: func (f *flannelPlugin) CreateNode(node *k8s.NodeInfo) (model.NetNodeAction, error) { flannelHost, err := newFlannelHost(f.ipCache, node, f.infraShim, f.serviceProcessor, f.hostOptions) if err != nil { return nil, err } return &amp;BasePluginNode{ NetNode: flannelHost.netNode, IPCache: f.ipCache, SimplePluginNode: flannelHost, }, nil }  During implementation, you may need to use utilities such as IPCache and NetstackAssertion to help you get the information of a resource, or check its network configuration. For more details, you can refer to the implementation of the Flannel plugin in pkg/skoop/plugin/flannel.go. If you want to add any flags for your plugin, you should implement ConfigBinder, and register it. type CalicoConfig struct { PodMTU int IPIPPodMTU int Interface string } func (c *CalicoConfig) BindFlags(fs *pflag.FlagSet) { fs.StringVarP(&amp;c.Interface, &quot;calico-host-interface&quot;, &quot;&quot;, &quot;eth0&quot;, &quot;Host interface for calico plugin.&quot;) fs.IntVarP(&amp;c.PodMTU, &quot;calico-pod-mtu&quot;, &quot;&quot;, 1500, &quot;Pod MTU for calico plugin. Pod interface MTU in BGP mode.&quot;) fs.IntVarP(&amp;c.IPIPPodMTU, &quot;calico-ipip-pod-mtu&quot;, &quot;&quot;, 1480, &quot;Pod MTU for calico plugin. Pod interface MTU in IPIP mode.&quot;) } func (c *CalicoConfig) Validate() error { return nil } var Calico = &amp;CalicoConfig{} func init() { ctx.RegisterConfigBinder(&quot;Calico plugin&quot;, Calico) }  "},{"title":"Implement Network​","type":1,"pageTitle":"Add a new plugin","url":"/docs/contribute/diagnose/new-plugin#implement-network","content":"Network are located in pkg/skoop/network. type Network interface { Diagnose(ctx *ctx.Context, src model.Endpoint, dst model.Endpoint) ([]model.Suspicion, *model.PacketPath, error) }  Diagnose(): accepts *ctx.Context, source and destination as *model.Endpoint. Returns []model.Suspicion and *model.PacketPath. Network are cloud provider specified, and these implementations are located in pkg/skoop/network/&lt;provider name&gt;/. If your plugins are supported on this provider, you should add Networkimplementation for it. Network type generic stands for any cloud provider, so you should at least include your plugin's Network implementation in it. Plugin, NetNodeManager, NetworkPolicy, service.Processor and Diagnostor are configured during the creation of Network. For example: func NewFlannelNetwork(ctx *ctx.Context) (network.Network, error) { serviceProcessor := service.NewKubeProxyServiceProcessor(ctx) plgn, err := plugin.NewFlannelPlugin(ctx, serviceProcessor, nil) if err != nil { return nil, err } collectorManager, err := manager.NewSimplePodCollectorManager(ctx) if err != nil { return nil, err } netNodeManager, err := nodemanager.NewNetNodeManager(ctx, plgn, collectorManager) if err != nil { return nil, err } networkPolicy, err := plugin.NewNetworkPolicy(false, false, ctx.ClusterConfig().IPCache, ctx.KubernetesClient(), serviceProcessor) if err != nil { return nil, err } diagnostor, err := skoop.NewDefaultDiagnostor(ctx, netNodeManager, networkPolicy) if err != nil { return nil, err } return &amp;flannelNetwork{ plugin: plgn, diagnostor: diagnostor, collectorManager: collectorManager, netNodeManager: netNodeManager, }, nil }  "},{"title":"Add new plugin type and create it in Provider​","type":1,"pageTitle":"Add a new plugin","url":"/docs/contribute/diagnose/new-plugin#add-new-plugin-type-and-create-it-in-provider","content":"Plugin types are defined in pkg/skoop/context/cluster.go. You should add a new type here. const ( NetworkPluginFlannel = &quot;flannel&quot; NetworkPluginCalico = &quot;calico&quot; NetworkPluginTerway = &quot;terway&quot; // add your new plugin type here )  After this, you also need to create your plugin in supported cloud providers at pkg/skoop/provider/&lt;provider name&gt;.go. For example: func (g genericProvider) CreateNetwork(ctx *context.Context) (network.Network, error) { switch ctx.ClusterConfig().NetworkPlugin { case context.NetworkPluginFlannel: return generic.NewFlannelNetwork(ctx) case context.NetworkPluginCalico: return generic.NewCalicoNetwork(ctx) // add your plugin type default: return nil, fmt.Errorf(&quot;not support cni type %q&quot;, ctx.ClusterConfig().NetworkPlugin) } }  Now, you can make your plugin work by adding --network plugin &lt;your plugin name&gt; to the CLI command. "},{"title":"Add plugin auto detection​","type":1,"pageTitle":"Add a new plugin","url":"/docs/contribute/diagnose/new-plugin#add-plugin-auto-detection","content":"You can add plugin auto detection inDetectNetworkPlugin() in pkg/utils/k8s.go by listing the DaemonSet in the cluster. func DetectNetworkPlugin(k8sCli *kubernetes.Clientset) (networkMode string, err error) { dss, err := k8sCli.AppsV1().DaemonSets(&quot;&quot;).List(context.Background(), metav1.ListOptions{}) if err != nil { return &quot;&quot;, err } for _, ds := range dss.Items { switch ds.Name { case &quot;kube-flannel-ds&quot;: return &quot;flannel&quot;, nil case &quot;calico-node&quot;: return &quot;calico&quot;, nil case &quot;terway-eniip&quot;: return &quot;terway-eniip&quot;, nil } } return &quot;&quot;, nil }  "},{"title":"Add e2e tests​","type":1,"pageTitle":"Add a new plugin","url":"/docs/contribute/diagnose/new-plugin#add-e2e-tests","content":"Finally, you should add plugin specific tests in test/skoop/e2e/testcase/plugins.go, and add your plugin to test/skoop/e2e/testcase/testcases.go. "},{"title":"Supported Network Plugins","type":0,"sectionRef":"#","url":"/docs/guide/diagnose/network-plugins","content":"","keywords":""},{"title":"Flannel​","type":1,"pageTitle":"Supported Network Plugins","url":"/docs/guide/diagnose/network-plugins#flannel","content":"Type host-gw and vxlan are supported for Flannel cluster, and will auto detect which type should be used in diagnose. "},{"title":"Calico​","type":1,"pageTitle":"Supported Network Plugins","url":"/docs/guide/diagnose/network-plugins#calico","content":"BGP and IPIP mode are supported for Flannel cluster, and will auto detect which type should be used in diagnose. Note: Calico API Server should be installed in cluster to run connectivity diagnosis. For more information please see Calico documentation. "},{"title":"KubeSkoop exporter","type":0,"sectionRef":"#","url":"/docs/guide/exporter/exporter-description","content":"","keywords":""},{"title":"Overview​","type":1,"pageTitle":"KubeSkoop exporter","url":"/docs/guide/exporter/exporter-description#overview","content":"KubeSkoop exporter is a network monitoring tool designed for Kubernetes cloud native environments, which can provide the following functions: Pod-level network monitoring, including traffic, application layer connection information, socket memory allocation status, and more.Metrics monitoring for network abnormal states at the Pod level, such as the number of times a Pod's process waits for more than 100ms to read or write to a socket, the number of times a Pod issues TCP RST packets, and so on.At the Pod level, provide on-site observation of network abnormal events and detailed information on the occurrence of events, such as the kernel network soft interrupt scheduling waiting too long, UDP overflow caused by socket memory shortage, and more. The main differences from common Kubernetes monitoring and observability tools are as follows:&quot;： Functions\tPrometheus Node exporter\tcAdvisor/Metric API\tKubeSkoop exporterBy Pod differentiation\tNo\tYes\tYes Network status monitoring\tYes\tNo\tYes On-site capture of abnormal events\tNo\tNo\tYes Advanced kernel network information\tNo\tYes\tYes "},{"title":"Introduction​","type":1,"pageTitle":"KubeSkoop exporter","url":"/docs/guide/exporter/exporter-description#introduction","content":""},{"title":"Architecture​","type":1,"pageTitle":"KubeSkoop exporter","url":"/docs/guide/exporter/exporter-description#architecture","content":" "},{"title":"Information gathering​","type":1,"pageTitle":"KubeSkoop exporter","url":"/docs/guide/exporter/exporter-description#information-gathering","content":"KubeSkoop exporter provides adaptation for Kubernetes network monitoring function. On the nodes, KubeSkoop exporter collects and categorizes a large amount of network-related data. The core principle behind these functions includes: Obtaining the network isolation status within the node and its association with Pods through the CRI interface and Linux /proc/.Obtaining network monitoring information through Linux /proc/, Linux netlink, and eBPF.Obtaining the contextual state of the operating system kernel during network anomaly events through eBPF. "},{"title":"Aggregated analysis​","type":1,"pageTitle":"KubeSkoop exporter","url":"/docs/guide/exporter/exporter-description#aggregated-analysis","content":"Scraping monitoring information through Prometheus and visualizing it using Grafana.Configuring Grafana Loki to receive event push from KubeSkoop exporter and visualizing it using Grafana.Using the KubeSkoop inspector command-line tool to observe monitoring information. Regarding how to visualize monitoring data, please refer toKubeSkoop exporter visualization "},{"title":"Metrics​","type":1,"pageTitle":"KubeSkoop exporter","url":"/docs/guide/exporter/exporter-description#metrics","content":"KubeSkoop exporter provides Pod-level metric information to reflect environmental changes during instance operation. Metrics are classified into different probes according to their source and user, and their related information is as follows: Name\tDescription\tGranularity\tDatasourcenetdev\tExposes network interfaces statistics from /proc/net/snmp.\tpod\tprocfs io\tExposes process io syscall statistics from /proc/io.\tpod\tprocfs tcp\tExpose tcp basic statistics from /proc/net/tcp\tpod\tprocfs softnet\tExpose softnet statistics from /proc/net/softnet\tpod\tprocfs sock\tExpose sock alloc/memory usage statistics\tpod\tprocfs tcpext\tExpose tcp extended statistics from /proc/net/netstat\tpod\tprocfs udp\tExpose udp basic statistics from /proc/net/snmp\tpod\tprocfs tcpsummary\tExpose tcp diagnosis information\tpod\tnetlink ip\tExpose layer3 ip basic statistics from /proc/net/snmp\tpod\tprocfs socketlatency\tLatency statistics of processing syscall with socket\tpod\teBPF net_softirq\tNetwork softirq schedule and processing latency statistic\tnode\teBPF virtcmdlatency\tVirtio-net command processing latency statistic\tnode\teBPF kernellatency\tLatency statistics of processing network packet in kernel stack\tpod\teBPF netiftxlat\tNetwork interfaces tc qdisc processing latency statistic\tpod\teBPF packetloss\tStatistics of packet dropping in kernel stack processing\tpod\teBPF "},{"title":"Events​","type":1,"pageTitle":"KubeSkoop exporter","url":"/docs/guide/exporter/exporter-description#events","content":"KubeSkoop exporter provides network-related abnormal events occurring on the nodes. Based on our experience in handling network issues in the long-term, we have summarized several common network troubleshooting problems. They often interfere with normal business operations in the cluster in an unpredictable and occasional manner, lacking effective localization methods. Some of them are as follows: Connection failure, response timeout, and other issues caused by discarded network packets.Occasional performance issues caused by longer processing time for network data.Task abnormality issues caused by TCP, conntrack, and other stateful abnormalities. For network issues that are difficult to quickly reproduce and obtain on-site, KubeSkoop exporter provides eBPF-based operating system kernel context observation capabilities to capture the real-time state of the operating system at the scene of the problem and output it in the form of event logs. The events supported by KubeSkoop exporter are as follows: Name\tDescriptionnetif_txlat\tExpose slow processing events in tc egress qdisc packetloss\tExpose packet dropping events in kernel stack processing net_softirq\tExpose NET_RX/NET_TX softirq schedule/processing delay socketlatency\tExpose high latency of operating socket from user process kernellatency\tExpose netfilter/route delay in kernel virtcmdlatency\tExpose high latency virtio-net command processing tcpreset\tExpose receiving/sending tcp segments with RST flag In the information of the event log, relevant information of the event scene can be viewed. Taking the tcp_reset probe as an example, when a Pod receives a normal message on a certain port, KubeSkoop exporter will capture the following event information: type=TCPRESET_NOSOCK pod=storage-monitor-5775dfdc77-fj767 namespace=kube-system protocol=TCP saddr=100.103.42.233 sport=443 daddr=10.1.17.188 dport=33488  The information in the event is as follows: &quot;type&quot; indicates that an event of TCPRESET_NOSOCK type has occurred, which is a type of event captured by the tcpreset probe. It indicates that a message accessing a certain port was rejected locally by sending an RST message because there was no corresponding socket found based on the message. This event often occurs when NAT fails, or when the ipvs timer times out.&quot;pod/namespace&quot; is the Pod metadata associated with the event by KubeSkoop exporter, which is matched based on the network namespace, IP address, and network device number of the sending message.&quot;saddr/sport/daddr/dport&quot; is the information of the abnormal message obtained by KubeSkoop exporter in the kernel. With different events, this part of the information will also differ. For example, in the event information of the net_softirq probe, there is no IP address, instead, there is the CPU number where the interrupt occurred and the duration of the delay caused by it. For events that require effective operating system kernel stack information, additional protocol stack information of the operating system kernel can be obtained by configuring the switch, which will increase certain costs and obtain more accurate phenomena, for example: type=PACKETLOSS pod=hostNetwork namespace=hostNetwork protocol=TCP saddr=10.1.17.172 sport=6443 daddr=10.1.17.176 dport=43018 stacktrace:skb_release_data+0xA3 __kfree_skb+0xE tcp_recvmsg+0x61D inet_recvmsg+0x58 sock_read_iter+0x92 new_sync_read+0xE8 vfs_read+0x89 ksys_read+0x5A  "},{"title":"Install KubeSkoop exporter","type":0,"sectionRef":"#","url":"/docs/guide/exporter/exporter_installation","content":"","keywords":""},{"title":"Dependencies​","type":1,"pageTitle":"Install KubeSkoop exporter","url":"/docs/guide/exporter/exporter_installation#dependencies","content":"Linux kernel &gt;= 4.9.17 （Some functions can be supported on lower versions of the kernel.）Containers runtime based on Docker/Containerd/Pouch. "},{"title":"Quick Installation​","type":1,"pageTitle":"Install KubeSkoop exporter","url":"/docs/guide/exporter/exporter_installation#quick-installation","content":""},{"title":"Quickly experience​","type":1,"pageTitle":"Install KubeSkoop exporter","url":"/docs/guide/exporter/exporter_installation#quickly-experience","content":"KubeSkoop exporter provides a quick deployment configuration that includes the following components: KubeSkoop exporter.Single-instance Prometheus and Grafana components, Grafana Loki component.NodePort services of Prometheus and Grafana. The following steps show how to quickly deploy KubeSkoop exporter and its observability combination with Prometheus, Grafana, and Loki in a Kubernetes cluster: kubectl apply -f https://github.com/alibaba/kubeskoop/deploy/skoopbundle.yaml  Follow the steps below to confirm the installation is complete and obtain the access entry: # Check the running status of kubeskoop exporter. kubectl get pod -n kubeskoop -l app=kubeskoop-exporter -o wide # Check the running status of the Probe collector. kubectl get --raw /api/v1/namespaces/kubeskoop/pods/{{kubeskoop-exporter pod name}}:9102/proxy/status |jq . # Obtain the entry for the Prometheus service. kubectl get service -n kubeskoop prometheus-service -o wide # Obtain the access entry for the Grafana console. kubectl get service -n kubeskoop grafana -o wide  "},{"title":"Install only KubeSkoop exporter​","type":1,"pageTitle":"Install KubeSkoop exporter","url":"/docs/guide/exporter/exporter_installation#install-only-kubeskoop-exporter","content":""},{"title":"Install using Helm​","type":1,"pageTitle":"Install KubeSkoop exporter","url":"/docs/guide/exporter/exporter_installation#install-using-helm","content":"# Add kubeskoop charts repo helm repo add kubeskoop https://kubeskoop.github.io # On the first execution, it is necessary to update the Helm repo cache. helm repo update # Install kubeskoop exporter helm install kubeskoop-exporter kubeskoop/skoop-exporter  If you need to debug Helm Charts information, you can install it locally: # Get the KubeSkoop exporter code. git clone https://github.com/alibaba/kubeskoop.git helm install --set namespace=kube-system skoop-exporter ./kubeskoop/deploy/skoop-exporter-0.1.0.tgz --debug  KubeSkoop exporter is deployed in the cluster as a DaemonSet and can be verified if it is working properly in the following ways: # Check the running status of kubeskoop exporter. kubectl get pod -n kubeskoop -l app=kubeskoop-exporter -o wide # Check the running status of the Probe collector. kubectl get --raw /api/v1/namespaces/kubeskoop/pods/{{kubeskoop-exporter pod name}}:9102/proxy/status |jq . # If you have direct access to the kubeskoop exporter instance, you can also directly check the status of the Probe's operation. curl {{kubeskoop-exporter pod ip}}:9102/status |jq .  "},{"title":"Helm Configuration​","type":1,"pageTitle":"Install KubeSkoop exporter","url":"/docs/guide/exporter/exporter_installation#helm-configuration","content":"The parameters that can be configured when installing KubeSkoop exporter through Helm are as follows: Setting\tDescription\tDefaultname\tkubeskoop-exporter daemonset name\tkubeskoop-exporter namespace\tThe namespace of kubeskoop-exporter workload\tkubeskoop debugmode\tEnable the debugmode of kubeskoop-exporter, with debug interface, debug log level and pprof support\tfalse appName\tPod app label\tkubeskoop-exporter runtimeEndpoint\tCRI runtime endpoint socket, you can use `crictl info\tawk -F&quot;:&quot; '/containerdEndpoint/ {print $2'` to obtain it config.enableEventServer\tEnable the event server\tfalse config.enableMetricServer\tEnable the metric server\ttrue config.remoteLokiAddress\tSet the remote grafana loki endpoint to push events\t`` config.metricLabelVerbose\tDeliever the detail information of pod in metric label, such as app label, ip\tfalse config.metricServerPort\tMetric server port, provide HTTP service\t9102 config.eventServerPort\tEvent sever port, provide GRPC service\t19102 config.metricProbes\tMetric probes to enable\trefer to the probe guide config.eventProbes\tEvent probes to enable\trefer to the probe guide config.metricCacheInterval\tMetric cache interval\t15 "},{"title":"Verification after installation completion​","type":1,"pageTitle":"Install KubeSkoop exporter","url":"/docs/guide/exporter/exporter_installation#verification-after-installation-completion","content":"After completing the installation of KubeSkoop exporter using Helm, you can verify if it is running correctly in the following ways: # Check the running status of the Probe collector. kubectl get --raw /api/v1/namespaces/kubeskoop/pods/{{kubeskoop-exporter pod name}}:9102/proxy/status |jq .  "},{"title":"Configuration​","type":1,"pageTitle":"Install KubeSkoop exporter","url":"/docs/guide/exporter/exporter_installation#configuration","content":"The configuration of KubeSkoop exporter is managed by the ConfigMap object 'inspector-config' by default in the same namespace as the workload. The following methods can be used to modify it: # Change the namespace to the actual effective namespace. kubectl edit cm -n kubeskoop inspector-config  The configuration items supported by KubeSkoop exporter are as follows: Configuration item\tConfiguration function\tDefault valuedebugmode\tDebug mode switch. After turning on debug mode, you can obtain more detailed logs and enable pprof and gops interfaces.\tfalse event_config.loki_enable\tThe switch to push event collection service to Grafana Loki.\tfalse event_config.loki_address\tAfter enabling the event collection service, configure the Grafana Loki service address where the events need to be pushed through this option.\t`` event_config.probes\tConfigure the enabled event collection probes. event_config.port\tThe GRPC server port of KubeSkoop exporter provides event streaming service.\t19102 metric_config.verbose\tGet more detailed monitoring metric labels, including the app label and IP address of the Pod.\tfalse metric_config.port\tThe port of the monitoring metric service that provides HTTP service.\t9102 metric_config.probes\tConfigure the enabled monitoring metric probes. metric_config.interval\tThe caching period for collecting monitoring metrics, measured in seconds.\t15 Reference information for the selectable probe configuration can be found atKubeSkoop exporter Introduction "},{"title":"KubeSkoop exporter visualization","type":0,"sectionRef":"#","url":"/docs/guide/exporter/exporter-visualization-guide","content":"","keywords":""},{"title":"Using Prometheus & Grafana for visualization of metrics.​","type":1,"pageTitle":"KubeSkoop exporter visualization","url":"/docs/guide/exporter/exporter-visualization-guide#using-prometheus--grafana-for-visualization-of-metrics","content":"KubeSkoop exporter provides a standard Prometheus format metric output service. You can quickly integrate KubeSkoop exporter's monitoring information into an existing monitoring system. Please refer to the configuration for details. If there is no ready-to-use monitoring service, please refer to the installation guide to set up a visual monitoring service. "},{"title":"Installation​","type":1,"pageTitle":"KubeSkoop exporter visualization","url":"/docs/guide/exporter/exporter-visualization-guide#installation","content":"Refer to Prometheus Installation to complete the deployment and installation of Prometheus. Refer to Grafana Installation to complete the deployment and installation of Grafana. "},{"title":"Configuring KubeSkoop exporter metric monitoring​","type":1,"pageTitle":"KubeSkoop exporter visualization","url":"/docs/guide/exporter/exporter-visualization-guide#configuring-kubeskoop-exporter-metric-monitoring","content":"KubeSkoop exporter supports the service discovering of Prometheus running in Kubernetes. After installing Prometheus, you can view the ready instances by entering skoop-exporter in the search bar on the Status-&gt;Targets page, for example:  After the KubeSkoop exporter instance is successfully scraped by Prometheus, you can complete the visualization of metrics through the following steps: Enter the Grafana console, click Configuration-&gt;Data sources-&gt;Add data source, select Prometheus, and add the address of the prepared Prometheus instance to the data source subscription of GrafanaCreate a new dashboard or select to create a new panel in an existing dashboard. In the panel configuration, select the data source configured in 1, enter inspector in the Metric browser, and you can see the associated KubeSkoop exporter metrics. Select the desired information from it, for example, inspector_pod_netdevrxbytes. After inputting this, you can see the obtained data in the panel.In the visualization of metrics, you can set the legend and unit information of the metrics as needed. The legend supports configuring information such as the Pod's namespace, IP, and label. These supported legends can be configured in the panel's Legend. "},{"title":"Import the pre-defined default dashboard​","type":1,"pageTitle":"KubeSkoop exporter visualization","url":"/docs/guide/exporter/exporter-visualization-guide#import-the-pre-defined-default-dashboard","content":"KubeSkoop exporter provides a default Grafana dashboard configuration file that can follow version updates: curl https://raw.githubusercontent.com/alibaba/kubeskoop/main/deploy/resource/kubeskoop-exporter-dashboard.json -o dashboard.json  After logging in to the Grafana console, click Dashboards-&gt;Import-&gt;Upload JSON file, select the saved file for upload, select Take Prometheus as data source, and click Import to import it. You can then view the default dashboard. By selecting different panel groups, you can view monitoring metrics of different categories.  "},{"title":"Use Grafana & Loki to view visualized network events​","type":1,"pageTitle":"KubeSkoop exporter visualization","url":"/docs/guide/exporter/exporter-visualization-guide#use-grafana--loki-to-view-visualized-network-events","content":""},{"title":"Installation​","type":1,"pageTitle":"KubeSkoop exporter visualization","url":"/docs/guide/exporter/exporter-visualization-guide#installation-1","content":"Follow the official documentation to install Grafana Loki for different scenarios Grafana Loki Installation。 After installation, you can check the availability of Grafana Loki using the following methods: curl http://[Grafana Loki实例的地址]:3100/ready  "},{"title":"Configure KubeSkoop exporter event stream​","type":1,"pageTitle":"KubeSkoop exporter visualization","url":"/docs/guide/exporter/exporter-visualization-guide#configure-kubeskoop-exporter-event-stream","content":"Grafana dashboard​ You can use Grafana to visualize the KubeSkoop exporter pushed to Grafana Loki events. Follow these steps to achieve visualization: After clicking Configuration-&gt;Data sources-&gt;Add data source, select Loki, and add the address of the Grafana Loki service to the data source subscription of Grafana. This can be an IP address or domain name with a default port of 3100.Create a new dashboard or select a new panel in an existing dashboard. In the panel configuration, select the data source configured in step 1 as the data source, and filter the required event information in the Label browser.In the event panel, you can query specific events through LogQL. After clicking on the event, you can view detailed on-site information. "},{"title":"Intro","type":0,"sectionRef":"#","url":"/docs/guide/intro","content":"","keywords":""},{"title":"Connectivity diagnosis​","type":1,"pageTitle":"Intro","url":"/docs/guide/intro#connectivity-diagnosis","content":""},{"title":"Monitoring​","type":1,"pageTitle":"Intro","url":"/docs/guide/intro#monitoring","content":""},{"title":"Intro","type":0,"sectionRef":"#","url":"/docs/intro","content":"","keywords":""},{"title":"Overview​","type":1,"pageTitle":"Intro","url":"/docs/intro#overview","content":"KubeSkoop is a kubernetes networking diagnose tool for different CNI plug-ins and IaaS providers. KubeSkoop automatic construct network traffic graph of Pod in the Kubernetes cluster, monitoring and analysis of the kernel's critical path by eBPF, to resolve most of Kubernetes cluster network problems. Significantly simplifies the difficulty of diagnosing Kubernetes networking issues. "},{"title":"Key Features​","type":1,"pageTitle":"Intro","url":"/docs/intro#key-features","content":""},{"title":"One-Shot Diagnose​","type":1,"pageTitle":"Intro","url":"/docs/intro#one-shot-diagnose","content":"Diagnose in-cluster traffic between Pod,Service,Node and Ingress/Egress Traffic.Cover whole linux network stack: Socket,Bridge,Veth,Netfilter,sysctls…Support IAAS network probe for cloud providers. "},{"title":"In-Depth Kernel Monitor​","type":1,"pageTitle":"Intro","url":"/docs/intro#in-depth-kernel-monitor","content":"eBPF seamless kernel monitorCO-RE scripts on series kernel by BTFexport metrics to standard Prometheus metric API "},{"title":"Network Anomaly Event​","type":1,"pageTitle":"Intro","url":"/docs/intro#network-anomaly-event","content":"support dozens of anomy scenes recognitionexport anomy event to Grafana Loki Contributing Feel free to open issues and pull requests. Any feedback is much appreciated! Contact DingTalk Group ID(26720020148) License Most source code in KubeSkoop which running on userspace are licensed under the Apache License, Version 2.0. The BPF code in /bpf directory are licensed under the GPL v2.0 to compact with Linux kernel helper functions. "},{"title":"Roadmap","type":0,"sectionRef":"#","url":"/docs/roadmap","content":"Roadmap kubeskoop roadmap","keywords":""},{"title":"Quick Start","type":0,"sectionRef":"#","url":"/docs/quick-start","content":"","keywords":""},{"title":"Kind of kubernetes network issues:​","type":1,"pageTitle":"Quick Start","url":"/docs/quick-start#kind-of-kubernetes-network-issues","content":"Persistent network failure Most of persistent network failure issue are misconfig of network stack, e.g. error iptables rule, misconfig of VM security group. KubeSkoop generates a traffic graph by analyzing the link of src-&gt;dst, and then performs rule verification and simulation on the nodes and edges on the graph to locate the network misconfiguration. Occasional network jitter Occasional packet delays, losses, and retransmissions in network links often lead to application jitter problems. Because they are sporadic, it is difficult to trace back and locate the root cause of the problem. KubeSkoop monitors the key path of the protocol stack in the kernel through eBPF in-depth, integrates multiple indicators to correlate typical jitter scenarios, and records and traces back to the root cause of network anomalies. Network performance bottlenecks Application network dependencies are usually associated with many network links, such as upstream and downstream services, DNS resolution, etc., and it is difficult to analyze the root cause when the performance cannot improve. KubeSkoop finds out key links that affect performance by analyzing application-related links and application-layer bottlenecks. "},{"title":"One-Shot diagnose persistent network failure​","type":1,"pageTitle":"Quick Start","url":"/docs/quick-start#one-shot-diagnose-persistent-network-failure","content":""},{"title":"Install KubeSkoop command​","type":1,"pageTitle":"Quick Start","url":"/docs/quick-start#install-kubeskoop-command","content":"Through go install to install KubeSkoop cli： go install github.com/alibaba/kubeskoop/cmd/skoop@latest  "},{"title":"One-Shot Diagnose​","type":1,"pageTitle":"Quick Start","url":"/docs/quick-start#one-shot-diagnose","content":"$ skoop -s 172.18.0.4 -d 10.96.0.10 -p 53 --http # Execute the diagnostic command, specify the src,dst, and use --http to provide the diagnostic result through the local web service I0118 11:43:23.383446 6280 web.go:97] HTTP server listening on http://127.0.0.1:8080 # After the diagnosis is completed, a link to the diagnosis result will be output  Open the diagnosis result http://127.0.0.1:8080 through browser： "},{"title":"Monitor network jitter and bottlenecks​","type":1,"pageTitle":"Quick Start","url":"/docs/quick-start#monitor-network-jitter-and-bottlenecks","content":""},{"title":"Install monitor components​","type":1,"pageTitle":"Quick Start","url":"/docs/quick-start#install-monitor-components","content":"The Skoop exporter bundles with Prometheus, Grafana, and Loki can be quickly deployed in a Kubernetes cluster by following these steps: kubectl apply -f https://raw.githubusercontent.com/alibaba/kubeskoop/main/deploy/skoopbundle.yaml  Confirm that the installation is complete and obtain access through the following steps： # View the status of Skoop exporter kubectl get pod -n kubeskoop -l app=skoop-exporter -o wide # View the status of Probe collection probes kubectl get --raw /api/v1/namespaces/kubeskoop/pods/skoop-exporter-t4d9m:9102/proxy/status |jq . # Obtain the entrance of Prometheus service, which is exposed by NodePort by default kubectl get service -n kubeskoop prometheus-service -o wide # Obtain the access entry of the Grafana console, which is exposed by NodePort by default kubectl get service -n kubeskoop grafana -o wide  Note: skoopbundle.yaml starts with a minimal copy, not suitable for production environments "},{"title":"network performance analysis​","type":1,"pageTitle":"Quick Start","url":"/docs/quick-start#network-performance-analysis","content":"Open the NodePort Service of grafana on web browser, open the network monitoring page, and check the water level of each monitor item corresponding to the time point of the performance problem. For example： 具体指标说明参考文档: Kubeskoop exporter 功能简介  "},{"title":"network jitter & anomy event analysis​","type":1,"pageTitle":"Quick Start","url":"/docs/quick-start#network-jitter--anomy-event-analysis","content":"Open the NodePort Service of grafana on web browser, open the Loki page, check the events corresponding to the time point of network jitter and the water level corresponding to the network monitoring page. 具体指标说明参考文档: Kubeskoop exporter 功能简介  "}]
[{"title":"First Blog Post","type":0,"sectionRef":"#","url":"/blog/first-blog-post","content":"Lorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque elementum dignissim ultricies. Fusce rhoncus ipsum tempor eros aliquam consequat. Lorem ipsum dolor sit amet","keywords":""},{"title":"Long Blog Post","type":0,"sectionRef":"#","url":"/blog/long-blog-post","content":"This is the summary of a very long blog post, Use a &lt;!-- truncate --&gt; comment to limit blog post size in the list view. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque elementum dignissim ultricies. Fusce rhoncus ipsum tempor eros aliquam consequat. Lorem ipsum dolor sit amet Lorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque elementum dignissim ultricies. Fusce rhoncus ipsum tempor eros aliquam consequat. Lorem ipsum dolor sit amet Lorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque elementum dignissim ultricies. Fusce rhoncus ipsum tempor eros aliquam consequat. Lorem ipsum dolor sit amet Lorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque elementum dignissim ultricies. Fusce rhoncus ipsum tempor eros aliquam consequat. Lorem ipsum dolor sit amet Lorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque elementum dignissim ultricies. Fusce rhoncus ipsum tempor eros aliquam consequat. Lorem ipsum dolor sit amet Lorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque elementum dignissim ultricies. Fusce rhoncus ipsum tempor eros aliquam consequat. Lorem ipsum dolor sit amet Lorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque elementum dignissim ultricies. Fusce rhoncus ipsum tempor eros aliquam consequat. Lorem ipsum dolor sit amet Lorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque elementum dignissim ultricies. Fusce rhoncus ipsum tempor eros aliquam consequat. Lorem ipsum dolor sit amet Lorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque elementum dignissim ultricies. Fusce rhoncus ipsum tempor eros aliquam consequat. Lorem ipsum dolor sit amet Lorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque elementum dignissim ultricies. Fusce rhoncus ipsum tempor eros aliquam consequat. Lorem ipsum dolor sit amet Lorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque elementum dignissim ultricies. Fusce rhoncus ipsum tempor eros aliquam consequat. Lorem ipsum dolor sit amet Lorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque elementum dignissim ultricies. Fusce rhoncus ipsum tempor eros aliquam consequat. Lorem ipsum dolor sit amet Lorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque elementum dignissim ultricies. Fusce rhoncus ipsum tempor eros aliquam consequat. Lorem ipsum dolor sit amet Lorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque elementum dignissim ultricies. Fusce rhoncus ipsum tempor eros aliquam consequat. Lorem ipsum dolor sit amet Lorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque elementum dignissim ultricies. Fusce rhoncus ipsum tempor eros aliquam consequat. Lorem ipsum dolor sit amet Lorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque elementum dignissim ultricies. Fusce rhoncus ipsum tempor eros aliquam consequat. Lorem ipsum dolor sit amet","keywords":""},{"title":"MDX Blog Post","type":0,"sectionRef":"#","url":"/blog/mdx-blog-post","content":"Blog posts support Docusaurus Markdown features, such as MDX. tip Use the power of React to create interactive blog posts. &lt;button onClick={() =&gt; alert('button clicked!')}&gt;Click me!&lt;/button&gt; Click me!","keywords":""},{"title":"Welcome","type":0,"sectionRef":"#","url":"/blog/welcome","content":"Docusaurus blogging features are powered by the blog plugin. Simply add Markdown files (or folders) to the blog directory. Regular blog authors can be added to authors.yml. The blog post date can be extracted from filenames, such as: 2019-05-30-welcome.md2019-05-30-welcome/index.md A blog post folder can be convenient to co-locate blog post images: The blog supports tags as well! And if you don't want a blog: just delete this directory, and use blog: false in your Docusaurus config.","keywords":""},{"title":"Code Overview","type":0,"sectionRef":"#","url":"/docs/contribute/code-overview","content":"","keywords":""},{"title":"High level​","type":1,"pageTitle":"Code Overview","url":"/docs/contribute/code-overview#high-level","content":""},{"title":"bpf​","type":1,"pageTitle":"Code Overview","url":"/docs/contribute/code-overview#bpf","content":"The eBPF code and headers used by exporter. "},{"title":"cmd​","type":1,"pageTitle":"Code Overview","url":"/docs/contribute/code-overview#cmd","content":"CLI programs. "},{"title":"deploy​","type":1,"pageTitle":"Code Overview","url":"/docs/contribute/code-overview#deploy","content":"Helm charts and manifests for deploying KubeSkoop. "},{"title":"docs​","type":1,"pageTitle":"Code Overview","url":"/docs/contribute/code-overview#docs","content":"Documentation. "},{"title":"pkg​","type":1,"pageTitle":"Code Overview","url":"/docs/contribute/code-overview#pkg","content":"Common go packages. "},{"title":"rpc​","type":1,"pageTitle":"Code Overview","url":"/docs/contribute/code-overview#rpc","content":"gRPC definitions used by exporter. "},{"title":"test​","type":1,"pageTitle":"Code Overview","url":"/docs/contribute/code-overview#test","content":"E2E tests. "},{"title":"KubeSkoop diagnosis​","type":1,"pageTitle":"Code Overview","url":"/docs/contribute/code-overview#kubeskoop-diagnosis","content":""},{"title":"cmd/skoop​","type":1,"pageTitle":"Code Overview","url":"/docs/contribute/code-overview#cmdskoop","content":"skoop command. "},{"title":"cmd/collector​","type":1,"pageTitle":"Code Overview","url":"/docs/contribute/code-overview#cmdcollector","content":"collector command. "},{"title":"pkg/skoop/cmd​","type":1,"pageTitle":"Code Overview","url":"/docs/contribute/code-overview#pkgskoopcmd","content":"Main logic of skoop CLI command. "},{"title":"pkg/skoop/assertions​","type":1,"pageTitle":"Code Overview","url":"/docs/contribute/code-overview#pkgskoopassertions","content":"Assertion type definitions and common assertion utils, including kubernetes and netstack. "},{"title":"pkg/skoop/collector​","type":1,"pageTitle":"Code Overview","url":"/docs/contribute/code-overview#pkgskoopcollector","content":"Definitions and implementation of collector command and CollectorManager . "},{"title":"pkg/skoop/context​","type":1,"pageTitle":"Code Overview","url":"/docs/contribute/code-overview#pkgskoopcontext","content":"Runtime context of the program, providing cluster or task information for the diagnosis. It also provides command flags parsing, and allow other package to register their flags. "},{"title":"pkg/skoop/infra​","type":1,"pageTitle":"Code Overview","url":"/docs/contribute/code-overview#pkgskoopinfra","content":"Implementation of cloud providers. "},{"title":"pkg/skoop/k8s​","type":1,"pageTitle":"Code Overview","url":"/docs/contribute/code-overview#pkgskoopk8s","content":"Definitions and utilities for components of Kubernetes cluster. "},{"title":"pkg/skoop/model​","type":1,"pageTitle":"Code Overview","url":"/docs/contribute/code-overview#pkgskoopmodel","content":"Definitions of models used for diagnosis, including Packet, Link, Action, etc. "},{"title":"pkg/skoop/netstack​","type":1,"pageTitle":"Code Overview","url":"/docs/contribute/code-overview#pkgskoopnetstack","content":"Definitions and parser of Linux network stack, like route, IPVS, and iptables simulation. "},{"title":"pkg/skoop/network​","type":1,"pageTitle":"Code Overview","url":"/docs/contribute/code-overview#pkgskoopnetwork","content":"Implementations of Network . "},{"title":"pkg/skoop/nodemanager​","type":1,"pageTitle":"Code Overview","url":"/docs/contribute/code-overview#pkgskoopnodemanager","content":"Implementation of NetNodeManager "},{"title":"pkg/skoop/plugin​","type":1,"pageTitle":"Code Overview","url":"/docs/contribute/code-overview#pkgskoopplugin","content":"Implementations of Plugin, including flannel, calico, etc. "},{"title":"pkg/skoop/provider​","type":1,"pageTitle":"Code Overview","url":"/docs/contribute/code-overview#pkgskoopprovider","content":"Implementations of Provider, including generic, aliyun, etc. "},{"title":"pkg/skoop/service​","type":1,"pageTitle":"Code Overview","url":"/docs/contribute/code-overview#pkgskoopservice","content":"Implementations of ServiceProcessor, including kube-proxy. "},{"title":"pkg/skoop/skoop​","type":1,"pageTitle":"Code Overview","url":"/docs/contribute/code-overview#pkgskoopskoop","content":"Implementations of Diagnostor. "},{"title":"pkg/skoop/ui​","type":1,"pageTitle":"Code Overview","url":"/docs/contribute/code-overview#pkgskoopui","content":"Output formatter and Web UI. "},{"title":"pkg/skoop/utils​","type":1,"pageTitle":"Code Overview","url":"/docs/contribute/code-overview#pkgskooputils","content":"Utilities. "},{"title":"Architecture","type":0,"sectionRef":"#","url":"/docs/contribute/diagnose/architecture","content":"","keywords":""},{"title":"Key components​","type":1,"pageTitle":"Architecture","url":"/docs/contribute/diagnose/architecture#key-components","content":""},{"title":"Provider​","type":1,"pageTitle":"Architecture","url":"/docs/contribute/diagnose/architecture#provider","content":"Abstraction of cloud provider, responsible for detecting network type and creating Network. "},{"title":"Network​","type":1,"pageTitle":"Architecture","url":"/docs/contribute/diagnose/architecture#network","content":"Cloud-specific container network. A Network should configure all resources that the diagnosis progress needs, including Plugin, Diagnostor, InfraShim, etc. "},{"title":"Diagnostor​","type":1,"pageTitle":"Architecture","url":"/docs/contribute/diagnose/architecture#diagnostor","content":"Implementation of the diagnosis algorithm. It generates the initial links and nodes on source NetNode by executing Send action, and continuously generates new links and nodes by executing Receive action on later added NetNode, until the entire graph has been constructed. "},{"title":"Plugin​","type":1,"pageTitle":"Architecture","url":"/docs/contribute/diagnose/architecture#plugin","content":"Network plugin(flannel, calico, etc.). It creates the actual NetNode from the network config and return NetNodeAction. "},{"title":"NetNodeManager​","type":1,"pageTitle":"Architecture","url":"/docs/contribute/diagnose/architecture#netnodemanager","content":"Create and cache NetNodeAction. It collects Kubernetes pod/node netstack info from CollectorManager, and create NetNodeAction from Plugin. "},{"title":"CollectorManager​","type":1,"pageTitle":"Architecture","url":"/docs/contribute/diagnose/architecture#collectormanager","content":"Manage collect tasks, which collect netstack info of Kubernetes pod/nodes. "},{"title":"IPCache​","type":1,"pageTitle":"Architecture","url":"/docs/contribute/diagnose/architecture#ipcache","content":"Cache major Kubernetes objects used by diagnosis, to prevent redundant access to the API Server. "},{"title":"NetNodeAction​","type":1,"pageTitle":"Architecture","url":"/docs/contribute/diagnose/architecture#netnodeaction","content":"An interface represents the network action of a NetNode. It should be implemented by any NetNode type. "},{"title":"InfraShim​","type":1,"pageTitle":"Architecture","url":"/docs/contribute/diagnose/architecture#infrashim","content":"Assertions of infra resources. Should be implemented by cloud providers. "},{"title":"service.Processor​","type":1,"pageTitle":"Architecture","url":"/docs/contribute/diagnose/architecture#serviceprocessor","content":"The component stands for a service processor (like kube-proxy). It gets the backends of a service, and check its configuration in from netstack info. "},{"title":"(Package)assertions​","type":1,"pageTitle":"Architecture","url":"/docs/contribute/diagnose/architecture#packageassertions","content":"Assertion utilities for diagnosis. Including NetstackAssertion and KubernetesAssertion. "},{"title":"(Package)netstack​","type":1,"pageTitle":"Architecture","url":"/docs/contribute/diagnose/architecture#packagenetstack","content":"Components and utilities of the Linux netstack. Including Router, Netfilter, IPTables, etc. "},{"title":"Key structures​","type":1,"pageTitle":"Architecture","url":"/docs/contribute/diagnose/architecture#key-structures","content":""},{"title":"Context​","type":1,"pageTitle":"Architecture","url":"/docs/contribute/diagnose/architecture#context","content":"type Context struct { Ctx *sync.Map }  Context is used to store runtime configurations. It is responsible for binding flags for modules and providing interfaces for registration. "},{"title":"Endpoint​","type":1,"pageTitle":"Architecture","url":"/docs/contribute/diagnose/architecture#endpoint","content":"type Endpoint struct { IP string Type EndpointType Port uint16 }  Endpoint for the network layer, including IP, Port and Type. "},{"title":"Packet​","type":1,"pageTitle":"Architecture","url":"/docs/contribute/diagnose/architecture#packet","content":"type Packet struct { Src net.IP Sport uint16 Dst net.IP Dport uint16 Protocol Protocol Encap *Packet Mark uint32 }  A data packet. Encap: If the packet is an encapsuled packet (such as an IPIP packet), the real packet is in this field. Mark: Used in router and iptables simulation. "},{"title":"NetNode​","type":1,"pageTitle":"Architecture","url":"/docs/contribute/diagnose/architecture#netnode","content":"type NetNode struct { Type NetNodeType ID string Actions map[*Link]*Action Suspicions []Suspicion initiative *Action }  Node in the network graph. It can be Pod or Node in Kubernetes, or can also be a network resources on the cloud. NetNode implements NetNodeAction for handle network traffic, and Assertion for storing assertions. "},{"title":"Transmission​","type":1,"pageTitle":"Architecture","url":"/docs/contribute/diagnose/architecture#transmission","content":"type Transmission struct { NextHop Hop Link *Link }  A transmit operation created by Send() or Receive() action of a NetNode. It contains NextHop pointing to the next NetNode, and Link to describe the transmission info. "},{"title":"Hop​","type":1,"pageTitle":"Architecture","url":"/docs/contribute/diagnose/architecture#hop","content":"type Hop struct { Type NetNodeType ID string }  Information for a hop, used to find a NetNode. "},{"title":"Link​","type":1,"pageTitle":"Architecture","url":"/docs/contribute/diagnose/architecture#link","content":"type Link struct { Type LinkType Source NetNodeAction Destination NetNodeAction Packet *Packet SourceAttribute LinkAttribute DestinationAttribute LinkAttribute Level int // for print } type LinkAttribute interface { GetAttrs() map[string]string }  The link between two nodes. Type: Contains external, vpc, veth, ipvlan, local, and more. SourceAttribute&amp;DestinationAttribute: The key-value attributes of this link on source and destination nodes. "},{"title":"k8s.Pod​","type":1,"pageTitle":"Architecture","url":"/docs/contribute/diagnose/architecture#k8spod","content":"type PodMeta struct { Namespace string PodName string NodeName string HostNetwork bool } type Pod struct { model.NetNode netstack.NetNS PodMeta }  Information for a Pod of Kubernetes. Includes Pod's metadata and netstack info. "},{"title":"k8s.NodeInfo​","type":1,"pageTitle":"Architecture","url":"/docs/contribute/diagnose/architecture#k8snodeinfo","content":"type NodeInfo struct { netstack.NetNS SubNetNSInfo []netstack.NetNSInfo NodeMeta } type NodeNetworkStackDump struct { Pods []PodNetInfo `json:&quot;pods&quot;` Netns []netstack.NetNSInfo `json:&quot;netns&quot;` } type NodeMeta struct { NodeName string }  Information for a Node of Kubernetes. Includes Node's metadata and netstack info of node and pods on it. "},{"title":"Suspicion​","type":1,"pageTitle":"Architecture","url":"/docs/contribute/diagnose/architecture#suspicion","content":"type Suspicion struct { Level SuspicionLevel Message string }  The problem occurred on a NetNode. Level: Severity of the problem. Contains Info, Warning, Critical and Fatal. Message: Problem description. "},{"title":"Add a new cloud provider","type":0,"sectionRef":"#","url":"/docs/contribute/diagnose/new-cloud-provider","content":"","keywords":""},{"title":"Implement InfraShim​","type":1,"pageTitle":"Add a new cloud provider","url":"/docs/contribute/diagnose/new-cloud-provider#implement-infrashim","content":"InfraShim is used for checking configuration of the underlying infra network. type InfraShim interface { NodeToNode(src *v1.Node, oif string, dst *v1.Node, packet *model.Packet) ([]model.Suspicion, error) NodeToExternal(src *v1.Node, oif string, packet *model.Packet) ([]model.Suspicion, error) }  NodeToNode(): Transmission between two nodes. Accepts kubernetes *v1.Node for source and destination, output interface name, and *model.Packet. Returns []model.Suspicions as result. NodeToExternal() : Transmission from node to external network (eg. internet). Accepts kubernetes *v1.Node for source, output interface name and *model.Packet. Returns []model.Suspicions as result. InfraShim is responsible to check whether the packet can reach its destination in the underlying network, for example, an address in intranet but outside of the cluster should check routes and security groups rules, or an address in internet should check NAT entries. InfraShim should be implemented in pkg/skoop/network/&lt;provider name&gt;. "},{"title":"Implement Network​","type":1,"pageTitle":"Add a new cloud provider","url":"/docs/contribute/diagnose/new-cloud-provider#implement-network","content":"Network are also located in pkg/skoop/network/&lt;provider name&gt;.They are both cloud provider specified and plugin specified, so you should implement your own Network for supported plugins. type Network interface { Diagnose(ctx *ctx.Context, src model.Endpoint, dst model.Endpoint) ([]model.Suspicion, *model.PacketPath, error) }  Diagnose(): accepts *ctx.Context, source and destination as *model.Endpoint. Returns []model.Suspicion and *model.PacketPath. A Network should configure all resources that a diagnosis progress needs, including Plugin, Diagnostor, InfraShim, etc. "},{"title":"Add new Provider​","type":1,"pageTitle":"Add a new cloud provider","url":"/docs/contribute/diagnose/new-cloud-provider#add-new-provider","content":"Provider are located in pkg/skoop/provider. type Provider interface { CreateNetwork(ctx *ctx.Context) (network.Network, error) }  CreateNetwork(): accepts *ctx.Context and returns network.Network. The implementation of Provider is simple: check the plugin type, and create corresponding Network. type genericProvider struct { } func (g genericProvider) CreateNetwork(ctx *context.Context) (network.Network, error) { switch ctx.ClusterConfig().NetworkPlugin { case context.NetworkPluginFlannel: return generic.NewFlannelNetwork(ctx) case context.NetworkPluginCalico: return generic.NewCalicoNetwork(ctx) default: return nil, fmt.Errorf(&quot;not support cni type %q&quot;, ctx.ClusterConfig().NetworkPlugin) } }  You should implement your Provider in pkg/skoop/provider/&lt;provider name&gt;.go. Then, a new provider type constant need to be added in pkg/skoop/provider/provider.go. const ( providerNameGeneric = &quot;generic&quot; providerNameAliyun = &quot;aliyun&quot; // add new provider name here )  This constant value will be used in the command line arguments At last, add your implementation to providers. var providers = map[string]Provider{ providerNameGeneric: genericProvider{}, providerNameAliyun: aliyunProvider{}, // add new provider }  "},{"title":"Components used by cloud providers​","type":1,"pageTitle":"Add a new cloud provider","url":"/docs/contribute/diagnose/new-cloud-provider#components-used-by-cloud-providers","content":"Cloud provider related components are located in pkg/skoop/infra/&lt;provider name&gt;. Such as config, or cloud client. If you want to add any flags for your plugin, you should implement ConfigBinder, and register it. For example in pkg/skoop/infra/aliyun/config.go. type ProviderConfig struct { AccessKeyID string AccessKeySecret string SecurityToken string } var Config = &amp;ProviderConfig{} func init() { context.RegisterConfigBinder(&quot;Aliyun provider&quot;, Config) } func (pc *ProviderConfig) BindFlags(fs *pflag.FlagSet) { fs.StringVarP(&amp;pc.AccessKeyID, &quot;aliyun-access-key-id&quot;, &quot;&quot;, &quot;&quot;, &quot;Aliyun access key.&quot;) fs.StringVarP(&amp;pc.AccessKeySecret, &quot;aliyun-access-key-secret&quot;, &quot;&quot;, &quot;&quot;, &quot;Aliyun access secret.&quot;) fs.StringVarP(&amp;pc.SecurityToken, &quot;aliyun-security-token&quot;, &quot;&quot;, &quot;&quot;, &quot;Aliyun security token (optional).&quot;) } func (pc *ProviderConfig) Validate() error { return nil }  "},{"title":"Extend KubeSkoop","type":0,"sectionRef":"#","url":"/docs/contribute/extend-kubeskoop","content":"","keywords":""},{"title":"Extend KubeSkoop diagnosis​","type":1,"pageTitle":"Extend KubeSkoop","url":"/docs/contribute/extend-kubeskoop#extend-kubeskoop-diagnosis","content":"The key components and structures a described in Architecture. If you are going to add a new plugin or a new cloud provider support for the diagnosis, you can refer to Add a new plugin or Add a new cloud provider. "},{"title":"Extend KubeSkoop exporter​","type":1,"pageTitle":"Extend KubeSkoop","url":"/docs/contribute/extend-kubeskoop#extend-kubeskoop-exporter","content":""},{"title":"Specifying Cloud Provider","type":0,"sectionRef":"#","url":"/docs/guide/diagnose/cloud-providers","content":"Specifying Cloud Provider Cloud provider can be specified via --cloud-provider argument before execution of KubeSkoop diagnose. After setting cloud provider of the cluster, connectivity diagnosis will your configuration on the cloud, like VM security group, route tables, NAT, etc. Aliyun(Alibaba Cloud) Specify --cloud-provider aliyun to use Alibaba Cloud as the cloud provider. Except this, you should also use arguments below: Argument\tDescription--aliyun-access-key-id\taccess key for aliyun provider --aliyun-access-key-secret\taccess secret for aliyun provider --aliyun-security-token\tsecurity token for aliyun provider","keywords":""},{"title":"Command line arguments","type":0,"sectionRef":"#","url":"/docs/guide/diagnose/command-line-arguments","content":"Command line arguments The following command line arguments are provided by kubeskoop cli. Argument\tDescription-p, --dport uint16\tDestination port for the network problem. -d, --dst string\tDestination address for the network problem. --protocol string\tProtocol for the network problem. (default tcp) -s, --src string\tSource address for the network problem. --cloud-provider string\tCloud provider of cluster. (default generic) --cluster-cidr string\tCluster pod CIDR. If not set, will try to detect it automatically. --kube-config string\tCluster kubeconfig file. (default ~/.kube/config) --network-plugin string\tNetwork plugin used in cluster. If not set, will try to auto detect it. --proxy-mode string\tProxy mode for kube-proxy. If not set, will try to detect it automatically. --format string\tOutput format of diagnose result, support dot/svg/json. If not set, only print simple path info on console. --http\tEnable an http server to show diagnose result. --http-address string\tListen address for http server. (default 127.0.0.1:8080) --output string\tOutput file name, default is output.dot/svg/json in current work directory. --aliyun-access-key-id string\tAliyun access key. --aliyun-access-key-secret string\tAliyun access secret. --aliyun-security-token string\tAliyun security token (optional). --collector-image string\tImage used for collector. (default kubeskoop/kubeskoop:&lt;version&gt;) --collector-namespace string\tNamespace where collector pods in. (default skoop) --collector-pod-wait-interval duration\tCollector pod running check interval. (default 2s) --collector-pod-wait-timeout duration\tCollector pod running check timeout. (default 2m0s) --calico-host-interface string\tHost interface for calico plugin. (default eth0) --calico-ipip-pod-mtu int\tPod MTU for calico plugin. Pod interface MTU in IPIP mode. (default 1480) --calico-pod-mtu int\tPod MTU for calico plugin. Pod interface MTU in BGP mode. (default 1500) --flannel-backend-type string\tBackend type for flannel plugin, support host-gw,vxlan,alloc. If not set, it will auto detect from flannel config. --flannel-bridge string\tBridge name for flannel plugin. (default cni0) --flannel-host-interface string\tHost interface for flannel plugin. (default eth0) --flannel-ip-masq\tShould do IP masquerade for flannel plugin. (default true) --flannel-pod-mtu int\tPod MTU for flannel plugin. If not set, it will auto detect from flannel cni mode (1450 for vxlan, 1500 for others).","keywords":""},{"title":"Show/Save Diagnosis Result","type":0,"sectionRef":"#","url":"/docs/guide/diagnose/diagnosis-result","content":"","keywords":""},{"title":"Web UI​","type":1,"pageTitle":"Show/Save Diagnosis Result","url":"/docs/guide/diagnose/diagnosis-result#web-ui","content":"Web UI are provided to view diagnosis result interactivity, by adding --http argument to enable it. When diagnosis finished, it will start an HTTP server on the specified address, by using --http-address argument. Default value of --http-address is 127.0.0.1:8080. $ skoop -s 172.18.0.4 -d 10.96.0.10 -p 53 --http # Execute the diagnostic command, specify the src,dst, and use --http to provide the diagnostic result through the local web service I0118 11:43:23.383446 6280 web.go:97] HTTP server listening on http://127.0.0.1:8080 # After the diagnosis is completed, a link to the diagnosis result will be output  Open the diagnosis result http://127.0.0.1:8080 through browser：  "},{"title":"Output format​","type":1,"pageTitle":"Show/Save Diagnosis Result","url":"/docs/guide/diagnose/diagnosis-result#output-format","content":"dot, svg and json are supported as output format, by using --format to specify which one you want to use. You can also use --output to specify output filename. When set output filename to -, it will print the result to standard output. File will be saved into output.dot/svg/json by default. "},{"title":"dot​","type":1,"pageTitle":"Show/Save Diagnosis Result","url":"/docs/guide/diagnose/diagnosis-result#dot","content":"Use dot as the output format. For more information about dot syntax, please see documentation. This format only contains link graph, and will not contain diagnose result. "},{"title":"svg​","type":1,"pageTitle":"Show/Save Diagnosis Result","url":"/docs/guide/diagnose/diagnosis-result#svg","content":"Use svg as the output format. svg are generated by graphviz via dot file. This format only contains link graph, and will not contain diagnose result. "},{"title":"json​","type":1,"pageTitle":"Show/Save Diagnosis Result","url":"/docs/guide/diagnose/diagnosis-result#json","content":"Use json as the output format. It contains details about nodes and edges in link graph, and also contains diagnose result on them. "},{"title":"Add a new plugin","type":0,"sectionRef":"#","url":"/docs/contribute/diagnose/new-plugin","content":"","keywords":""},{"title":"Implement Plugin​","type":1,"pageTitle":"Add a new plugin","url":"/docs/contribute/diagnose/new-plugin#implement-plugin","content":"All plugins are located in pkg/skoop/plugin. A plugin should implement interface Plugin. type Plugin interface { CreatePod(pod *k8s.Pod) (model.NetNodeAction, error) CreateNode(node *k8s.NodeInfo) (model.NetNodeAction, error) }  CreatePod(): accepts *k8s.Pod and creates pod implementation as NetNodeAction. CreateNode(): accepts *k8s.NodeInfo and creates node implementation as NetNodeAction You should provide implementations for pod and node based on your plugin. The definition of NetNodeAction is as follows: type NetNodeAction interface { Send(dst Endpoint, protocol Protocol) ([]Transmission, error) Receive(upstream *Link) ([]Transmission, error) }  Send() represents the operation of sending a packet from the node. It accepts destination endpoint and protocol, and returns []Transmission as the result.Receive() represents the operation of receiving a packet on the node. It accepts upstream as *Link, and returns []Transmission as the result. It's quite common to use veth pair as the network interface of pod. In this case, you can use simpleVethPod as implementation of pod by newSimpleVethPod(). For example: func (f *flannelPlugin) CreatePod(pod *k8s.Pod) (model.NetNodeAction, error) { return newSimpleVEthPod(pod, f.ipCache, f.podMTU, &quot;eth0&quot;) }  For node implementations, you may have to determine the type of an Endpoint (Pod, Node, Service, or External). For general, you can use BasePluginNode as NetNodeAction, and implement SimplePluginNode for it. type SimplePluginNode interface { ToPod(upstream *model.Link, dst model.Endpoint, protocol model.Protocol, pod *v1.Pod) ([]model.Transmission, error) ToHost(upstream *model.Link, dst model.Endpoint, protocol model.Protocol, node *v1.Node) ([]model.Transmission, error) ToService(upstream *model.Link, dst model.Endpoint, protocol model.Protocol, service *v1.Service) ([]model.Transmission, error) ToExternal(upstream *model.Link, dst model.Endpoint, protocol model.Protocol) ([]model.Transmission, error) Serve(upstream *model.Link, dst model.Endpoint, protocol model.Protocol) ([]model.Transmission, error) }  SimplePluginNode has already classified actions according to endpoint types. Take Flannel plugin as an example: func (f *flannelPlugin) CreateNode(node *k8s.NodeInfo) (model.NetNodeAction, error) { flannelHost, err := newFlannelHost(f.ipCache, node, f.infraShim, f.serviceProcessor, f.hostOptions) if err != nil { return nil, err } return &amp;BasePluginNode{ NetNode: flannelHost.netNode, IPCache: f.ipCache, SimplePluginNode: flannelHost, }, nil }  During implementation, you may need to use utilities such as IPCache and NetstackAssertion to help you get the information of a resource, or check its network configuration. For more details, you can refer to the implementation of the Flannel plugin in pkg/skoop/plugin/flannel.go. If you want to add any flags for your plugin, you should implement ConfigBinder, and register it. type CalicoConfig struct { PodMTU int IPIPPodMTU int Interface string } func (c *CalicoConfig) BindFlags(fs *pflag.FlagSet) { fs.StringVarP(&amp;c.Interface, &quot;calico-host-interface&quot;, &quot;&quot;, &quot;eth0&quot;, &quot;Host interface for calico plugin.&quot;) fs.IntVarP(&amp;c.PodMTU, &quot;calico-pod-mtu&quot;, &quot;&quot;, 1500, &quot;Pod MTU for calico plugin. Pod interface MTU in BGP mode.&quot;) fs.IntVarP(&amp;c.IPIPPodMTU, &quot;calico-ipip-pod-mtu&quot;, &quot;&quot;, 1480, &quot;Pod MTU for calico plugin. Pod interface MTU in IPIP mode.&quot;) } func (c *CalicoConfig) Validate() error { return nil } var Calico = &amp;CalicoConfig{} func init() { ctx.RegisterConfigBinder(&quot;Calico plugin&quot;, Calico) }  "},{"title":"Implement Network​","type":1,"pageTitle":"Add a new plugin","url":"/docs/contribute/diagnose/new-plugin#implement-network","content":"Network are located in pkg/skoop/network. type Network interface { Diagnose(ctx *ctx.Context, src model.Endpoint, dst model.Endpoint) ([]model.Suspicion, *model.PacketPath, error) }  Diagnose(): accepts *ctx.Context, source and destination as *model.Endpoint. Returns []model.Suspicion and *model.PacketPath. Network are cloud provider specified, and these implementations are located in pkg/skoop/network/&lt;provider name&gt;/. If your plugins are supported on this provider, you should add Networkimplementation for it. Network type generic stands for any cloud provider, so you should at least include your plugin's Network implementation in it. Plugin, NetNodeManager, NetworkPolicy, service.Processor and Diagnostor are configured during the creation of Network. For example: func NewFlannelNetwork(ctx *ctx.Context) (network.Network, error) { serviceProcessor := service.NewKubeProxyServiceProcessor(ctx) plgn, err := plugin.NewFlannelPlugin(ctx, serviceProcessor, nil) if err != nil { return nil, err } collectorManager, err := manager.NewSimplePodCollectorManager(ctx) if err != nil { return nil, err } netNodeManager, err := nodemanager.NewNetNodeManager(ctx, plgn, collectorManager) if err != nil { return nil, err } networkPolicy, err := plugin.NewNetworkPolicy(false, false, ctx.ClusterConfig().IPCache, ctx.KubernetesClient(), serviceProcessor) if err != nil { return nil, err } diagnostor, err := skoop.NewDefaultDiagnostor(ctx, netNodeManager, networkPolicy) if err != nil { return nil, err } return &amp;flannelNetwork{ plugin: plgn, diagnostor: diagnostor, collectorManager: collectorManager, netNodeManager: netNodeManager, }, nil }  "},{"title":"Add new plugin type and create it in Provider​","type":1,"pageTitle":"Add a new plugin","url":"/docs/contribute/diagnose/new-plugin#add-new-plugin-type-and-create-it-in-provider","content":"Plugin types are defined in pkg/skoop/context/cluster.go. You should add a new type here. const ( NetworkPluginFlannel = &quot;flannel&quot; NetworkPluginCalico = &quot;calico&quot; NetworkPluginTerway = &quot;terway&quot; // add your new plugin type here )  After this, you also need to create your plugin in supported cloud providers at pkg/skoop/provider/&lt;provider name&gt;.go. For example: func (g genericProvider) CreateNetwork(ctx *context.Context) (network.Network, error) { switch ctx.ClusterConfig().NetworkPlugin { case context.NetworkPluginFlannel: return generic.NewFlannelNetwork(ctx) case context.NetworkPluginCalico: return generic.NewCalicoNetwork(ctx) // add your plugin type default: return nil, fmt.Errorf(&quot;not support cni type %q&quot;, ctx.ClusterConfig().NetworkPlugin) } }  Now, you can make your plugin work by adding --network plugin &lt;your plugin name&gt; to the CLI command. "},{"title":"Add plugin auto detection​","type":1,"pageTitle":"Add a new plugin","url":"/docs/contribute/diagnose/new-plugin#add-plugin-auto-detection","content":"You can add plugin auto detection inDetectNetworkPlugin() in pkg/utils/k8s.go by listing the DaemonSet in the cluster. func DetectNetworkPlugin(k8sCli *kubernetes.Clientset) (networkMode string, err error) { dss, err := k8sCli.AppsV1().DaemonSets(&quot;&quot;).List(context.Background(), metav1.ListOptions{}) if err != nil { return &quot;&quot;, err } for _, ds := range dss.Items { switch ds.Name { case &quot;kube-flannel-ds&quot;: return &quot;flannel&quot;, nil case &quot;calico-node&quot;: return &quot;calico&quot;, nil case &quot;terway-eniip&quot;: return &quot;terway-eniip&quot;, nil } } return &quot;&quot;, nil }  "},{"title":"Add e2e tests​","type":1,"pageTitle":"Add a new plugin","url":"/docs/contribute/diagnose/new-plugin#add-e2e-tests","content":"Finally, you should add plugin specific tests in test/skoop/e2e/testcase/plugins.go, and add your plugin to test/skoop/e2e/testcase/testcases.go. "},{"title":"Intro","type":0,"sectionRef":"#","url":"/docs/guide/diagnose/intro","content":"","keywords":""},{"title":"Quick Start​","type":1,"pageTitle":"Intro","url":"/docs/guide/diagnose/intro#quick-start","content":""},{"title":"Install KubeSkoop command​","type":1,"pageTitle":"Intro","url":"/docs/guide/diagnose/intro#install-kubeskoop-command","content":"Through go install to install KubeSkoop CLI： go install github.com/alibaba/kubeskoop/cmd/skoop@latest  "},{"title":"One-Shot Diagnose​","type":1,"pageTitle":"Intro","url":"/docs/guide/diagnose/intro#one-shot-diagnose","content":"$ skoop -s 172.18.0.4 -d 10.96.0.10 -p 53 --http # Execute the diagnostic command, specify the src,dst, and use --http to provide the diagnostic result through the local web service I0118 11:43:23.383446 6280 web.go:97] HTTP server listening on http://127.0.0.1:8080 # After the diagnosis is completed, a link to the diagnosis result will be output  And then, you can open http://127.0.0.1:8080 to view the diagnosis result through browser. "},{"title":"How it works​","type":1,"pageTitle":"Intro","url":"/docs/guide/diagnose/intro#how-it-works","content":"When run KubeSkoop connectivity diagnosis, it generates traffic graph from source address to destination address by the network plugin and cloud provider of your cluster. Then, it collects network stack information (iptables rules, network device info, sysctls, etc.) on nodes. When build traffic links, it will evaluate links and edges in the graph to check whether it works as expected. If not, it will be considered as a misconfiguration. "},{"title":"Limitations​","type":1,"pageTitle":"Intro","url":"/docs/guide/diagnose/intro#limitations","content":"KubeSkoop connectivity diagnosis now only supports diagnosis for implemented network plugins. For more information, please see Network plugins "},{"title":"Supported Network Plugins","type":0,"sectionRef":"#","url":"/docs/guide/diagnose/network-plugins","content":"","keywords":""},{"title":"Flannel​","type":1,"pageTitle":"Supported Network Plugins","url":"/docs/guide/diagnose/network-plugins#flannel","content":"Type host-gw and vxlan are supported for Flannel cluster, and will auto detect which type should be used in diagnose. "},{"title":"Calico​","type":1,"pageTitle":"Supported Network Plugins","url":"/docs/guide/diagnose/network-plugins#calico","content":"BGP and IPIP mode are supported for Flannel cluster, and will auto detect which type should be used in diagnose. Note: Calico API Server should be installed in cluster to run connectivity diagnosis. For more information please see Calico documentation. "},{"title":"KubeSkoop exporter 功能简介","type":0,"sectionRef":"#","url":"/docs/guide/exporter/exporter-description","content":"","keywords":""},{"title":"概述​","type":1,"pageTitle":"KubeSkoop exporter 功能简介","url":"/docs/guide/exporter/exporter-description#概述","content":"KubeSkoop exporter是面向Kubernetes云原生环境的网络监控工具，可以提供以下功能： 针对Pod级别的网络监控，包括流量，应用层连接信息，socket内存分配状态等针对Pod级别的网络异常状态的指标监控，例如Pod内进程对socket进行读写操作的等待时间超过100ms的次数，Pod发出TCP rst报文的次数等针对Pod级别的网络异常事件的现场，提供事件发生的详细信息的观测，例如内核网络软中断调度等待过久，UDP出现socket内存不足导致的溢出等 与常见的Kubernetes监控和可观测性工具的主要区别如下： 功能选项\tPrometheus Node exporter\tcAdvisor/Metric API\tKubeSkoop exporter按照Pod区分\tNo\tYes\tYes 网络状态监控\tYes\tNo\tYes 异常事件的现场捕获\tNo\tNo\tYes 内核网络高阶信息\tNo\tYes\tYes "},{"title":"核心原理​","type":1,"pageTitle":"KubeSkoop exporter 功能简介","url":"/docs/guide/exporter/exporter-description#核心原理","content":""},{"title":"架构​","type":1,"pageTitle":"KubeSkoop exporter 功能简介","url":"/docs/guide/exporter/exporter-description#架构","content":" "},{"title":"信息采集​","type":1,"pageTitle":"KubeSkoop exporter 功能简介","url":"/docs/guide/exporter/exporter-description#信息采集","content":"KubeSkoop exporter提供了适配于Kubernetes网络监控功能，在节点上，KubeSkoop exporter采集并归类了网络相关的大量数据，实现这些功能的核心原理包括: 通过CRI接口和Linux /proc/获取节点内的网络隔离状态及其与Pod的关联信息通过Linux /proc/，Linux netlink和eBPF获取网络监控信息通过eBPF获取操作系统内核在网络异常事件发生时的上下文状态 "},{"title":"聚合分析​","type":1,"pageTitle":"KubeSkoop exporter 功能简介","url":"/docs/guide/exporter/exporter-description#聚合分析","content":"KubeSkoop exporter采集的数据可以通过多种方式获取，包括: 通过Prometheus获取监控信息，并使用Grafana进行可视化操作通过配置Grafana Loki接收KubeSkoop exporter的事件推送，并使用Grafana进行可视化操作使用kubeskoop inspector命令行工具观察监控信息 关于如何将监控数据进行可视化，请参考KubeSkoop exporter 可视化配置 "},{"title":"指标信息​","type":1,"pageTitle":"KubeSkoop exporter 功能简介","url":"/docs/guide/exporter/exporter-description#指标信息","content":"KubeSkoop exporter 提供Pod级别的指标信息来反应实例运行过程中的环境变化，指标按照来源和用户，分类到不同的探针他们的相关信息如下: Name\tDescription\tGranularity\tDatasourcenetdev\tExposes network interfaces statistics from /proc/net/snmp.\tpod\tprocfs io\tExposes process io syscall statistics from /proc/io.\tpod\tprocfs tcp\tExpose tcp basic statistics from /proc/net/tcp\tpod\tprocfs softnet\tExpose softnet statistics from /proc/net/softnet\tpod\tprocfs sock\tExpose sock alloc/memory usage statistics\tpod\tprocfs tcpext\tExpose tcp extended statistics from /proc/net/netstat\tpod\tprocfs udp\tExpose udp basic statistics from /proc/net/snmp\tpod\tprocfs tcpsummary\tExpose tcp diagnosis information\tpod\tnetlink ip\tExpose layer3 ip basic statistics from /proc/net/snmp\tpod\tprocfs socketlatency\tLatency statistics of processing syscall with socket\tpod\teBPF net_softirq\tNetwork softirq schedule and processing latency statistic\tnode\teBPF virtcmdlatency\tVirtio-net command processing latency statistic\tnode\teBPF kernellatency\tLatency statistics of processing network packet in kernel stack\tpod\teBPF netiftxlat\tNetwork interfaces tc qdisc processing latency statistic\tpod\teBPF packetloss\tStatistics of packet dropping in kernel stack processing\tpod\teBPF "},{"title":"网络异常事件信息​","type":1,"pageTitle":"KubeSkoop exporter 功能简介","url":"/docs/guide/exporter/exporter-description#网络异常事件信息","content":"KubeSkoop exporter 提供节点上发生的网络相关的异常事件，根据在长期处理网络问题中的经验，我们归纳了几种常见的网络疑难问题，他们往往在集群中以无法复现，偶然发生的方式干扰正常的业务，缺乏有效的定位手段，其中部分如下： 网络数据报文被丢弃引发的连接失败，响应超时等问题。网络数据处理耗时久引发的偶发性能问题。TCP，conntrack等状态机制异常引发的业务异常问题。 针对无法快速复现和难以获取现场的网络问题，KubeSkoop exporter提供了基于eBPF的操作系统内核上下文观测能力，在问题发生的现场捕获操作系统的实时状态，以事件日志的方式输出。 KubeSkoop exporter 内置支持的事件如下： Name\tDescriptionnetif_txlat\tExpose slow processing events in tc egress qdisc packetloss\tExpose packet dropping events in kernel stack processing net_softirq\tExpose NET_RX/NET_TX softirq schedule/processing delay socketlatency\tExpose high latency of operating socket from user process kernellatency\tExpose netfilter/route delay in kernel virtcmdlatency\tExpose high latency virtio-net command processing tcpreset\tExpose receiving/sending tcp segments with RST flag 在事件日志的信息中，可以查看到事件现场的相关信息，以tcp_reset探针为例，当出现有Pod收到了一个访问为止端口的正常报文时，KubeSkoop exporter会捕获以下事件信息: type=TCPRESET_NOSOCK pod=storage-monitor-5775dfdc77-fj767 namespace=kube-system protocol=TCP saddr=100.103.42.233 sport=443 daddr=10.1.17.188 dport=33488  事件中的信息如下： type表明出现了一次TCPRESET_NOSOCK类型的事件，这是tcpreset探针捕获的一种事件，他表明有访问为止端口的报文被本地发送RST报文拒绝，拒绝的原因是没有根据报文找到相应的socket，通常在NAT失效，如ipvs定时器超时等原因发生后，会伴随这个事件。pod/namespace是KubeSkoop exporter根据发送报文的网络命名空间，ip地址和网络设备序号进行匹配后关联给事件的Pod元信息。saddr/sport/daddr/dport是KubeSkoop exporter在内核获取到的异常报文的信息，随着事件的不同，这部分信息也会有差异，例如net_softirq探针的事件信息中没有ip地址，取而代之的是中断发生的CPU序号，产生的延迟时长等。 对于需要有效的操作系统内核堆栈信息的事件，可以通过配置开关来额外获取操作系统内核的协议栈信息，这会增加一定的消耗，从而获取到更加精准的现象，例如： type=PACKETLOSS pod=hostNetwork namespace=hostNetwork protocol=TCP saddr=10.1.17.172 sport=6443 daddr=10.1.17.176 dport=43018 stacktrace:skb_release_data+0xA3 __kfree_skb+0xE tcp_recvmsg+0x61D inet_recvmsg+0x58 sock_read_iter+0x92 new_sync_read+0xE8 vfs_read+0x89 ksys_read+0x5A  "},{"title":"安装 KubeSkoop exporter","type":0,"sectionRef":"#","url":"/docs/guide/exporter/exporter_installation","content":"","keywords":""},{"title":"安装依赖​","type":1,"pageTitle":"安装 KubeSkoop exporter","url":"/docs/guide/exporter/exporter_installation#安装依赖","content":"Linux kernel &gt;= 4.9.17 （在低版本内核上可以支持部分功能）基于Docker/Containerd/Pouch的容器运行时 "},{"title":"快速安装​","type":1,"pageTitle":"安装 KubeSkoop exporter","url":"/docs/guide/exporter/exporter_installation#快速安装","content":""},{"title":"快速体验KubeSkoop exporter功能​","type":1,"pageTitle":"安装 KubeSkoop exporter","url":"/docs/guide/exporter/exporter_installation#快速体验kubeskoop-exporter功能","content":"KubeSkoop exporter提供了一个可以快速部署的配置，包含以下组件： KubeSkoop exporter组件。单副本的Prometheus组件与Grafana组件，Grafana Loki组件。Prometheus和Grafana的NodePort服务。 通过以下步骤，可以在Kubernetes集群中快速部署KubeSkoop exporter及其与Prometheus，Grafana和Loki构成的可观测性组合： kubectl apply -f https://github.com/alibaba/kubeskoop/deploy/skoopbundle.yaml  通过以下步骤，确认安装完成以及获取访问入口： # 查看Skoop exporter的运行状态 kubectl get pod -n kubeskoop -l app=skoop-exporter -o wide # 查看Probe采集探针的运行状态 kubectl get --raw /api/v1/namespaces/{{skoop-exporter的pod namespace}}/pods/{{skoop-exporter的pod name}}:9102/proxy/status |jq . # 获取Prometheus服务的入口 kubectl get service -n kubeskoop prometheus-service -o wide # 获取Grafana控制台的访问入口 kubectl get service -n kubeskoop grafana -o wide  "},{"title":"仅安装KubeSkoop exporter​","type":1,"pageTitle":"安装 KubeSkoop exporter","url":"/docs/guide/exporter/exporter_installation#仅安装kubeskoop-exporter","content":"通过以下步骤，可以在Kubernetes集群中快速部署KubeSkoop exporter： kubectl apply -f https://github.com/alibaba/kubeskoop/deploy/kubeskoopexporter.yaml  "},{"title":"使用Helm安装​","type":1,"pageTitle":"安装 KubeSkoop exporter","url":"/docs/guide/exporter/exporter_installation#使用helm安装","content":"# 添加skoop charts repo helm repo add kubeskoop https://github.com/alibaba/kubeskoop/charts # 首次执行时，需要更新helm repo缓存 helm repo update # 安装skoop exporter helm install skoop-exporter kubeskoop/skoop-exporter  如果需要调试Helm Charts信息，可以通过本地安装： # 获取skoop exporter代码仓库 git clone https://github.com/alibaba/kubeskoop.git # 进行本地安装 helm install --set namespace=kube-system skoop-exporter ./kubeskoop/deploy/skoop-exporter-0.1.0.tgz --debug  Skoop-exporter以DaemonSet方式部署在集群中，可以通过以下方式验证是否正常工作： # 查看Skoop exporter的运行状态 kubectl get pod -n skoop -l app=skoop-exporter -o wide # 获取到pod的信息后，可以通过apiserver查看Probe采集探针的运行状态 kubectl get --raw /api/v1/namespaces/{{skoop-exporter的pod namespace}}/pods/{{skoop-exporter的pod name}}:9102/proxy/status |jq . # 如果可以直接访问skoop-exporter实例，也可以直接查看Probe的运行状态 curl {{skoop-exporter的pod ip}}:9102/status |jq .  "},{"title":"Helm配置​","type":1,"pageTitle":"安装 KubeSkoop exporter","url":"/docs/guide/exporter/exporter_installation#helm配置","content":"通过helm安装KubeSkoop exporter时，可以配置的参数如下： 配置项\t配置说明\t默认配置name\tKubeSkoop exporter的组件名称\tskoop-exporter namespace\tKubeSkoop exporter的命名空间\tkubeskoop debugmode\t调试模式的开关，打开调试模式后，可以获得更详细的日志以及开启pprof和gops接口\tfalse config.enableEventServer\t事件采集服务的开关\tfalse config.enableMetricServer\t监控指标服务的开关\ttrue config.remoteLokiAddress\t开启事件采集服务后，通过这个选项配置需要推送事件的Grafana Loki服务地址\t`` config.metricLabelVerbose\t获取更加详细的监控指标标签，包括Pod的app标签，ip地址等\tfalse config.metricServerPort\t监控指标服务的端口，提供http服务\t9102 config.eventServerPort\tKubeSkoop exporter的GRPC服务端口，提供事件流服务\t19102 config.metricProbes\t配置开启的监控指标探针 config.eventProbes\t配置开启的事件采集探针 config.metricCacheInterval\t监控指标的采集缓存周期，单位为秒\t15 "},{"title":"安装完成校验​","type":1,"pageTitle":"安装 KubeSkoop exporter","url":"/docs/guide/exporter/exporter_installation#安装完成校验","content":"通过helm方式完成KubeSkoop exporter的安装后，可以通过以下方式验证是否正常运行: # 查看Probe采集探针的运行状态 kubectl get --raw /api/v1/namespaces/{{KubeSkoop exporter的pod namespace}}/pods/{{KubeSkoop exporter的pod name}}:9102/proxy/status |jq .  "},{"title":"配置​","type":1,"pageTitle":"安装 KubeSkoop exporter","url":"/docs/guide/exporter/exporter_installation#配置","content":"KubeSkoop exporter的配置是默认由与workload相同命名空间下的ConfigMap对象inspector-config进行管理，通过以下方式可以进行修改： # 修改命名空间为实际生效的命名空间 kubectl edit cm -n kubeskoop inspector-config  KubeSkoop exporter支持的配置项如下: 配置项\t配置功能\t默认值debugmode\t调试模式的开关，打开调试模式后，可以获得更详细的日志以及开启pprof和gops接口\tfalse event_config.loki_enable\t事件采集服务推向给Grafana Loki的开关\tfalse event_config.loki_address\t开启事件采集服务后，通过这个选项配置需要推送事件的Grafana Loki服务地址\t`` event_config.probes\t配置开启的事件采集探针 event_config.port\tKubeSkoop exporter的GRPC服务端口，提供事件流服务\t19102 metric_config.verbose\t获取更加详细的监控指标标签，包括Pod的app标签，ip地址等\tfalse metric_config.port\t监控指标服务的端口，提供http服务\t9102 metric_config.probes\t配置开启的监控指标探针 metric_config.interval\t监控指标的采集缓存周期，单位为秒\t15 可以选择配置的探针信息可以参考KubeSkoop exporter 功能简介 "},{"title":"Intro","type":0,"sectionRef":"#","url":"/docs/guide/intro","content":"","keywords":""},{"title":"Connectivity diagnosis​","type":1,"pageTitle":"Intro","url":"/docs/guide/intro#connectivity-diagnosis","content":""},{"title":"Monitoring​","type":1,"pageTitle":"Intro","url":"/docs/guide/intro#monitoring","content":""},{"title":"KubeSkoop exporter 可视化配置","type":0,"sectionRef":"#","url":"/docs/guide/exporter/exporter-visualization-guide","content":"","keywords":""},{"title":"使用 Prometheus & Grafana 进行指标的可视化​","type":1,"pageTitle":"KubeSkoop exporter 可视化配置","url":"/docs/guide/exporter/exporter-visualization-guide#使用-prometheus--grafana-进行指标的可视化","content":"KubeSkoop exporter提供了标准的Prometheus格式的指标输出服务，您可以快速将KubeSkoop exporter的监控信息集成到已有的监控系统中，请参考 配置 。 如果没有就绪的监控服务，请参考 安装 搭建可视化的监控服务。 "},{"title":"安装​","type":1,"pageTitle":"KubeSkoop exporter 可视化配置","url":"/docs/guide/exporter/exporter-visualization-guide#安装","content":"参考 Prometheus 的安装 完成Prometheus的部署安装。 参考 Grafana 的安装 完成Grafana的安装并配置与Prometheus的连接。 "},{"title":"配置KubeSkoop exporter指标监控​","type":1,"pageTitle":"KubeSkoop exporter 可视化配置","url":"/docs/guide/exporter/exporter-visualization-guide#配置kubeskoop-exporter指标监控","content":"KubeSkoop exporter支持运行在kubernetes中的prometheus的服务发现功能，在安装完成prometheus之后，可以通过Status-&gt;Targets页面，在搜索栏中输入skoop-exporter，查看已经就绪的实例:  在KubeSkoop exporter实例被prometheus正常捕获后，可以通过以下步骤完成指标的可视化操作： 进入Grafana的控制台，点击Configuration-&gt;Data sources-&gt;Add data source后选择Prometheus，将已经就绪的prometheus实例的地址添加到Grafana的数据源订阅中:新建一个大盘，或者在已有大盘中选择新建一个面板，在面板的配置中选取数据源为1中配置的数据源，并在Metric browser中输入inspector，即可看到联想后的KubeSkoop exporter指标，选取其中需要的信息，以inspector_pod_netdevrxbytes为例，输入完成后，可以在面板中看到获取到的数据。在指标的可视化中，可以根据需要设置指标的图例和单位等信息，其中，图例支持配置Pod的Namespace，ip，label等信息，在面板的Legend中可以配置这些支持的图例。 "},{"title":"导入预定义默认大盘​","type":1,"pageTitle":"KubeSkoop exporter 可视化配置","url":"/docs/guide/exporter/exporter-visualization-guide#导入预定义默认大盘","content":"KubeSkoop exporter提供跟随版本更新的默认Grafana大盘配置文件: curl https://raw.githubusercontent.com/alibaba/kubeskoop/main/deploy/resource/kubeskoop-exporter-dashboard.json -o dashboard.json  登陆Grafana控制台后，点击Dashboards-&gt;Import-&gt;Upload JSON file，选择保存好的文件上传后，选取prometheus作为数据源，点击Import导入，即可查看到默认大盘。通过选取不同的面板组，可以查看到不同类别的监控指标信息:  "},{"title":"使用 Grafana & Loki 查看可视化的网络事件​","type":1,"pageTitle":"KubeSkoop exporter 可视化配置","url":"/docs/guide/exporter/exporter-visualization-guide#使用-grafana--loki-查看可视化的网络事件","content":""},{"title":"安装 Grafana Loki​","type":1,"pageTitle":"KubeSkoop exporter 可视化配置","url":"/docs/guide/exporter/exporter-visualization-guide#安装-grafana-loki","content":"按照官方文档进行不同场景下的 Grafana Loki的安装。 安装完成后，可以通过以下方式检查Grafana Loki的可用性: curl http://[Grafana Loki实例的地址]:3100/ready  "},{"title":"配置KubeSkoop exporter事件流​","type":1,"pageTitle":"KubeSkoop exporter 可视化配置","url":"/docs/guide/exporter/exporter-visualization-guide#配置kubeskoop-exporter事件流","content":"通过Grafana​ 通过Grafana可以将KubeSkoop exporter推送到Grafana Loki的事件进行可视化，通过以下步骤可以实现实现可视化操作： 点击Configuration-&gt;Data sources-&gt;Add data source后选择Loki，将Grafana Loki服务的地址添加到Grafana的数据源订阅中，可以是ip地址和域名，默认端口为3100：新建一个大盘，或者在已有大盘中选择新建一个面板，在面板的配置中选取数据源为1中配置的数据源，并在Label browser中过滤需要的事件信息：在事件面板中，可以通过LogQL查询特定的事件，点击事件后，可以看到详细的现场信息: "},{"title":"Intro","type":0,"sectionRef":"#","url":"/docs/intro","content":"","keywords":""},{"title":"Overview​","type":1,"pageTitle":"Intro","url":"/docs/intro#overview","content":"KubeSkoop is a kubernetes networking diagnose tool for different CNI plug-ins and IaaS providers. KubeSkoop automatic construct network traffic graph of Pod in the Kubernetes cluster, monitoring and analysis of the kernel's critical path by eBPF, to resolve most of Kubernetes cluster network problems. Significantly simplifies the difficulty of diagnosing Kubernetes networking issues. "},{"title":"Key Features​","type":1,"pageTitle":"Intro","url":"/docs/intro#key-features","content":""},{"title":"One-Shot Diagnose​","type":1,"pageTitle":"Intro","url":"/docs/intro#one-shot-diagnose","content":"Diagnose in-cluster traffic between Pod,Service,Node and Ingress/Egress Traffic.Cover whole linux network stack: Socket,Bridge,Veth,Netfilter,sysctls…Support IAAS network probe for cloud providers. "},{"title":"In-Depth Kernel Monitor​","type":1,"pageTitle":"Intro","url":"/docs/intro#in-depth-kernel-monitor","content":"eBPF seamless kernel monitorCO-RE scripts on series kernel by BTFexport metrics to standard Prometheus metric API "},{"title":"Network Anomaly Event​","type":1,"pageTitle":"Intro","url":"/docs/intro#network-anomaly-event","content":"support dozens of anomy scenes recognitionexport anomy event to Grafana Loki Contributing Feel free to open issues and pull requests. Any feedback is much appreciated! Contact DingTalk Group ID(26720020148) License Most source code in KubeSkoop which running on userspace are licensed under the Apache License, Version 2.0. The BPF code in /bpf directory are licensed under the GPL v2.0 to compact with Linux kernel helper functions. "},{"title":"Roadmap","type":0,"sectionRef":"#","url":"/docs/roadmap","content":"Roadmap kubeskoop roadmap","keywords":""},{"title":"Quick Start","type":0,"sectionRef":"#","url":"/docs/quick-start","content":"","keywords":""},{"title":"Kind of kubernetes network issues:​","type":1,"pageTitle":"Quick Start","url":"/docs/quick-start#kind-of-kubernetes-network-issues","content":"Persistent network failure Most of persistent network failure issue are misconfig of network stack, e.g. error iptables rule, misconfig of VM security group. KubeSkoop generates a traffic graph by analyzing the link of src-&gt;dst, and then performs rule verification and simulation on the nodes and edges on the graph to locate the network misconfiguration. Occasional network jitter Occasional packet delays, losses, and retransmissions in network links often lead to application jitter problems. Because they are sporadic, it is difficult to trace back and locate the root cause of the problem. KubeSkoop monitors the key path of the protocol stack in the kernel through eBPF in-depth, integrates multiple indicators to correlate typical jitter scenarios, and records and traces back to the root cause of network anomalies. Network performance bottlenecks Application network dependencies are usually associated with many network links, such as upstream and downstream services, DNS resolution, etc., and it is difficult to analyze the root cause when the performance cannot improve. KubeSkoop finds out key links that affect performance by analyzing application-related links and application-layer bottlenecks. "},{"title":"One-Shot diagnose persistent network failure​","type":1,"pageTitle":"Quick Start","url":"/docs/quick-start#one-shot-diagnose-persistent-network-failure","content":""},{"title":"Install KubeSkoop command​","type":1,"pageTitle":"Quick Start","url":"/docs/quick-start#install-kubeskoop-command","content":"Through go install to install KubeSkoop cli： go install github.com/alibaba/kubeskoop/cmd/skoop@latest  "},{"title":"One-Shot Diagnose​","type":1,"pageTitle":"Quick Start","url":"/docs/quick-start#one-shot-diagnose","content":"$ skoop -s 172.18.0.4 -d 10.96.0.10 -p 53 --http # Execute the diagnostic command, specify the src,dst, and use --http to provide the diagnostic result through the local web service I0118 11:43:23.383446 6280 web.go:97] HTTP server listening on http://127.0.0.1:8080 # After the diagnosis is completed, a link to the diagnosis result will be output  Open the diagnosis result http://127.0.0.1:8080 through browser： "},{"title":"Monitor network jitter and bottlenecks​","type":1,"pageTitle":"Quick Start","url":"/docs/quick-start#monitor-network-jitter-and-bottlenecks","content":""},{"title":"Install monitor components​","type":1,"pageTitle":"Quick Start","url":"/docs/quick-start#install-monitor-components","content":"The Skoop exporter bundles with Prometheus, Grafana, and Loki can be quickly deployed in a Kubernetes cluster by following these steps: kubectl apply -f https://raw.githubusercontent.com/alibaba/kubeskoop/main/deploy/skoopbundle.yaml  Confirm that the installation is complete and obtain access through the following steps： # View the status of Skoop exporter kubectl get pod -n kubeskoop -l app=skoop-exporter -o wide # View the status of Probe collection probes kubectl get --raw /api/v1/namespaces/kubeskoop/pods/skoop-exporter-t4d9m:9102/proxy/status |jq . # Obtain the entrance of Prometheus service, which is exposed by NodePort by default kubectl get service -n kubeskoop prometheus-service -o wide # Obtain the access entry of the Grafana console, which is exposed by NodePort by default kubectl get service -n kubeskoop grafana -o wide  Note: skoopbundle.yaml starts with a minimal copy, not suitable for production environments "},{"title":"network performance analysis​","type":1,"pageTitle":"Quick Start","url":"/docs/quick-start#network-performance-analysis","content":"Open the NodePort Service of grafana on web browser, open the network monitoring page, and check the water level of each monitor item corresponding to the time point of the performance problem. For example： 具体指标说明参考文档: Kubeskoop exporter 功能简介  "},{"title":"network jitter & anomy event analysis​","type":1,"pageTitle":"Quick Start","url":"/docs/quick-start#network-jitter--anomy-event-analysis","content":"Open the NodePort Service of grafana on web browser, open the Loki page, check the events corresponding to the time point of network jitter and the water level corresponding to the network monitoring page. 具体指标说明参考文档: Kubeskoop exporter 功能简介  "}]
[{"title":"First Blog Post","type":0,"sectionRef":"#","url":"/zh/blog/first-blog-post","content":"Lorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque elementum dignissim ultricies. Fusce rhoncus ipsum tempor eros aliquam consequat. Lorem ipsum dolor sit amet","keywords":""},{"title":"MDX Blog Post","type":0,"sectionRef":"#","url":"/zh/blog/mdx-blog-post","content":"Blog posts support Docusaurus Markdown features, such as MDX. 提示 Use the power of React to create interactive blog posts. &lt;button onClick={() =&gt; alert('button clicked!')}&gt;Click me!&lt;/button&gt; Click me!","keywords":""},{"title":"Long Blog Post","type":0,"sectionRef":"#","url":"/zh/blog/long-blog-post","content":"This is the summary of a very long blog post, Use a &lt;!-- truncate --&gt; comment to limit blog post size in the list view. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque elementum dignissim ultricies. Fusce rhoncus ipsum tempor eros aliquam consequat. Lorem ipsum dolor sit amet Lorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque elementum dignissim ultricies. Fusce rhoncus ipsum tempor eros aliquam consequat. Lorem ipsum dolor sit amet Lorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque elementum dignissim ultricies. Fusce rhoncus ipsum tempor eros aliquam consequat. Lorem ipsum dolor sit amet Lorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque elementum dignissim ultricies. Fusce rhoncus ipsum tempor eros aliquam consequat. Lorem ipsum dolor sit amet Lorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque elementum dignissim ultricies. Fusce rhoncus ipsum tempor eros aliquam consequat. Lorem ipsum dolor sit amet Lorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque elementum dignissim ultricies. Fusce rhoncus ipsum tempor eros aliquam consequat. Lorem ipsum dolor sit amet Lorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque elementum dignissim ultricies. Fusce rhoncus ipsum tempor eros aliquam consequat. Lorem ipsum dolor sit amet Lorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque elementum dignissim ultricies. Fusce rhoncus ipsum tempor eros aliquam consequat. Lorem ipsum dolor sit amet Lorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque elementum dignissim ultricies. Fusce rhoncus ipsum tempor eros aliquam consequat. Lorem ipsum dolor sit amet Lorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque elementum dignissim ultricies. Fusce rhoncus ipsum tempor eros aliquam consequat. Lorem ipsum dolor sit amet Lorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque elementum dignissim ultricies. Fusce rhoncus ipsum tempor eros aliquam consequat. Lorem ipsum dolor sit amet Lorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque elementum dignissim ultricies. Fusce rhoncus ipsum tempor eros aliquam consequat. Lorem ipsum dolor sit amet Lorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque elementum dignissim ultricies. Fusce rhoncus ipsum tempor eros aliquam consequat. Lorem ipsum dolor sit amet Lorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque elementum dignissim ultricies. Fusce rhoncus ipsum tempor eros aliquam consequat. Lorem ipsum dolor sit amet Lorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque elementum dignissim ultricies. Fusce rhoncus ipsum tempor eros aliquam consequat. Lorem ipsum dolor sit amet Lorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque elementum dignissim ultricies. Fusce rhoncus ipsum tempor eros aliquam consequat. Lorem ipsum dolor sit amet","keywords":""},{"title":"Welcome","type":0,"sectionRef":"#","url":"/zh/blog/welcome","content":"Docusaurus blogging features are powered by the blog plugin. Simply add Markdown files (or folders) to the blog directory. Regular blog authors can be added to authors.yml. The blog post date can be extracted from filenames, such as: 2019-05-30-welcome.md2019-05-30-welcome/index.md A blog post folder can be convenient to co-locate blog post images: The blog supports tags as well! And if you don't want a blog: just delete this directory, and use blog: false in your Docusaurus config.","keywords":""},{"title":"代码概览","type":0,"sectionRef":"#","url":"/zh/docs/contribute/code-overview","content":"","keywords":""},{"title":"整体概览​","type":1,"pageTitle":"代码概览","url":"/zh/docs/contribute/code-overview#整体概览","content":""},{"title":"bpf​","type":1,"pageTitle":"代码概览","url":"/zh/docs/contribute/code-overview#bpf","content":"KubeSkoop所使用的eBPF程序源码。 "},{"title":"cmd​","type":1,"pageTitle":"代码概览","url":"/zh/docs/contribute/code-overview#cmd","content":"CLI程序。 "},{"title":"deploy​","type":1,"pageTitle":"代码概览","url":"/zh/docs/contribute/code-overview#deploy","content":"用于部署KubeSkoop的Helm chart和资源文件。 "},{"title":"docs​","type":1,"pageTitle":"代码概览","url":"/zh/docs/contribute/code-overview#docs","content":"文档。 "},{"title":"pkg​","type":1,"pageTitle":"代码概览","url":"/zh/docs/contribute/code-overview#pkg","content":"go包代码。 "},{"title":"rpc​","type":1,"pageTitle":"代码概览","url":"/zh/docs/contribute/code-overview#rpc","content":"Exporter所使用的gRPC定义。 "},{"title":"test​","type":1,"pageTitle":"代码概览","url":"/zh/docs/contribute/code-overview#test","content":"E2E测试。 "},{"title":"KubeSkoop diagnosis​","type":1,"pageTitle":"代码概览","url":"/zh/docs/contribute/code-overview#kubeskoop-diagnosis","content":""},{"title":"cmd/skoop​","type":1,"pageTitle":"代码概览","url":"/zh/docs/contribute/code-overview#cmdskoop","content":"skoop命令实现. "},{"title":"cmd/collector​","type":1,"pageTitle":"代码概览","url":"/zh/docs/contribute/code-overview#cmdcollector","content":"collector命令实现. "},{"title":"pkg/skoop/cmd​","type":1,"pageTitle":"代码概览","url":"/zh/docs/contribute/code-overview#pkgskoopcmd","content":"skoop命令的主要程序逻辑。 "},{"title":"pkg/skoop/assertions​","type":1,"pageTitle":"代码概览","url":"/zh/docs/contribute/code-overview#pkgskoopassertions","content":"断言的类型定义，以及常用的断言实现，包括kubernetes和netstack。 "},{"title":"pkg/skoop/collector​","type":1,"pageTitle":"代码概览","url":"/zh/docs/contribute/code-overview#pkgskoopcollector","content":"collector命令和CollectorManager 的定义与实现。 "},{"title":"pkg/skoop/context​","type":1,"pageTitle":"代码概览","url":"/zh/docs/contribute/code-overview#pkgskoopcontext","content":"程序的运行时上下文，提供了诊断所需的集群或诊断任务的信息。同时，它也提供了命令行参数的解析，并允许其它模块将自己所需要的参数注册过来。 "},{"title":"pkg/skoop/infra​","type":1,"pageTitle":"代码概览","url":"/zh/docs/contribute/code-overview#pkgskoopinfra","content":"云厂商相关代码的实现。 "},{"title":"pkg/skoop/k8s​","type":1,"pageTitle":"代码概览","url":"/zh/docs/contribute/code-overview#pkgskoopk8s","content":"与Kubernetes集群相关的定义，以及实用工具。 "},{"title":"pkg/skoop/model​","type":1,"pageTitle":"代码概览","url":"/zh/docs/contribute/code-overview#pkgskoopmodel","content":"与诊断相关的模型定义，包括Packet、Link、Action等。 "},{"title":"pkg/skoop/netstack​","type":1,"pageTitle":"代码概览","url":"/zh/docs/contribute/code-overview#pkgskoopnetstack","content":"与Linux网路栈相关的定义以及解析工具，如路由、IPVS，以及iptables模拟。 "},{"title":"pkg/skoop/network​","type":1,"pageTitle":"代码概览","url":"/zh/docs/contribute/code-overview#pkgskoopnetwork","content":"Network 的实现。 "},{"title":"pkg/skoop/nodemanager​","type":1,"pageTitle":"代码概览","url":"/zh/docs/contribute/code-overview#pkgskoopnodemanager","content":"NetNodeManager的实现。 "},{"title":"pkg/skoop/plugin​","type":1,"pageTitle":"代码概览","url":"/zh/docs/contribute/code-overview#pkgskoopplugin","content":"Plugin的实现，包括flannel, calico等。 "},{"title":"pkg/skoop/provider​","type":1,"pageTitle":"代码概览","url":"/zh/docs/contribute/code-overview#pkgskoopprovider","content":"Provider的实现，包括generic, aliyun等。 "},{"title":"pkg/skoop/service​","type":1,"pageTitle":"代码概览","url":"/zh/docs/contribute/code-overview#pkgskoopservice","content":"ServiceProcessor的实现，包括kube-proxy。 "},{"title":"pkg/skoop/skoop​","type":1,"pageTitle":"代码概览","url":"/zh/docs/contribute/code-overview#pkgskoopskoop","content":"Diagnostor的实现。 "},{"title":"pkg/skoop/ui​","type":1,"pageTitle":"代码概览","url":"/zh/docs/contribute/code-overview#pkgskoopui","content":"格式化输出以及Web UI。 "},{"title":"pkg/skoop/utils​","type":1,"pageTitle":"代码概览","url":"/zh/docs/contribute/code-overview#pkgskooputils","content":"实用工具。 "},{"title":"架构","type":0,"sectionRef":"#","url":"/zh/docs/contribute/connectivity-diagnosis/architecture","content":"","keywords":""},{"title":"关键组件​","type":1,"pageTitle":"架构","url":"/zh/docs/contribute/connectivity-diagnosis/architecture#关键组件","content":""},{"title":"Provider​","type":1,"pageTitle":"架构","url":"/zh/docs/contribute/connectivity-diagnosis/architecture#provider","content":"云提供商的抽象，负责探测集群的网络类型，以及创建Network。 "},{"title":"Network​","type":1,"pageTitle":"架构","url":"/zh/docs/contribute/connectivity-diagnosis/architecture#network","content":"云提供商特定的网络。Network中应当对诊断过程中需要的所有资源进行配置，包括Plugin、Diagnostor、InfraShim等。 "},{"title":"Diagnostor​","type":1,"pageTitle":"架构","url":"/zh/docs/contribute/connectivity-diagnosis/architecture#diagnostor","content":"诊断算法的实现。该算法会在通过在源NetNode上执行Send动作，获得初始的链路信息。随后，将会在随后生成出的NetNode上执行Receive动作，不断产生新的链路和节点，直到整张链路图被构造完成。 "},{"title":"Plugin​","type":1,"pageTitle":"架构","url":"/zh/docs/contribute/connectivity-diagnosis/architecture#plugin","content":"网络插件（flannel、calico等）。负责从网络配置中创建出实际的NetNode，作为NetNodeAction返回。 "},{"title":"NetNodeManager​","type":1,"pageTitle":"架构","url":"/zh/docs/contribute/connectivity-diagnosis/architecture#netnodemanager","content":"创建并缓存NetNodeAction。通过CollectorManager采集Kubernetes pod/node网络栈信息后，通过Plugin创建出NetNodeAction。 "},{"title":"CollectorManager​","type":1,"pageTitle":"架构","url":"/zh/docs/contribute/connectivity-diagnosis/architecture#collectormanager","content":"管理Kubernetes pod/nodes网络栈信息的采集任务。 "},{"title":"IPCache​","type":1,"pageTitle":"架构","url":"/zh/docs/contribute/connectivity-diagnosis/architecture#ipcache","content":"缓存被诊断过程使用的主要Kubernetes对象，防止对API Server的冗余访问。 "},{"title":"NetNodeAction​","type":1,"pageTitle":"架构","url":"/zh/docs/contribute/connectivity-diagnosis/architecture#netnodeaction","content":"代表NetNode上的网络动作的接口。任何NetNode都应当实现该接口。 "},{"title":"InfraShim​","type":1,"pageTitle":"架构","url":"/zh/docs/contribute/connectivity-diagnosis/architecture#infrashim","content":"对基础设施提供的资源的断言。该部分应当根据不同的云提供商实现。 "},{"title":"service.Processor​","type":1,"pageTitle":"架构","url":"/zh/docs/contribute/connectivity-diagnosis/architecture#serviceprocessor","content":"代表处理Service的组件（如kube-proxy）。它获得service的后端端点，并且根据网络栈信息来检查它们是否配置正确。 "},{"title":"(包)assertions​","type":1,"pageTitle":"架构","url":"/zh/docs/contribute/connectivity-diagnosis/architecture#包assertions","content":"用于诊断中的断言。包括NetstackAssertion和KubernetesAssertion。 "},{"title":"(包)netstack​","type":1,"pageTitle":"架构","url":"/zh/docs/contribute/connectivity-diagnosis/architecture#包netstack","content":"与Linux网络栈相关的组件和实用工具。包括Router、Netfilter、IPTables等。 "},{"title":"关键数据结构​","type":1,"pageTitle":"架构","url":"/zh/docs/contribute/connectivity-diagnosis/architecture#关键数据结构","content":""},{"title":"Context​","type":1,"pageTitle":"架构","url":"/zh/docs/contribute/connectivity-diagnosis/architecture#context","content":"type Context struct { Ctx *sync.Map }  Context 用于存储运行时配置。除此之外，它同时负责为各个模块绑定其所需的命令行参数，以及提供模块注册用的接口。 "},{"title":"Endpoint​","type":1,"pageTitle":"架构","url":"/zh/docs/contribute/connectivity-diagnosis/architecture#endpoint","content":"type Endpoint struct { IP string Type EndpointType Port uint16 }  网络层面的端点，包括IP、Port、和Type。 "},{"title":"Packet​","type":1,"pageTitle":"架构","url":"/zh/docs/contribute/connectivity-diagnosis/architecture#packet","content":"type Packet struct { Src net.IP Sport uint16 Dst net.IP Dport uint16 Protocol Protocol Encap *Packet Mark uint32 }  一个数据包。 Encap: 如果是一个被封装过的数据包（比如IPIP数据包），被封装的真实数据包储存于该字段。 Mark: 用于路由以及iptables模拟。 "},{"title":"NetNode​","type":1,"pageTitle":"架构","url":"/zh/docs/contribute/connectivity-diagnosis/architecture#netnode","content":"type NetNode struct { Type NetNodeType ID string Actions map[*Link]*Action Suspicions []Suspicion initiative *Action }  网络链路图中的节点。它可以是Kubernets中的Pod或Node，也可以是云上的网络资源等。NetNode实现了NetNodeAction接口来处理网络流量，以及Assertion接口用来在节点上储存断言信息。 "},{"title":"Transmission​","type":1,"pageTitle":"架构","url":"/zh/docs/contribute/connectivity-diagnosis/architecture#transmission","content":"type Transmission struct { NextHop Hop Link *Link }  NetNode上Send()或者Receive()动作创建出的一次传输请求。其中包括指向下一个NetNode的NetHop，以及描述了本次传输信息的Link。 "},{"title":"Hop​","type":1,"pageTitle":"架构","url":"/zh/docs/contribute/connectivity-diagnosis/architecture#hop","content":"type Hop struct { Type NetNodeType ID string }  某一跳的信息，用于定位到某个NetNode。 "},{"title":"Link​","type":1,"pageTitle":"架构","url":"/zh/docs/contribute/connectivity-diagnosis/architecture#link","content":"type Link struct { Type LinkType Source NetNodeAction Destination NetNodeAction Packet *Packet SourceAttribute LinkAttribute DestinationAttribute LinkAttribute Level int // for print } type LinkAttribute interface { GetAttrs() map[string]string }  两个节点之间的传输链路。 Type: 包括 external, vpc, veth, ipvlan, local等。 SourceAttribute&amp;DestinationAttribute: 在源节点和目的节点上，用于描述该条链路信息的键值对。 "},{"title":"k8s.Pod​","type":1,"pageTitle":"架构","url":"/zh/docs/contribute/connectivity-diagnosis/architecture#k8spod","content":"type PodMeta struct { Namespace string PodName string NodeName string HostNetwork bool } type Pod struct { model.NetNode netstack.NetNS PodMeta }  Kubernetes上的Pod信息。包括Pod的元数据和网络栈数据。 "},{"title":"k8s.NodeInfo​","type":1,"pageTitle":"架构","url":"/zh/docs/contribute/connectivity-diagnosis/architecture#k8snodeinfo","content":"type NodeInfo struct { netstack.NetNS SubNetNSInfo []netstack.NetNSInfo NodeMeta } type NodeNetworkStackDump struct { Pods []PodNetInfo `json:&quot;pods&quot;` Netns []netstack.NetNSInfo `json:&quot;netns&quot;` } type NodeMeta struct { NodeName string }  Kubernetes上的Node信息。包括Node的元数据，Node和Node上Pod的网络栈数据。 "},{"title":"Suspicion​","type":1,"pageTitle":"架构","url":"/zh/docs/contribute/connectivity-diagnosis/architecture#suspicion","content":"type Suspicion struct { Level SuspicionLevel Message string }  在 NetNode上出现的问题。 Level: 问题的严重程度。包括Info、Warning、Critical 和 Fatal。 Message: 问题描述。 "},{"title":"扩展KubeSkoop","type":0,"sectionRef":"#","url":"/zh/docs/contribute/extend-kubeskoop","content":"","keywords":""},{"title":"扩展KubeSkoop连通性诊断​","type":1,"pageTitle":"扩展KubeSkoop","url":"/zh/docs/contribute/extend-kubeskoop#扩展kubeskoop连通性诊断","content":"关键的组件和数据结构可以查看架构文档。 如果您想要为诊断添加新的插件或云厂商支持，可以参考添加新插件或添加新云提供商文档。 "},{"title":"扩展KubeSkoop深度网络监控​","type":1,"pageTitle":"扩展KubeSkoop","url":"/zh/docs/contribute/extend-kubeskoop#扩展kubeskoop深度网络监控","content":""},{"title":"添加新云提供商","type":0,"sectionRef":"#","url":"/zh/docs/contribute/connectivity-diagnosis/new-cloud-provider","content":"","keywords":""},{"title":"实现InfraShim​","type":1,"pageTitle":"添加新云提供商","url":"/zh/docs/contribute/connectivity-diagnosis/new-cloud-provider#实现infrashim","content":"InfraShim用于对底层基础设施网络进行配置检查。 type InfraShim interface { NodeToNode(src *v1.Node, oif string, dst *v1.Node, packet *model.Packet) ([]model.Suspicion, error) NodeToExternal(src *v1.Node, oif string, packet *model.Packet) ([]model.Suspicion, error) }  NodeToNode(): 在两个节点之间进行数据传输。接受Kubernetes *v1.Node 用于源和目的、出网络接口名称以及*model.Pakcet作为参数，返回[]model.Suspicion作为结果。 NodeToExternal() : 在节点和外部网络（如互联网）之间进行数据传输。接受Kubernetes *v1.Node用于源、出网络接口名称以及*model.Packet作为参数，返回[]model.Suspicions作为结果。 InfraShim需要检查数据包是否能够在底层网络中到达其目的地址。如一个内网但是在集群外的地址应当检查路由或安全组配置；一个公网地址应当检查NAT是否配置正确。 InfraShim实现应当放在pkg/skoop/network/&lt;提供商名称&gt;下。 "},{"title":"实现Network​","type":1,"pageTitle":"添加新云提供商","url":"/zh/docs/contribute/connectivity-diagnosis/new-cloud-provider#实现network","content":"Network也位于pkg/skoop/network/&lt;提供商名称&gt;下。它的实现也是云提供商以及插件特定的，所以你需要为你支持的插件实现自己的Network。 type Network interface { Diagnose(ctx *ctx.Context, src model.Endpoint, dst model.Endpoint) ([]model.Suspicion, *model.PacketPath, error) }  Diagnose(): 接受 *ctx.Context，*model.Endpoint类型的源和目的地址作为参数，返回[]model.Suspicion和*model.PacketPath作为结果。 Network应当对诊断过程中所需需要的所有资源进行配置，包括Plugin、Diagnostor、InfraShim等。 "},{"title":"添加新的Provider​","type":1,"pageTitle":"添加新云提供商","url":"/zh/docs/contribute/connectivity-diagnosis/new-cloud-provider#添加新的provider","content":"Provider位于pkg/skoop/provider。 type Provider interface { CreateNetwork(ctx *ctx.Context) (network.Network, error) }  CreateNetwork(): 接受 *ctx.Context作为参数，返回network.Network。 Provider的实现过程很简单：检查网络插件类型，并为其创建对应的Network。 type genericProvider struct { } func (g genericProvider) CreateNetwork(ctx *context.Context) (network.Network, error) { switch ctx.ClusterConfig().NetworkPlugin { case context.NetworkPluginFlannel: return generic.NewFlannelNetwork(ctx) case context.NetworkPluginCalico: return generic.NewCalicoNetwork(ctx) default: return nil, fmt.Errorf(&quot;not support cni type %q&quot;, ctx.ClusterConfig().NetworkPlugin) } }  你需要在pkg/skoop/provider/&lt;提供商名称&gt;.go中实现你的Provider。 之后，需要为新的提供商类型添加一个常量，位于pkg/skoop/provider/provider.go。 const ( providerNameGeneric = &quot;generic&quot; providerNameAliyun = &quot;aliyun&quot; // 在此处添加新的提供商名称 )  这个常量的值也会在命令行参数中被使用。 最后，把你的实现添加到providers中。 var providers = map[string]Provider{ providerNameGeneric: genericProvider{}, providerNameAliyun: aliyunProvider{}, // 添加新的提供商 }  "},{"title":"云提供商所使用的其它组件​","type":1,"pageTitle":"添加新云提供商","url":"/zh/docs/contribute/connectivity-diagnosis/new-cloud-provider#云提供商所使用的其它组件","content":"云提供商相关的组件放在pkg/skoop/infra/&lt;提供商名称&gt;下，比如配置或是云客户端。 如果你想为你的插件添加命令行参数，你应当实现ConfigBinder接口并将其注册到程序中。如pkg/skoop/infra/aliyun/config.go中的实现： type ProviderConfig struct { AccessKeyID string AccessKeySecret string SecurityToken string } var Config = &amp;ProviderConfig{} func init() { context.RegisterConfigBinder(&quot;Aliyun provider&quot;, Config) } func (pc *ProviderConfig) BindFlags(fs *pflag.FlagSet) { fs.StringVarP(&amp;pc.AccessKeyID, &quot;aliyun-access-key-id&quot;, &quot;&quot;, &quot;&quot;, &quot;Aliyun access key.&quot;) fs.StringVarP(&amp;pc.AccessKeySecret, &quot;aliyun-access-key-secret&quot;, &quot;&quot;, &quot;&quot;, &quot;Aliyun access secret.&quot;) fs.StringVarP(&amp;pc.SecurityToken, &quot;aliyun-security-token&quot;, &quot;&quot;, &quot;&quot;, &quot;Aliyun security token (optional).&quot;) } func (pc *ProviderConfig) Validate() error { return nil }  "},{"title":"安装要求","type":0,"sectionRef":"#","url":"/zh/docs/getting-started/requirements","content":"","keywords":""},{"title":"网络连通性诊断​","type":1,"pageTitle":"安装要求","url":"/zh/docs/getting-started/requirements#网络连通性诊断","content":"网络连通性诊断功能依赖于该网络插件已被实现，你可以在这里查看到目前所支持的网络插件列表。 若要同时进行云上配置的诊断，你可以在这里找到已实现的云提供商列表。 "},{"title":"内核版本需求​","type":1,"pageTitle":"安装要求","url":"/zh/docs/getting-started/requirements#内核版本需求","content":"KubeSkoop使用eBPF技术作为观测能力的核心实现。因此，在使用KubeSkoop的网络监控能力时，要求Kubernetes集群节点的内核版本应为4.9.17及以上。 "},{"title":"简介","type":0,"sectionRef":"#","url":"/zh/docs/guide/connectivity-diagnosis/intro","content":"","keywords":""},{"title":"工作原理​","type":1,"pageTitle":"简介","url":"/zh/docs/guide/connectivity-diagnosis/intro#工作原理","content":"KubeSkoop连通性诊断根据集群中所使用的插件和所使用的云供应商，构造从源地址到目的地址的链路图，并且对节点进行网络信息的采集（如iptables规则、网络设备信息、sysctls等）。 在构造链路的过程中，会对图中的节点和边的信息进行校验和模拟。若预期情况与实际情况不符，则认为网络配置错误。 "},{"title":"使用连通性诊断​","type":1,"pageTitle":"简介","url":"/zh/docs/guide/connectivity-diagnosis/intro#使用连通性诊断","content":""},{"title":"通过Web控制台​","type":1,"pageTitle":"简介","url":"/zh/docs/guide/connectivity-diagnosis/intro#通过web控制台","content":"可以通过Web控制台对集群内网络发起连通性诊断。  在 Diagnosis - Connectivity Diagnosis 下输入诊断的源地址、目的地址、端口和协议，点击Diagnose 发起诊断。诊断完成后，可以在列表中看到诊断结果。  在诊断链路图中，你可以通过点击节点和边来查看详细信息和发现的问题。  "},{"title":"通过命令行​","type":1,"pageTitle":"简介","url":"/zh/docs/guide/connectivity-diagnosis/intro#通过命令行","content":"请见通过命令行诊断。 "},{"title":"使用限制​","type":1,"pageTitle":"简介","url":"/zh/docs/guide/connectivity-diagnosis/intro#使用限制","content":"网络连通性诊断功能依赖于该网络插件已被实现，你可以在这里查看到目前所支持的网络插件列表。 若要同时进行云上配置的诊断，你可以在这里找到已实现的云提供商列表。 "},{"title":"安装","type":0,"sectionRef":"#","url":"/zh/docs/getting-started/installation","content":"","keywords":""},{"title":"通过Helm安装​","type":1,"pageTitle":"安装","url":"/zh/docs/getting-started/installation#通过helm安装","content":"你可以通过Helm来安装生产可用的KubeSkoop实例。 执行以下命令，将KubeSkoop仓库添加到Helm中并安装KubeSkoop： # 添加kubeskoop repo helm repo add kubeskoop https://kubeskoop.io/ # 更新helm repo helm repo update # 安装kubeskoop helm install -n kubeskoop kubeskoop kubeskoop/kubeskoop  该命令将会将KubeSkoop安装至kubeskoop命名空间，并默认开启KubeSkoop的agent、controller和webconsole组件。 "},{"title":"自定义配置​","type":1,"pageTitle":"安装","url":"/zh/docs/getting-started/installation#自定义配置","content":"你可以执行以下命令查看helm chart中可以配置的值。 helm show values kubeskoop/kubeskoop  你可以将值保存至values.yaml文件中，对你需要的参数进行修改，然后进行KubeSkoop的安装。 # 若你已经安装了KubeSkoop，你可以通过`helm upgrade`命令对其进行更新。 helm install -f values.yaml -n kubeskoop kubeskoop kubeskoop/kubeskoop  你也可以使用--set来进行简单的配置。 helm install --set controller.config.prometheusEndpoint=http://prometheus -n kubeskoop kubeskoop kubeskoop/kubeskoop  "},{"title":"配置探针​","type":1,"pageTitle":"安装","url":"/zh/docs/getting-started/installation#配置探针","content":"在配置中的config一节，可以对所需开启的指标/事件探针进行配置。默认配置如下： config: metricProbes: - name: conntrack - name: qdisc - name: netdev - name: io - name: sock - name: tcpsummary - name: tcp - name: tcpext - name: udp - name: kernellatency - name: packetloss - name: flow args: enablePortInLabel: false - name: tcpretrans eventProbes: - name: biolatency - name: kernellatency - name: packetloss args: enableStack: false - name: tcpreset - name: tcpretrans eventSinks: - name: stderr  关于探针的更多信息，请见文档。 "},{"title":"配置Prometheus和Loki端点地址​","type":1,"pageTitle":"安装","url":"/zh/docs/getting-started/installation#配置prometheus和loki端点地址","content":"Web控制台的部分功能（如网络链路图、异常事件）依赖Prometheus和Loki。你需要在Helm安装时提供Prometheus和Loki服务的端点地址。 提示 若没有已经就绪的Prometheus或Loki实例，可以参考以下文档： 参考 Prometheus的安装 完成Prometheus的部署安装。参考 使用Helm安装Loki 完成Loki的部署安装。 在controller.config一节中配置prometheusEndpoint和lokiEndpoint。 假设Prometheus和Loki安装在monitoring命名空间，并且service名称分别为prometheus和loki，示例配置如下： controller: enabled: true config: # 配置prometheus的端点地址。 prometheusEndpoint: 'http://prometheus.monitoring:9090' # 配置loki的端点地址。 lokiEndpoint: 'http://loki.monitoring:3100'  同时，需要在config.eventSink中配置事件收集器，使事件能够通过Loki收集。 config: # ...其它探针配置 eventSinks: - name: stderr # 配置loki事件收集器，并指定地址为loki的service地址。 - name: loki args: addr: 'http://loki.monitoring:3100'  最后，通过helm install或者helm upgrade对KubeSkoop进行安装/更新。 "},{"title":"配置","type":0,"sectionRef":"#","url":"/zh/docs/guide/configuration","content":"","keywords":""},{"title":"配置热加载​","type":1,"pageTitle":"配置","url":"/zh/docs/guide/configuration#配置热加载","content":"KubeSkoop agent支持配置热加载，即在配置发生变更时，KubeSkoop会自动重新加载配置。 "},{"title":"延迟探测","type":0,"sectionRef":"#","url":"/zh/docs/guide/latency-detection","content":"","keywords":""},{"title":"发起延迟探测​","type":1,"pageTitle":"延迟探测","url":"/zh/docs/guide/latency-detection#发起延迟探测","content":""},{"title":"添加目标​","type":1,"pageTitle":"延迟探测","url":"/zh/docs/guide/latency-detection#添加目标","content":"通过点击Targets的Add按钮，可以通过选择器添加抓包目标。  在Add Target窗口中，你可以添加节点或者Pod作为抓包目标。你可以根据命名空间&amp;名称选择单个Pod/Node，或是根据标签同时选择多个。 "},{"title":"查看结果​","type":1,"pageTitle":"延迟探测","url":"/zh/docs/guide/latency-detection#查看结果","content":"延迟探测任务运行结束后，将会在Result中展示链路图。  链路图中，你可以通过节点之间连线的颜色来判断节点间的连接状态，连线上也会展示节点间的平均延迟。你也可以将鼠标悬停在连接上，查看连接的详细信息。 "},{"title":"使用命令行诊断","type":0,"sectionRef":"#","url":"/zh/docs/guide/connectivity-diagnosis/use-cli","content":"","keywords":""},{"title":"安装​","type":1,"pageTitle":"使用命令行诊断","url":"/zh/docs/guide/connectivity-diagnosis/use-cli#安装","content":"你可以通过go install安装KubeSkoop连通性诊断工具。 go install github.com/alibaba/kubeskoop/cmd/skoop@main  安装完成后，可以通过输入skoop --help来确认是否安装成功。 提示 若在go install安装完成后仍无法执行skoop命令，请检查PATH环境变量中是否包含了go install安装的路径（一般为$GOPATH/bin或$HOME/go/bin）。 你也可以使用Docker镜像，直接运行skoop诊断程序。 docker run --rm -it kubeskoop/kubeskoop:latest skoop --help  "},{"title":"发起诊断​","type":1,"pageTitle":"使用命令行诊断","url":"/zh/docs/guide/connectivity-diagnosis/use-cli#发起诊断","content":"执行以下命令，发起从172.18.0.4到10.96.0.10，80端口，TCP协议（默认）的连通性诊断。 skoop -s 172.18.0.4 -d 10.96.0.10 -p 80  诊断完成后，本次诊断的链路以及发现的问题将会输出到屏幕上。 $ skoop -s 172.18.0.4 -d 10.96.0.10 -p 53 Packet path: &quot;default/netshoot-6bddd57fb7-49q9s&quot; -&gt; &quot;node1&quot; [label=&quot;type=veth,level=0,trans=service,oif=eth0,iif=cni0,src=172.18.0.4,dst=10.96.0.10,dport=53&quot;] &quot;node1&quot; -&gt; &quot;kube-system/coredns-547b98dbcc-dxmnl&quot; [label=&quot;type=veth,level=1,trans=serve,oif=cni0,iif=eth0,src=172.18.0.4,dst=172.18.0.2,dport=53&quot;,arrowhead=&quot;dot&quot;] &quot;node1&quot; -&gt; &quot;node2&quot; [label=&quot;type=infra,level=1,trans=forward,oif=eth0,iif=eth0,src=172.18.0.4,dst=172.18.0.69,dport=53&quot;] &quot;node2&quot; -&gt; &quot;kube-system/coredns-547b98dbcc-zr2zl&quot; [label=&quot;type=veth,level=2,trans=serve,oif=cni0,iif=eth0,src=172.18.0.4,dst=172.18.0.69,dport=53&quot;,arrowhead=&quot;dot&quot;] Suspicions on node &quot;kube-system/coredns-547b98dbcc-zr2zl&quot; [FATAL] no process listening on 0.0.0.0:80 or 172.18.0.69:80 protocol tcp  "},{"title":"通过Web查看诊断结果​","type":1,"pageTitle":"使用命令行诊断","url":"/zh/docs/guide/connectivity-diagnosis/use-cli#通过web查看诊断结果","content":"可以通过在诊断时加入--http参数来启用HTTP服务器，用于交互式地查看诊断结果。 当使用--http参数时，在诊断完成后，会在指定地址上启动HTTP服务器接受请求，你可以通过打开该地址来查看本次诊断的链路图以及最终结果。 $ skoop -s 172.18.0.4 -d 10.96.0.10 -p 53 --http I0118 11:43:23.383446 6280 web.go:97] HTTP server listening on http://127.0.0.1:8080  服务器默认在127.0.0.1:8080上启动，你也可以通过--http-address参数指定地址。 提示 若您在Docker或远程服务器上运行诊断，您可能需要将--http-address设置为0.0.0.0:8080以便远程地址访问。以Docker为例： docker run -p 8080:8080 -v ~/.kube:/root/.kube kubeskoop/kubeskoop:latest skoop -s 172.18.0.4 -d 10.96.0.10 -p 80 --http --http-address=0.0.0.0:8080  通过浏览器打开http://127.0.0.1:8080后，可以看到诊断结果：  "},{"title":"输出格式​","type":1,"pageTitle":"使用命令行诊断","url":"/zh/docs/guide/connectivity-diagnosis/use-cli#输出格式","content":"你可以通过--format参数来指定输出格式。 若没有指定任何格式，诊断结束后，默认将会在标准输出中输出简单链路信息和诊断结果。 当前支持d2、svg、json输出。 除此之外，你也可以使用--output来指定输出文件名（默认为result.d2/svg/json），可以指定为-表示输出到标准输出。 "},{"title":"d2​","type":1,"pageTitle":"使用命令行诊断","url":"/zh/docs/guide/connectivity-diagnosis/use-cli#d2","content":"输出格式为d2。关于d2语法格式的更多说明，请见文档。 该输出格式仅包含生成的链路信息，不携带诊断结果。 "},{"title":"svg​","type":1,"pageTitle":"使用命令行诊断","url":"/zh/docs/guide/connectivity-diagnosis/use-cli#svg","content":"输出格式为svg，通过d2文件生成。 该输出格式仅包含生成的链路信息，不携带诊断结果。 "},{"title":"json​","type":1,"pageTitle":"使用命令行诊断","url":"/zh/docs/guide/connectivity-diagnosis/use-cli#json","content":"输出格式为json。json中包含链路图中的节点和边的详细信息，以及集群中的诊断结果。 "},{"title":"指定云供应商​","type":1,"pageTitle":"使用命令行诊断","url":"/zh/docs/guide/connectivity-diagnosis/use-cli#指定云供应商","content":"KubeSkoop支持在诊断时指定云供应商，以提供云上资源配置的校验。 通过--cloud-provider参数指定云供应商后。连通性诊断将会对云上资源配置进行校验，如VM安全组、路由表、NAT等。 支持的云供应商以及需要的额外参数，请参见文档 "},{"title":"更多命令行参数​","type":1,"pageTitle":"使用命令行诊断","url":"/zh/docs/guide/connectivity-diagnosis/use-cli#更多命令行参数","content":"你可以使用--help参数来查看其余参数和它们的用法，或见文档。 "},{"title":"可视化配置","type":0,"sectionRef":"#","url":"/zh/docs/guide/monitoring/visualization","content":"","keywords":""},{"title":"使用 Prometheus & Grafana 进行指标的可视化​","type":1,"pageTitle":"可视化配置","url":"/zh/docs/guide/monitoring/visualization#使用-prometheus--grafana-进行指标的可视化","content":"KubeSkoop提供了标准的Prometheus格式的指标输出服务，您可以快速将KubeSkoop的监控信息集成到已有的监控系统中。 提示 若没有已经就绪的监控服务，可以参考以下文档： 参考 Prometheus 的安装 完成Prometheus的部署安装。参考 Grafana 的安装 完成Grafana的安装并配置与Prometheus的连接。 "},{"title":"配置KubeSkoop指标监控​","type":1,"pageTitle":"可视化配置","url":"/zh/docs/guide/monitoring/visualization#配置kubeskoop指标监控","content":"KubeSkoop支持运行在kubernetes中的prometheus的服务发现功能，在安装完成prometheus之后，可以通过Status-&gt;Targets页面，在搜索栏中输入skoop-exporter，查看已经就绪的实例:  在KubeSkoop实例被prometheus正常捕获后，可以通过以下步骤完成指标的可视化操作： 进入Grafana的控制台，点击Configuration-&gt;Data sources-&gt;Add data source后选择Prometheus，将已经就绪的prometheus实例的地址添加到Grafana的数据源订阅中:新建一个大盘，或者在已有大盘中选择新建一个面板，在面板的配置中选取数据源为1中配置的数据源，并在Metric browser中输入inspector，即可看到联想后的KubeSkoop指标，选取其中需要的信息，以inspector_pod_netdevrxbytes为例，输入完成后，可以在面板中看到获取到的数据。在指标的可视化中，可以根据需要设置指标的图例和单位等信息，其中，图例支持配置Pod的Namespace，ip，label等信息，在面板的Legend中可以配置这些支持的图例。 "},{"title":"导入预定义默认大盘​","type":1,"pageTitle":"可视化配置","url":"/zh/docs/guide/monitoring/visualization#导入预定义默认大盘","content":"KubeSkoop提供跟随版本更新的默认Grafana大盘配置文件: curl https://raw.githubusercontent.com/alibaba/kubeskoop/main/deploy/resource/kubeskoop-exporter-dashboard.json -o dashboard.json  登陆Grafana控制台后，点击Dashboards-&gt;Import-&gt;Upload JSON file，选择保存好的文件上传后，选取prometheus作为数据源，点击Import导入，即可查看到默认大盘。通过选取不同的面板组，可以查看到不同类别的监控指标信息:  "},{"title":"使用 Grafana & Loki 查看可视化的网络事件​","type":1,"pageTitle":"可视化配置","url":"/zh/docs/guide/monitoring/visualization#使用-grafana--loki-查看可视化的网络事件","content":""},{"title":"安装 Grafana Loki​","type":1,"pageTitle":"可视化配置","url":"/zh/docs/guide/monitoring/visualization#安装-grafana-loki","content":"按照官方文档进行不同场景下的 Grafana Loki的安装。 安装完成后，可以通过以下方式检查Grafana Loki的可用性: curl http://[Grafana Loki实例的地址]:3100/ready  "},{"title":"配置事件流​","type":1,"pageTitle":"可视化配置","url":"/zh/docs/guide/monitoring/visualization#配置事件流","content":"通过Grafana​ 通过Grafana可以将KubeSkoop推送到Grafana Loki的事件进行可视化，通过以下步骤可以实现实现可视化操作： 点击Configuration-&gt;Data sources-&gt;Add data source后选择Loki，将Grafana Loki服务的地址添加到Grafana的数据源订阅中，可以是ip地址和域名，默认端口为3100：新建一个大盘，或者在已有大盘中选择新建一个面板，在面板的配置中选取数据源为1中配置的数据源，并在Label browser中过滤需要的事件信息：在事件面板中，可以通过LogQL查询特定的事件，点击事件后，可以看到详细的现场信息: "},{"title":"简介","type":0,"sectionRef":"#","url":"/zh/docs/guide/monitoring/intro","content":"","keywords":""},{"title":"概述​","type":1,"pageTitle":"简介","url":"/zh/docs/guide/monitoring/intro#概述","content":"KubeSkoop网络监控提供了以下能力： 针对Pod级别的网络监控，包括流量，应用层连接信息，socket内存分配状态等针对Pod级别的网络异常状态的指标监控，例如Pod内进程对socket进行读写操作的等待时间超过100ms的次数，Pod发出TCP rst报文的次数等针对Pod级别的网络异常事件的现场，提供事件发生的详细信息的观测，例如内核网络软中断调度等待过久，UDP出现socket内存不足导致的溢出等 与常见的Kubernetes监控和可观测性工具的主要区别如下： 功能选项\tPrometheus Node exporter\tcAdvisor/Metric API\tKubeSkoop按照Pod区分\tNo\tYes\tYes 网络状态监控\tYes\tNo\tYes 异常事件的现场捕获\tNo\tNo\tYes 内核网络高阶信息\tNo\tYes\tYes "},{"title":"核心原理​","type":1,"pageTitle":"简介","url":"/zh/docs/guide/monitoring/intro#核心原理","content":""},{"title":"架构​","type":1,"pageTitle":"简介","url":"/zh/docs/guide/monitoring/intro#架构","content":" "},{"title":"信息采集​","type":1,"pageTitle":"简介","url":"/zh/docs/guide/monitoring/intro#信息采集","content":"KubeSkoop提供了适配于Kubernetes网络监控功能，在节点上，KubeSkoop采集并归类了网络相关的大量数据，实现这些功能的核心原理包括: 通过CRI接口和Linux /proc/获取节点内的网络隔离状态及其与Pod的关联信息通过Linux /proc/，Linux netlink和eBPF获取网络监控信息通过eBPF获取操作系统内核在网络异常事件发生时的上下文状态 "},{"title":"聚合分析​","type":1,"pageTitle":"简介","url":"/zh/docs/guide/monitoring/intro#聚合分析","content":"KubeSkoop采集的数据可以通过多种方式获取，包括: 通过Prometheus获取监控信息，并使用Grafana进行可视化操作通过配置Grafana Loki接收KubeSkoop的事件推送，并使用Grafana进行可视化操作使用kubeskoop inspector命令行工具观察监控信息 关于如何将监控数据进行可视化，请参考可视化配置 "},{"title":"指标​","type":1,"pageTitle":"简介","url":"/zh/docs/guide/monitoring/intro#指标","content":"KubeSkoop提供Pod级别的指标信息，反应实例运行过程中的环境变化，通过Prometheus metrics暴露。 "},{"title":"异常事件​","type":1,"pageTitle":"简介","url":"/zh/docs/guide/monitoring/intro#异常事件","content":"KubeSkoop提供节点上发生的网络相关的异常事件，根据在长期处理网络问题中的经验，我们归纳了几种常见的网络疑难问题，他们往往在集群中以无法复现，偶然发生的方式干扰正常的业务，缺乏有效的定位手段，其中部分如下： 网络数据报文被丢弃引发的连接失败，响应超时等问题。网络数据处理耗时久引发的偶发性能问题。TCP，conntrack等状态机制异常引发的业务异常问题。 针对无法快速复现和难以获取现场的网络问题，KubeSkoop提供了基于eBPF的操作系统内核上下文观测能力，在问题发生的现场捕获操作系统的实时状态，以事件日志的方式输出。 在事件日志的信息中，可以查看到事件现场的相关信息，以tcp_reset探针为例，当出现有Pod收到了一个访问为止端口的正常报文时，KubeSkoop会捕获以下事件信息: type=TCPRESET_NOSOCK pod=storage-monitor-5775dfdc77-fj767 namespace=kube-system protocol=TCP saddr=100.103.42.233 sport=443 daddr=10.1.17.188 dport=33488  事件中的信息如下： type表明出现了一次TCPRESET_NOSOCK类型的事件，这是tcpreset探针捕获的一种事件，他表明有访问为止端口的报文被本地发送RST报文拒绝，拒绝的原因是没有根据报文找到相应的socket，通常在NAT失效，如ipvs定时器超时等原因发生后，会伴随这个事件。pod/namespace是KubeSkoop根据发送报文的网络命名空间，ip地址和网络设备序号进行匹配后关联给事件的Pod元信息。saddr/sport/daddr/dport是KubeSkoop在内核获取到的异常报文的信息，随着事件的不同，这部分信息也会有差异，例如net_softirq探针的事件信息中没有ip地址，取而代之的是中断发生的CPU序号，产生的延迟时长等。 对于需要有效的操作系统内核堆栈信息的事件，可以通过配置开关来额外获取操作系统内核的协议栈信息，这会增加一定的消耗，从而获取到更加精准的现象，例如： type=PACKETLOSS pod=hostNetwork namespace=hostNetwork protocol=TCP saddr=10.1.17.172 sport=6443 daddr=10.1.17.176 dport=43018 stacktrace:skb_release_data+0xA3 __kfree_skb+0xE tcp_recvmsg+0x61D inet_recvmsg+0x58 sock_read_iter+0x92 new_sync_read+0xE8 vfs_read+0x89 ksys_read+0x5A  信息 关于支持的探针、指标和事件的列表，请见探针，指标和事件。 "},{"title":"添加新插件","type":0,"sectionRef":"#","url":"/zh/docs/contribute/connectivity-diagnosis/new-plugin","content":"","keywords":""},{"title":"实现 Plugin​","type":1,"pageTitle":"添加新插件","url":"/zh/docs/contribute/connectivity-diagnosis/new-plugin#实现-plugin","content":"所有插件的实现都位于pkg/skoop/plugin。 插件应当实现Plugin接口。 type Plugin interface { CreatePod(pod *k8s.Pod) (model.NetNodeAction, error) CreateNode(node *k8s.NodeInfo) (model.NetNodeAction, error) }  CreatePod(): 接受*k8s.Pod作为参数，创建对应的Pod实现，作为NetNodeAction类型返回。 CreateNode(): 接受*k8s.NodeInfo作为参数，创建对应的Node实现，作为NetNodeAction返回。 你应当根据你的插件，为Pod和Node提供相应的实现。 NetNodeAction的定义如下： type NetNodeAction interface { Send(dst Endpoint, protocol Protocol) ([]Transmission, error) Receive(upstream *Link) ([]Transmission, error) }  Send()代表从节点上发送一个数据包。接受目的端点以及协议作为参数，并返回[]Transsmision作为结果。Receive()代表在节点上接受一个数据包。接受*Link类型的上游作为参数，并返回[]Transsmision作为结果。 使用veth网卡对作为Pod的网络接口是一种很常见的情况。在这种情况下，你可以通过调用newSimpleVethPod()，直接使用simpleVethPod作为Pod的实现。比如： func (f *flannelPlugin) CreatePod(pod *k8s.Pod) (model.NetNodeAction, error) { return newSimpleVEthPod(pod, f.ipCache, f.podMTU, &quot;eth0&quot;) }  对于Node的实现，你可能需要判断网络端点的类型（Pod、Node、Service还是External）。通常来说，你可以直接使用BasePluginNode作为NetNodeAction的实现，并且实现SimplePluginNode接口。 type SimplePluginNode interface { ToPod(upstream *model.Link, dst model.Endpoint, protocol model.Protocol, pod *v1.Pod) ([]model.Transmission, error) ToHost(upstream *model.Link, dst model.Endpoint, protocol model.Protocol, node *v1.Node) ([]model.Transmission, error) ToService(upstream *model.Link, dst model.Endpoint, protocol model.Protocol, service *v1.Service) ([]model.Transmission, error) ToExternal(upstream *model.Link, dst model.Endpoint, protocol model.Protocol) ([]model.Transmission, error) Serve(upstream *model.Link, dst model.Endpoint, protocol model.Protocol) ([]model.Transmission, error) }  SimplePluginNode已经根据端点类型对动作进行了分类。以Flannel插件的实现举例： func (f *flannelPlugin) CreateNode(node *k8s.NodeInfo) (model.NetNodeAction, error) { flannelHost, err := newFlannelHost(f.ipCache, node, f.infraShim, f.serviceProcessor, f.hostOptions) if err != nil { return nil, err } return &amp;BasePluginNode{ NetNode: flannelHost.netNode, IPCache: f.ipCache, SimplePluginNode: flannelHost, }, nil }  在实现过程中，你可能会用到IPCache或NetsatckAssertion等工具来帮助你获得某个资源的信息，或是检查网络配置是否正确。关于此的详细信息，你可以参考Flannel插件的的实现，位于pkg/skoop/plugin/flannel.go。 如果你需要为你的插件添加命令行参数，你需要实现ConfigBinder，并将其注册到程序中。 type CalicoConfig struct { PodMTU int IPIPPodMTU int Interface string } func (c *CalicoConfig) BindFlags(fs *pflag.FlagSet) { fs.StringVarP(&amp;c.Interface, &quot;calico-host-interface&quot;, &quot;&quot;, &quot;eth0&quot;, &quot;Host interface for calico plugin.&quot;) fs.IntVarP(&amp;c.PodMTU, &quot;calico-pod-mtu&quot;, &quot;&quot;, 1500, &quot;Pod MTU for calico plugin. Pod interface MTU in BGP mode.&quot;) fs.IntVarP(&amp;c.IPIPPodMTU, &quot;calico-ipip-pod-mtu&quot;, &quot;&quot;, 1480, &quot;Pod MTU for calico plugin. Pod interface MTU in IPIP mode.&quot;) } func (c *CalicoConfig) Validate() error { return nil } var Calico = &amp;CalicoConfig{} func init() { ctx.RegisterConfigBinder(&quot;Calico plugin&quot;, Calico) }  "},{"title":"实现 Network​","type":1,"pageTitle":"添加新插件","url":"/zh/docs/contribute/connectivity-diagnosis/new-plugin#实现-network","content":"Network 位于pkg/skoop/network中。 type Network interface { Diagnose(ctx *ctx.Context, src model.Endpoint, dst model.Endpoint) ([]model.Suspicion, *model.PacketPath, error) }  Diagnose(): 接受*ctx.Context、*model.Endpoint类型的源和目的地址，返回 []model.Suspicion 和*model.PacketPath作为返回值。 Network是云提供商特定的，特定的实现位于pkg/skoop/network/&lt;提供商名称&gt;/. 如果你的插件支持该提供商，你就需要为其添加Network的实现。网络类型generic代表任意云提供商，所以你至少为这个网络类型提供你的插件的Network实现。 Plugin、NetNodeManager、NetworkPolicy、service.Processor和Diagnostor会在Network创建时被配置好。如： func NewFlannelNetwork(ctx *ctx.Context) (network.Network, error) { serviceProcessor := service.NewKubeProxyServiceProcessor(ctx) plgn, err := plugin.NewFlannelPlugin(ctx, serviceProcessor, nil) if err != nil { return nil, err } collectorManager, err := manager.NewSimplePodCollectorManager(ctx) if err != nil { return nil, err } netNodeManager, err := nodemanager.NewNetNodeManager(ctx, plgn, collectorManager) if err != nil { return nil, err } networkPolicy, err := plugin.NewNetworkPolicy(false, false, ctx.ClusterConfig().IPCache, ctx.KubernetesClient(), serviceProcessor) if err != nil { return nil, err } diagnostor, err := skoop.NewDefaultDiagnostor(ctx, netNodeManager, networkPolicy) if err != nil { return nil, err } return &amp;flannelNetwork{ plugin: plgn, diagnostor: diagnostor, collectorManager: collectorManager, netNodeManager: netNodeManager, }, nil }  "},{"title":"添加新的插件类型并在Provider中创建​","type":1,"pageTitle":"添加新插件","url":"/zh/docs/contribute/connectivity-diagnosis/new-plugin#添加新的插件类型并在provider中创建","content":"插件类型的定义在pkg/skoop/context/cluster.go中。你应当在这里添加一个新的类型。 const ( NetworkPluginFlannel = &quot;flannel&quot; NetworkPluginCalico = &quot;calico&quot; NetworkPluginTerway = &quot;terway&quot; // 在这里添加新的插件类型 )  在这之后，你还需要为所支持的云提供商创建你的插件，文件位于pkg/skoop/provider/&lt;提供商名称&gt;.go。示例如下： func (g genericProvider) CreateNetwork(ctx *context.Context) (network.Network, error) { switch ctx.ClusterConfig().NetworkPlugin { case context.NetworkPluginFlannel: return generic.NewFlannelNetwork(ctx) case context.NetworkPluginCalico: return generic.NewCalicoNetwork(ctx) // add your plugin type default: return nil, fmt.Errorf(&quot;not support cni type %q&quot;, ctx.ClusterConfig().NetworkPlugin) } }  现在，你可以在命令行参数中指定--network plugin &lt;插件名&gt;来使用你的插件。 "},{"title":"添加插件自动探测​","type":1,"pageTitle":"添加新插件","url":"/zh/docs/contribute/connectivity-diagnosis/new-plugin#添加插件自动探测","content":"你可以在pkg/utils/k8s.go的DetectNetworkPlugin()文件中，通过遍历集群中的DaemonSet的方式来添加插件类型的自动探测。 func DetectNetworkPlugin(k8sCli *kubernetes.Clientset) (networkMode string, err error) { dss, err := k8sCli.AppsV1().DaemonSets(&quot;&quot;).List(context.Background(), metav1.ListOptions{}) if err != nil { return &quot;&quot;, err } for _, ds := range dss.Items { switch ds.Name { case &quot;kube-flannel-ds&quot;: return &quot;flannel&quot;, nil case &quot;calico-node&quot;: return &quot;calico&quot;, nil case &quot;terway-eniip&quot;: return &quot;terway-eniip&quot;, nil } } return &quot;&quot;, nil }  "},{"title":"添加e2e测试​","type":1,"pageTitle":"添加新插件","url":"/zh/docs/contribute/connectivity-diagnosis/new-plugin#添加e2e测试","content":"最后，你应当在test/skoop/e2e/testcase/plugins.go中添加插件相关的测试用例，并且将你的插件添加到test/skoop/e2e/testcase/testcases.go文件中。 "},{"title":"抓包","type":0,"sectionRef":"#","url":"/zh/docs/guide/packet-capturing","content":"","keywords":""},{"title":"发起抓包任务​","type":1,"pageTitle":"抓包","url":"/zh/docs/guide/packet-capturing#发起抓包任务","content":"发起抓包任务，需要填写抓包的目标、过滤表达式、抓包时间信息。在填写好相应的信息后，点击Submit Task按钮，发起抓包任务。 "},{"title":"添加目标​","type":1,"pageTitle":"抓包","url":"/zh/docs/guide/packet-capturing#添加目标","content":"通过点击Targets的Add按钮，可以通过选择器添加抓包目标。  在Add Target窗口中，你可以添加节点或者Pod作为抓包目标。你可以根据命名空间&amp;名称选择单个Pod/Node，或是根据标签同时选择多个。 在选择Pod作为目标时，通过勾选Also capture node packets，会同时将Pod所在的Node添加至抓包目标中。 "},{"title":"过滤包​","type":1,"pageTitle":"抓包","url":"/zh/docs/guide/packet-capturing#过滤包","content":"在Filter中，你可以添加过滤表达式，对抓包结果进行过滤。过滤表达式与tcpdump一致，使用Pcap filter语法。例如，想要抓取与IP地址10.0.1.0之间的通信流量，可以将表达式写为： host 10.0.1.0  若无需过滤，请将表达式留空。 "},{"title":"下载抓包结果​","type":1,"pageTitle":"抓包","url":"/zh/docs/guide/packet-capturing#下载抓包结果","content":"在抓包运行结束后，通过点击History中Result列的Download按钮，下载抓包结果至本地，并使用Wireshark等网络分析工具进行查看。 "},{"title":"简介","type":0,"sectionRef":"#","url":"/zh/docs/intro","content":"","keywords":""},{"title":"关键特性​","type":1,"pageTitle":"简介","url":"/zh/docs/intro#关键特性","content":""},{"title":"一键诊断网络链路​","type":1,"pageTitle":"简介","url":"/zh/docs/intro#一键诊断网络链路","content":"诊断kubernetes集群中各种网络访问方式和链路：Pod,Service,Node and Ingress/Egress Traffic.覆盖完整的Linux协议栈的配置错误场景: Socket,Bridge,Veth,Netfilter,sysctls…支持诊断多种云供应商的IaaS层网络错误配置 "},{"title":"深度网络监控​","type":1,"pageTitle":"简介","url":"/zh/docs/intro#深度网络监控","content":"通过eBPF实现无侵入的Kernel Monitor通过BTF在各种版本的Kernel上直接运行通过标准的Prometheus接口暴露深度监控Metrics "},{"title":"网络异常事件识别​","type":1,"pageTitle":"简介","url":"/zh/docs/intro#网络异常事件识别","content":"几十种网络异常场景自动分析识别通过Web Console或Grafana Loki展示网络异常事件 "},{"title":"用户友好的Web控制台​","type":1,"pageTitle":"简介","url":"/zh/docs/intro#用户友好的web控制台","content":"集成KubeSkoop所有能力，提供网络诊断、异常事件监控、抓包、延迟探测等功能。 "},{"title":"参与贡献​","type":1,"pageTitle":"简介","url":"/zh/docs/intro#参与贡献","content":"欢迎提交issue和PR来共建此项目！ 如果你想参与到KubeSkoop的开发中来，可以参考扩展KubeSkoop。 "},{"title":"联系​","type":1,"pageTitle":"简介","url":"/zh/docs/intro#联系","content":"钉钉群号（26720020148） "},{"title":"License​","type":1,"pageTitle":"简介","url":"/zh/docs/intro#license","content":"Most source code in KubeSkoop which running on userspace are licensed under the Apache License, Version 2.0. The BPF code in /bpf directory are licensed under the GPL v2.0 to compact with Linux kernel helper functions. "},{"title":"网络链路图","type":0,"sectionRef":"#","url":"/zh/docs/guide/network-graph","content":"","keywords":""},{"title":"展示历史时间的链路图​","type":1,"pageTitle":"网络链路图","url":"/zh/docs/guide/network-graph#展示历史时间的链路图","content":"通过Time时间选择器，可以查询某个特定时间点15分钟范围内的链路信息。 "},{"title":"根据命名空间筛选端点​","type":1,"pageTitle":"网络链路图","url":"/zh/docs/guide/network-graph#根据命名空间筛选端点","content":"你可以通过Namespaces下拉菜单来根据命名空间名称筛选端点。若不进行选择，则默认显示所有命名空间下的端点。 "},{"title":"展开和收起节点​","type":1,"pageTitle":"网络链路图","url":"/zh/docs/guide/network-graph#展开和收起节点","content":"你可以通过点击节点来展开并显示该组内的所有节点。你也可以通过再次点击已展开的节点来收起它。 "},{"title":"查看详细链路信息​","type":1,"pageTitle":"网络链路图","url":"/zh/docs/guide/network-graph#查看详细链路信息","content":"通过切换ViewMode为Table模式，可以以表格形式查看详细的链路信息。除了源和目的节点之外，还会显示IP、端口、连接流量等详细信息。  "},{"title":"使用Sidecar模式","type":0,"sectionRef":"#","url":"/zh/docs/guide/running-in-sidecar","content":"","keywords":""},{"title":"示例​","type":1,"pageTitle":"使用Sidecar模式","url":"/zh/docs/guide/running-in-sidecar#示例","content":"接下来的示例会演示如何在一个nginx deployment中运行KubeSkoop Agent的sidecar容器。 保存以下yaml文件，并将其apply到你的Kubernetes集群中。 apiVersion: apps/v1 kind: Deployment metadata: name: nginx-with-exporter spec: replicas: 1 selector: matchLabels: app: nginx-with-exporter template: metadata: labels: app: nginx-with-exporter spec: containers: - name: nginx image: nginx ports: - containerPort: 80 # add KubeSkoop sidecar container - name: exporter image: kubeskoop/agent:latest imagePullPolicy: Always command: - /bin/inspector - server # enable sidecar mode - --sidecar volumeMounts: - name: config-volume mountPath: /etc/config env: # set node name, pod name/namespace from env - name: INSPECTOR_NODENAME valueFrom: fieldRef: apiVersion: v1 fieldPath: spec.nodeName - name: INSPECTOR_POD_NAME valueFrom: fieldRef: apiVersion: v1 fieldPath: metadata.name - name: INSPECTOR_POD_NAMESPACE valueFrom: fieldRef: apiVersion: v1 fieldPath: metadata.namespace ports: - containerPort: 9012 volumes: - configMap: defaultMode: 420 name: kubeskoop-config name: config-volume --- apiVersion: v1 kind: ConfigMap metadata: name: kubeskoop-config data: config.yaml: |- debugmode: true port: 9102 metrics: probes: - name: netdev - name: io - name: sock - name: tcpsummary - name: tcp - name: tcpext - name: udp  这个文件将会在default命名空间下创建名为nginx-with-exporter的Deployment，以及ConfigMapkubeskoop-config用于配置。 当Pod启动后，你便可以通过kubectl来获得Pod中的metrics。 kubectl get --raw /api/v1/namespaces/default/pods/{{kubeskoop pod name}}:9102/proxy/metrics  示例输出如下： # HELP kubeskoop_io_ioreadbytes io ioioreadbytes count in netns/pod # TYPE kubeskoop_io_ioreadbytes gauge kubeskoop_io_ioreadbytes{namespace=&quot;default&quot;,node=&quot;node1&quot;,pod=&quot;nginx-with-exporter-66fb94cbfc-4bxf5&quot;,target_namespace=&quot;default&quot;,target_node=&quot;node1&quot;,target_pod=&quot;nginx-with-exporter-66fb94cbfc-4bxf5&quot;} 4096 # HELP kubeskoop_io_ioreadsyscall io ioioreadsyscall count in netns/pod # TYPE kubeskoop_io_ioreadsyscall gauge kubeskoop_io_ioreadsyscall{namespace=&quot;default&quot;,node=&quot;node1&quot;,pod=&quot;nginx-with-exporter-66fb94cbfc-4bxf5&quot;,target_namespace=&quot;default&quot;,target_node=&quot;node1&quot;,target_pod=&quot;nginx-with-exporter-66fb94cbfc-4bxf5&quot;} 3765 # HELP kubeskoop_io_iowritebytes io ioiowritebytes count in netns/pod # TYPE kubeskoop_io_iowritebytes gauge kubeskoop_io_iowritebytes{namespace=&quot;default&quot;,node=&quot;node1&quot;,pod=&quot;nginx-with-exporter-66fb94cbfc-4bxf5&quot;,target_namespace=&quot;default&quot;,target_node=&quot;node1&quot;,target_pod=&quot;nginx-with-exporter-66fb94cbfc-4bxf5&quot;} 4096 # HELP kubeskoop_io_iowritesyscall io ioiowritesyscall count in netns/pod # TYPE kubeskoop_io_iowritesyscall gauge kubeskoop_io_iowritesyscall{namespace=&quot;default&quot;,node=&quot;node1&quot;,pod=&quot;nginx-with-exporter-66fb94cbfc-4bxf5&quot;,target_namespace=&quot;default&quot;,target_node=&quot;node1&quot;,target_pod=&quot;nginx-with-exporter-66fb94cbfc-4bxf5&quot;} 26578 # HELP kubeskoop_netdev_rxbytes netdev netdevrxbytes count in netns/pod # TYPE kubeskoop_netdev_rxbytes gauge kubeskoop_netdev_rxbytes{namespace=&quot;default&quot;,node=&quot;node1&quot;,pod=&quot;nginx-with-exporter-66fb94cbfc-4bxf5&quot;,target_namespace=&quot;default&quot;,target_node=&quot;node1&quot;,target_pod=&quot;nginx-with-exporter-66fb94cbfc-4bxf5&quot;} 2139 # HELP kubeskoop_netdev_rxdropped netdev netdevrxdropped count in netns/pod # TYPE kubeskoop_netdev_rxdropped gauge kubeskoop_netdev_rxdropped{namespace=&quot;default&quot;,node=&quot;node1&quot;,pod=&quot;nginx-with-exporter-66fb94cbfc-4bxf5&quot;,target_namespace=&quot;default&quot;,target_node=&quot;node1&quot;,target_pod=&quot;nginx-with-exporter-66fb94cbfc-4bxf5&quot;} 0 # ...and more  "},{"title":"限制​","type":1,"pageTitle":"使用Sidecar模式","url":"/zh/docs/guide/running-in-sidecar#限制","content":"当前sidecar模式暂不支持基于eBPF的探针。 "},{"title":"快速上手","type":0,"sectionRef":"#","url":"/zh/docs/quick-start","content":"快速上手 你可以通过skoopbundle.yaml文件快速部署KubeSkoop、Prometheus、Grafana和Loki至你的集群。并通过Web控制台使用KubeSkoop的功能。 kubectl apply -f https://raw.githubusercontent.com/alibaba/kubeskoop/main/deploy/skoopbundle.yaml 提示 skoopbundle.yaml以最小副本和默认配置启动，不适用于生产环境。在生产环境中安装KubeSkoop，请参考安装。 在安装完成并启动后，你可以通过webconsole服务来访问KubeSkoop Web控制台。 kubectl get svc -n kubeskoop webconsole 你可能需要将webconsole服务更改为NodePort 或LoadBalancer类型，以便从集群外访问。 控制台的默认用户为admin，密码为kubeskoop。 恭喜！你已经成功安装了KubeSkoop。关于控制台的更多功能，请见Web控制台。","keywords":""},{"title":"Web控制台","type":0,"sectionRef":"#","url":"/zh/docs/guide/web-console","content":"","keywords":""},{"title":"监控集群网络​","type":1,"pageTitle":"Web控制台","url":"/zh/docs/guide/web-console#监控集群网络","content":""},{"title":"查看网络抖动和性能大盘​","type":1,"pageTitle":"Web控制台","url":"/zh/docs/guide/web-console#查看网络抖动和性能大盘","content":"在Monitoring - Dashboard中，可以查看当前集群内网络大盘，从大盘中可查询对应性能问题时间点的各深度指标的水位情况。  "},{"title":"查看网络抖动事件​","type":1,"pageTitle":"Web控制台","url":"/zh/docs/guide/web-console#查看网络抖动事件","content":"在Monitoring - Event下，可以看到当前时间点集群内产生的异常事件。你也可以手动选择需要的时间范围，或者根据事件类型、节点、事件产生的Pod命名空间/名称等信息进行筛选。 点击右上角的Live，可以实时根据当前筛选条件，实时监控集群内事件。  "},{"title":"网络链路图​","type":1,"pageTitle":"Web控制台","url":"/zh/docs/guide/web-console#网络链路图","content":"见网络链路图。 "},{"title":"诊断网络问题​","type":1,"pageTitle":"Web控制台","url":"/zh/docs/guide/web-console#诊断网络问题","content":""},{"title":"网络连通性诊断​","type":1,"pageTitle":"Web控制台","url":"/zh/docs/guide/web-console#网络连通性诊断","content":"见连通性诊断。 "},{"title":"抓包​","type":1,"pageTitle":"Web控制台","url":"/zh/docs/guide/web-console#抓包","content":"见抓包。 "},{"title":"延迟探测​","type":1,"pageTitle":"Web控制台","url":"/zh/docs/guide/web-console#延迟探测","content":"见延迟探测。 "},{"title":"配置​","type":1,"pageTitle":"Web控制台","url":"/zh/docs/guide/web-console#配置","content":""},{"title":"节点配置​","type":1,"pageTitle":"Web控制台","url":"/zh/docs/guide/web-console#节点配置","content":"在Network - Configuration - Node Configuration中，可以对集群KubeSkoop Agent实例进行配置。  By clicking the Add or Delete, you can turn on or off the node's metrics/event probes, as well as configure the event collector from this page. 提示 在对节点配置修改完成后，需要点击页面右下角的Save Configuration按钮，使修改生效。 "},{"title":"命令行参数","type":0,"sectionRef":"#","url":"/zh/docs/reference/connectivity-diagnosis/command-line-arguments","content":"命令行参数 skoop命令目前提供以下命令行参数。 参数\t说明-p, --dport uint16\t网络诊断的端口 -d, --dst string\t网络诊断的目的地址 --protocol string\t网络诊断的协议（默认tcp） -s, --src string\t网络诊断的源地址 --cloud-provider string\t云提供商名称（默认generic） --cluster-cidr string\t集群Pod CIDR。若没有指定，将会尝试自动探测。 --kube-config string\t集群kubeconfig路径（默认~/.kube/config） --network-plugin string\t集群网络插件。若没有指定，将会尝试自动探测 --proxy-mode string\tkube-proxy模式。若没有指定，将会尝试自动探测 --format string\t结果输出格式，支持d2/svg/json。若没有指定，只会在控制台打印简单链路信息 --http\t启动HTTP服务器来展示诊断结果 --http-address string\tHTTP服务器监听地址（默认127.0.0.1:8080） --output string\t输出结果保存文件路径，默认为当前目录下的output.d2/svg/json --aliyun-access-key-id string\t阿里云access key --aliyun-access-key-secret string\t阿里云access secret --aliyun-security-token string\t阿里云security token（可选） --collector-image string\tcollector所使用的镜像地址（默认registry.cn-hangzhou.aliyuncs.com/kubeskoop/kubeskoop:&lt;版本&gt;） --collector-namespace string\tcollector pod所在命名空间 （默认skoop） --collector-pod-wait-interval duration\tcollector pod运行检测时间间隔（默认2s） --collector-pod-wait-timeout duration\tcollector pod运行检测超时时间（默认2m0s） --calico-host-interface string\tCalico插件所使用的主机网络接口（默认eth0） --calico-ipip-pod-mtu int\tCalico插件所使用的Pod MTU，IPIP模式（默认1480） --calico-pod-mtu int\tCalico插件所使用的Pod MTU，BGP模式（默认1500） --flannel-backend-type string\tFlannel插件的模式，支持host-gw,vxlan,alloc。若没有指定，将会尝试从Flannel配置中自动探测 --flannel-bridge string\tFlannel插件的bridge设备名称（默认cni0） --flannel-host-interface string\tFlannel插件所使用的主机网络接口（默认eth0） --flannel-ip-masq\tFlannel插件，是否进行IP masquerade（默认true） --flannel-pod-mtu int\tFlannel插件所使用的Pod MTU。若没有指定，将会根据模式自动设定（vxlan默认1450, 其它模式1500）","keywords":""},{"title":"网络插件","type":0,"sectionRef":"#","url":"/zh/docs/reference/connectivity-diagnosis/network-plugins","content":"","keywords":""},{"title":"Flannel​","type":1,"pageTitle":"网络插件","url":"/zh/docs/reference/connectivity-diagnosis/network-plugins#flannel","content":"支持host-gw和vxlan模式的连通性诊断，会在运行时自动检测所使用的类型。 "},{"title":"Calico​","type":1,"pageTitle":"网络插件","url":"/zh/docs/reference/connectivity-diagnosis/network-plugins#calico","content":"支持BGP以及IPIP模式的连通性诊断，会在运行时自动检测所使用的类型。 提示 Calico诊断将会优先使用projectcalico.org/v3。Calico API Server组件。更多信息，可见Calico文档。 "},{"title":"云供应商","type":0,"sectionRef":"#","url":"/zh/docs/reference/connectivity-diagnosis/cloud-providers","content":"","keywords":""},{"title":"阿里云​","type":1,"pageTitle":"云供应商","url":"/zh/docs/reference/connectivity-diagnosis/cloud-providers#阿里云","content":"指定--cloud-provider aliyun以使用阿里云作为云提供商。 参数\t说明--aliyun-access-key-id\t阿里云access key --aliyun-access-key-secret\t阿里云access secret --aliyun-security-token\t(可选)阿里云security token "},{"title":"Roadmap","type":0,"sectionRef":"#","url":"/zh/docs/roadmap","content":"Roadmap kubeskoop roadmap","keywords":""},{"title":"探针，指标和事件","type":0,"sectionRef":"#","url":"/zh/docs/reference/monitoring/probes-metrics-events","content":"","keywords":""},{"title":"探针​","type":1,"pageTitle":"探针，指标和事件","url":"/zh/docs/reference/monitoring/probes-metrics-events#探针","content":"以下是KubeSkoop所支持的探针。 探针名称\t说明\t探针类型\t数据源\t开销virtcmdlatency\tvirtio设备延迟追踪\t指标、事件\teBPF\t高 udp\tUDP统计\t指标\tprofcs\t低 tcpsummary\tTCP队列和连接状态统计\t指标\tprocfs\t中 tcpreset\tTCP reset追踪\t事件\teBPF\t低 tcpext\tTCPExt统计\t指标\tprocfs\t低 tcp\tsnmp中的TCP统计\t指标\tprofcs\t低 softnet\t网络设备发包和丢包数统计\t指标\tprocfs\t低 socketlatency\tsocket延迟追踪\t指标、事件\teBPF\t高 sock\tsocket统计\t指标\tprocfs\t低 qdisc\ttc qdisc统计\t指标\tnetlink\t低 flow\t连接流量统计\t指标\teBPF\t中 packetloss\t丢包事件追踪\t指标、事件\teBPF\t中 netiftxlatency\t发包网络延迟跟踪\t指标、事件\teBPF\t高 netdev\t网络设备统计\t指标\tprocfs\t低 net_softirq\t软中断延迟追踪\t指标、事件\teBPF\t高 kernellatency\t内核延迟跟踪\t指标、事件\teBPF\t高 ipvs\tIPVS统计\t指标\tprocfs\t低 ip\tIP统计\t指标\tprofcs\t低 io\t进程IO统计\t指标\tprocfs\t低 fd\t文件与socket描述符统计\t指标\tprocfs\t中 conntrack\tconntrack统计\t指标\tnetlink\t低 biolatency\tBlock IO延迟跟踪\t事件\teBPF\t中 tcpretrans\tTCP包重传追踪\t指标、事件\teBPF\t低 "},{"title":"指标​","type":1,"pageTitle":"探针，指标和事件","url":"/zh/docs/reference/monitoring/probes-metrics-events#指标","content":""},{"title":"标签​","type":1,"pageTitle":"探针，指标和事件","url":"/zh/docs/reference/monitoring/probes-metrics-events#标签","content":"在所有的指标上都存在以下标签。 标签名称\t说明k8s_namespace\tPod命名空间，或hostNetwork k8s_pod\tPod名称，或hostNetwork k8s_node\tNode名称 "},{"title":"指标列表​","type":1,"pageTitle":"探针，指标和事件","url":"/zh/docs/reference/monitoring/probes-metrics-events#指标列表","content":"指标名称\t探针名称\t说明kubeskoop_conntrack_found\tconntrack\tconntrack统计计数&quot;found&quot; kubeskoop_conntrack_invalid\tconntrack\tconntrack统计计数&quot;invalid&quot; kubeskoop_conntrack_ignore\tconntrack\tconntrack统计计数&quot;ignore&quot; kubeskoop_conntrack_insert\tconntrack\tconntrack统计计数&quot;insert&quot; kubeskoop_conntrack_insertfailed\tconntrack\tconntrack统计计数&quot;insert_failed&quot; kubeskoop_conntrack_drop\tconntrack\tconntrack统计计数&quot;drop&quot; kubeskoop_conntrack_earlydrop\tconntrack\tconntrack统计计数&quot;early_drop&quot; kubeskoop_conntrack_error\tconntrack\tconntrack统计计数&quot;error&quot; kubeskoop_conntrack_searchrestart\tconntrack\tconntrack统计计数&quot;search_restart&quot; kubeskoop_conntrack_entries\tconntrack\tconntrack全局计数&quot;entries&quot; kubeskoop_conntrack_maxentries\tconntrack\tconntrack全局计数&quot;max_entries&quot; kubeskoop_qdisc_bytes\tqdisc\ttc qdisc统计计数&quot;bytes&quot; kubeskoop_qdisc_packets\tqdisc\ttc qdisc统计计数&quot;packets&quot; kubeskoop_qdisc_drops\tqdisc\ttc qdisc统计计数&quot;drops&quot; kubeskoop_qdisc_qlen\tqdisc\ttc qdisc统计计数&quot;qlen&quot; kubeskoop_qdisc_backlog\tqdisc\ttc qdisc统计计数&quot;backlog&quot; kubeskoop_qdisc_overlimits\tqdisc\ttc qdisc统计计数&quot;overlimits&quot; kubeskoop_fdopenfd\tfd\tpod中打开fd数 kubeskoop_fd_opensocket\tfd\tpod中打开socket数 kubeskoop_io_ioreadsyscall\tio\tpod中读系统调用数 kubeskoop_io_iowritesyscall\tio\tpod中写系统调用数 kubeskoop_io_ioreadbytes\tio\tpod中读字节数 kubeskoop_io_iowritebytes\tio\tpod中写字节数 kubeskoop_ipvs_connections\tipvs\tpod中IPVS连接数 kubeskoop_ipvs_incomingpackets\tipvs\tpod中IPVS入数据包数 kubeskoop_ipvs_outgoingbytes\tipvs\tpod中IPVS出数据包数 kubeskoop_ipvs_incomingbytes\tipvs\tpod中IPVS入字节数 kubeskoop_ipvs_outgoingpackets\tipvs\tpod中IPVS出字节数 kubeskoop_netdev_rxbytes\tnetdev\tpod中所有网络设备的接收字节数 kubeskoop_netdev_rxerrors\tnetdev\tpod中所有网络设备的接收错误数 kubeskoop_netdev_txbytes\tnetdev\tpod中所有网络设备的发送字节数 kubeskoop_netdev_txerrors\tnetdev\tpod中所有网络设备的发送错误数 kubeskoop_netdev_rxpackets\tnetdev\tpod中所有网络设备的接收数据包数 kubeskoop_netdev_rxdropped\tnetdev\tpod中所有网络设备的接收丢弃数据包数 kubeskoop_netdev_txpackets\tnetdev\tpod中所有网络设备的发送数据包数 kubeskoop_netdev_txdropped\tnetdev\tpod中所有网络设备的发送丢弃数据包数 kubeskoop_tcpext_listendrops\ttcpext\tTCPExt中的ListenDrops kubeskoop_tcpext_listenoverflows\ttcpext\tTCPExt中的ListenOverflow kubeskoop_tcpext_tcpsynretrans\ttcpext\tTCPExt中的TCPSynRetrans kubeskoop_tcpext_tcpfastretrans\ttcpext\tTCPExt中的TCPFastRetrans kubeskoop_tcpext_tcpretransfail\ttcpext\tTCPExt中的TCPRetransFail kubeskoop_tcpext_tcptimeouts\ttcpext\tTCPExt中的TCPTimeouts kubeskoop_tcpext_tcpabortonclose\ttcpext\tTCPExt中的TCPAbortOnClose kubeskoop_tcpext_tcpabortonmemory\ttcpext\tTCPExt中的TCPAbortOnMemory kubeskoop_tcpext_tcpabortontimeout\ttcpext\tTCPExt中的TCPAbortOnTimeout kubeskoop_tcpext_tcpabortonlinger\ttcpext\tTCPExt中的TCPAbortOnLinger kubeskoop_tcpext_tcpabortondata\ttcpext\tTCPExt中的TCPAbortOnData kubeskoop_tcpext_tcpabortfailed\ttcpext\tTCPExt中的TCPAbortFailed kubeskoop_tcpext_tcpackskippedsynrecv\ttcpext\tTCPExt中的TCPACKSkippedSynRecv kubeskoop_tcpext_tcpackskippedpaws\ttcpext\tTCPExt中的TCPACKSkippedPAWS kubeskoop_tcpext_tcpackskippedseq\ttcpext\tTCPExt中的TCPACKSkippedSeq kubeskoop_tcpext_tcpackskippedfinwait2\ttcpext\tTCPExt中的TCPACKSkippedFinWait2 kubeskoop_tcpext_tcpackskippedtimewait\ttcpext\tTCPExt中的TCPACKSkippedTimeWait kubeskoop_tcpext_tcpackskippedchallenge\ttcpext\tTCPExt中的TCPACKSkippedChallenge kubeskoop_tcpext_tcprcvqdrop\ttcpext\tTCPExt中的TCPRcvQDrop kubeskoop_tcpext_tcpmemorypressures\ttcpext\tTCPExt中的TCPMemoryPressures kubeskoop_tcpext_tcpmemorypressureschrono\ttcpext\tTCPExt中的TCPMemoryPressuresChrono kubeskoop_tcpext_pawsactive\ttcpext\tTCPExt中的PAWSActive kubeskoop_tcpext_pawsestab\ttcpext\tTCPExt中的PAWSEstab kubeskoop_tcpext_embryonicrsts\ttcpext\tTCPExt中的EmbryonicRsts kubeskoop_tcpext_tcpwinprobe\ttcpext\tTCPExt中的TCPWinProbe kubeskoop_tcpext_tcpkeepalive\ttcpext\tTCPExt中的TCPKeepAlive kubeskoop_tcpext_tcpmtupfail\ttcpext\tTCPExt中的TCPMTUPFail kubeskoop_tcpext_tcpmtupsuccess\ttcpext\tTCPExt中的TCPMTUPSuccess kubeskoop_tcpext_tcpzerowindowdrop\ttcpext\tTCPExt中的TCPZeroWindowDrop kubeskoop_tcpext_tcpbacklogdrop\ttcpext\tTCPExt中的TCPBacklogDrop kubeskoop_tcpext_pfmemallocdrop\ttcpext\tTCPExt中的PFMemallocDrop kubeskoop_tcpext_tcpwqueuetoobig\ttcpext\tTCPExt中的TCPWqueueTooBig kubeskoop_tcp_activeopens\ttcp\tTCP中的ActiveOpens kubeskoop_tcp_passiveopens\ttcp\tTCP中的PassiveOpens kubeskoop_tcp_retranssegs\ttcp\tTCP中的RetransSegs kubeskoop_tcp_attemptfails\ttcp\tTCP中的AttemptFails kubeskoop_tcp_estabresets\ttcp\tTCP中的EstabResets kubeskoop_tcp_currestab\ttcp\tTCP中的CurrEstab kubeskoop_tcp_insegs\ttcp\tTCP中的InSegs kubeskoop_tcp_outsegs\ttcp\tTCP中的OutSegs kubeskoop_tcp_inerrs\ttcp\tTCP中的InErrs kubeskoop_tcp_outrsts\ttcp\tTCP中的OutRsts kubeskoop_udp_indatagrams\tudp\tUDP中的InDatagrams kubeskoop_udp_noports\tudp\tUDP中的NoPorts kubeskoop_udp_inerrors\tudp\tUDP中的InErrors kubeskoop_udp_outdatagrams\tudp\tUDP中的OutDatagrams kubeskoop_udp_rcvbuferrors\tudp\tUDP中的RcvbufErrors kubeskoop_udp_sndbuferrors\tudp\tUDP中的SndbufErrors kubeskoop_udp_incsumerrors\tudp\tUDP中的InCsumErrors kubeskoop_udp_ignoredmulti\tudp\tUDP中的IgnoredMulti kubeskoop_ip_innoroutes\tip\tIP中的InNoRoutes kubeskoop_ip_intruncatedpkts\tip\tIP中的InTruncatedPkts kubeskoop_sock_inuse\tsock\tsock中的Inuse kubeskoop_sock_orphan\tsock\tsock中的Orphan kubeskoop_sock_tw\tsock\tsock中的TW kubeskoop_sock_alloc\tsock\tsock中的Alloc kubeskoop_sock_mem\tsock\tsock中的Mem kubeskoop_softnet_processed\tsoftnet\tsoftnet中的Processed kubeskoop_softnet_dropped\tsoftnet\tsoftnet中的Dropped kubeskoop_tcpsummary_tcpestablishedconn\ttcpsummary\tESTABLISHED状态连接数 kubeskoop_tcpsummary_tcptimewaitconn\ttcpsummary\tTIME_WAIT状态连接数 kubeskoop_tcpsummary_tcptxqueue\ttcpsummary\t所有TCP连接的tx队列长度 kubeskoop_tcpsummary_tcprxqueue\ttcpsummary\t所有TCP连接的rx队列长度 kubeskoop_netiftxlat_qdiscslow100ms\tnetiftxlatency\tqdisc传输延迟超过100ms kubeskoop_netiftxlat_netdevslow100ms\tnetiftxlatency\tnetdev传输延迟超过100ms kubeskoop_kernellatency_rxslow\tkernellatency\t内核收包慢 kubeskoop_kernellatency_rxslow100ms\tkernellatency\t内核收包延迟超过100ms kubeskoop_kernellatency_txslow\tkernellatency\t内核发包慢 kubeskoop_kernellatency_txslow100ms\tkernellatency\t内核发包延迟超过100ms kubeskoop_packetloss_tcphandle\tpacketloss\t在tcp_v4_do_rcv()中的丢包数 kubeskoop_packetloss_tcprcv\tpacketloss\t在tcp_rcv()中的丢包数 kubeskoop_packetloss_abnormal\tpacketloss\t在其它函数中的丢包数 kubeskoop_packetloss_total\tpacketloss\t丢包总数 kubeskoop_packetloss_netfilter\tpacketloss\t在nf_hook_slow()中的丢包数 kubeskoop_packetloss_tcpstatm\tpacketloss\t在tcp_rcv_state_process()中的丢包数 kubeskoop_socketlatency_read100ms\tsocketlatency\tSocket读延迟超过100ms kubeskoop_socketlatency_read1ms\tsocketlatency\tSocket读延迟超过1ms kubeskoop_socketlatency_write100ms\tsocketlatency\tSocket写延迟超过100ms kubeskoop_socketlatency_write1ms\tsocketlatency\tSocket写延迟超过1ms kubeskoop_virtcmdlatency_latency100ms\tvirtcmdlatency\tVirtio发送命令延迟超过100ms kubeskoop_virtcmdlatency_latency\tvirtcmdlatency\tVirtio发送命令慢 kubeskoop_softirq_schedslow\tnet_softirq\tSoftirq调度慢(从softirq_raise()到softirq_entry()) kubeskoop_softirq_schedslow100ms\tnet_softirq\tSoftirq调度延迟超过100ms kubeskoop_softirq_excuteslow\tnet_softirq\tSoftirq执行慢(从softirq_entry()到softirq_exit()) kubeskoop_softirq_excuteslow100ms\tnet_softirq\tSoftirq执行延迟超过100ms kubeskoop_flow_bytes\tflow\t连接发送字节数 kubeskoop_flow_packets\tflow\t连接发送包数 "},{"title":"事件​","type":1,"pageTitle":"探针，指标和事件","url":"/zh/docs/reference/monitoring/probes-metrics-events#事件","content":""},{"title":"事件列表​","type":1,"pageTitle":"探针，指标和事件","url":"/zh/docs/reference/monitoring/probes-metrics-events#事件列表","content":"以下是KubeSkoop所支持的事件。 事件名称\t探针名称\t描述\t事件内容TXLAT_QDISC_100MS\tnetiftx延迟\tqdisc传输延迟超过100ms\t5元组(协议、源地址&amp;端口、目的地址&amp;端口), 延迟 TXLAT_NETDEV_100MS\tnetiftx延迟\tnetdev传输延迟超过100ms\t5元组(协议、源地址&amp;端口、目的地址&amp;端口), 延迟 BIOLAT_10MS\tbio延迟\tBlock IO延迟超过10ms\t进程名, pid, 延迟 BIOLAT_100MS\tbio延迟\tBlock IO延迟超过100ms\t进程名, pid, 延迟 RXKERNEL_SLOW\tkernel延迟\t内核接受包延迟超过100ms\t5元组(协议、源地址&amp;端口、目的地址&amp;端口), 不同位置的延迟 TXKERNEL_SLOW\tkernel延迟\t内核发送包延迟超过100ms\t5元组(协议、源地址&amp;端口、目的地址&amp;端口), 不同位置的延迟 PacketLoss\tpacketloss\t包被丢弃\t5元组(协议、源地址&amp;端口、目的地址&amp;端口), 栈追踪 SOCKETLAT_READSLOW\tsocket延迟\tSocket读取慢\t5元组(协议、源地址&amp;端口、目的地址&amp;端口), 延迟 SOCKETLAT_SENDSLOW\tsocket延迟\tSocket发送慢\t5元组(协议、源地址&amp;端口、目的地址&amp;端口), 延迟 TCPRESET_NOSOCK\ttcpreset\t因为没有socket导致TCP发送RST报文\t5元组(协议、源地址&amp;端口、目的地址&amp;端口), socket状态 TCPRESET_ACTIVE\ttcpreset\t因为close()系统调用或linger等原因，TCP发送active RST报文\t5元组(协议、源地址&amp;端口、目的地址&amp;端口), socket状态 TCPRESET_PROCESS\ttcpreset\t因为握手时出现问题等原因，TCP发送RST报文\t5元组(协议、源地址&amp;端口、目的地址&amp;端口), socket状态 TCPRESET_RECEIVE\ttcpreset\tTCP连接收到RST报文\t5元组(协议、源地址&amp;端口、目的地址&amp;端口), socket状态 VIRTCMDEXCUTE\tvirtcmd延迟\tVirtio发送命令执行慢\tcpu, pid, 延迟 NETSOFTIRQ_SCHED_SLOW\tnet_softirq\tSoftirq调度慢 (从softirq_raise()到softirq_entry())\tcpu, pid, 延迟 NETSOFTIRQ_SCHED_100MS\tnet_softirq\tSoftirq调度延迟超过100ms\tcpu, pid, 延迟 NETSOFTIRQ_EXCUTE_SLOW\tnet_softirq\tSoftirq执行慢(从softirq_entry()到softirq_exit())\tcpu, pid, 延迟 NETSOFTIRQ_EXCUTE_100MS\tnet_softirq\tSoftirq执行延迟超过100ms\tcpu, pid, 延迟 TCPRetrans\ttcpretrans\tTCP 发生重传\t栈追踪 "}]